{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Culture of International Relations - Corpus statistics\n",
    "\n",
    "#### About this notebook\n",
    "tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".jupyter-widgets {\n",
       "    font-size: 8pt;\n",
       "}\n",
       ".widget-label {\n",
       "    font-size: 8pt;\n",
       "}\n",
       ".widget-dropdown > select {\n",
       "    font-size: 8pt;\n",
       "}\n",
       ".widget-toggle-button > button {\n",
       "    font-size: 8pt;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".jupyter-widgets {\n",
    "    font-size: 8pt;\n",
    "}\n",
    ".widget-label {\n",
    "    font-size: 8pt;\n",
    "}\n",
    ".widget-dropdown > select {\n",
    "    font-size: 8pt;\n",
    "}\n",
    ".widget-toggle-button > button {\n",
    "    font-size: 8pt;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:blue'>**Mandatory Prepare Step**</span>: Setup Notebook\n",
    "The following code cell must to be executed once for each user session. The step loads utility Python code stored in separate files, and imports dependencies to external libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "#%run ../common/file_utility\n",
    "#%run ../common/network_utility\n",
    "\n",
    "%run ../common/widgets_utility\n",
    "%run ./configuration_elements\n",
    "%run ../common/utility\n",
    "%run ./treaty_corpus\n",
    "%run ../common/treaty_state\n",
    "\n",
    "logger = getLogger('corpus_text_analysis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:blue'>**Mandatory Prepare Step**</span>: Load and Process Treaty Master Index\n",
    "The following code cell to be executed once for each user session. The code loads the WTI master index (and some related data files), and prepares the data for subsequent use.\n",
    "\n",
    "The treaty data is processed as follows:\n",
    "- All the treaty data are loaded.Extract year treaty was signed as seperate fields\n",
    "- Add new fields for specified signed period divisions\n",
    "- Fields 'group1' and 'group2' are ignored (many missing values). Instead group are fetched via party code from encoding found in the \"groups\" table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported: Treaties_Master_List_Treaties.csv\n",
      "Imported: country_continent.csv\n",
      "Imported: parties_curated_parties.csv\n",
      "Imported: parties_curated_continent.csv\n",
      "Imported: parties_curated_group.csv\n",
      "Number of treaties loaded: 61365\n",
      "Number of cultural treaties: 2063 (total), 1127 within periods\n"
     ]
    }
   ],
   "source": [
    "# Load and process treaties master index\n",
    "%run ../common/treaty_state\n",
    "treaty_state = load_treaty_state(data_folder='../data', skip_columns=None)\n",
    "treaties = state.data['treaties']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style='color:blue'>**Mandatory Step**</span>: Convert Treaty Text Corpora to MM Format\n",
    "\n",
    "This code cell is a mandatory step for subsequent text corpus statistics. \n",
    "\n",
    "This step processes the treaty text for from given compressed archive (ZIP-file), each language , and stores in an efficient Market-Matrix (MM) corpus format. The corpora is only stored if it is not previously stored, or the \"Force Update\" is specified. Note that an update MUST be forced whenever the treaty archive is updated - otherwise the text in the new archive is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     119,
     200,
     219
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fef0eecbea403e80072bb43726a851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Corpus:', options=('../data/treaty_corpus_20180821.zip',),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code\n",
    "%run ./treaty_corpus\n",
    "def prepare_treaty_text_corpora(source_pattern):\n",
    "    \n",
    "    def store_mm_corpora(source_path, force, languages):\n",
    "        try:\n",
    "            progress_widget.value = 1\n",
    "            tokenizer = nltk.tokenize.word_tokenize\n",
    "            source_folder = os.path.split(source_path)[0]\n",
    "            for language in languages.split(','):\n",
    "                progress_widget.value += 1\n",
    "                loader = TreatyCorpusSaveLoad(source_folder, language)\n",
    "                if not loader.exists() or force:\n",
    "                    progress_widget.description = 'Processing: {}'.format(language)\n",
    "                    stream = CompressedFileReader(source_path, filename_pattern='*_{}*.txt'.format(language))\n",
    "                    treaty_corpus = TreatyCorpus(stream, tokenizer=tokenizer)        \n",
    "                    loader.store_as_mm_corpus(treaty_corpus)\n",
    "            progress_widget.description = ''\n",
    "            progress_widget.value = 0\n",
    "        except Exception as ex:\n",
    "            logger.error(ex)\n",
    "        \n",
    "    current_archives = (ls_sorted(source_pattern) or [])\n",
    "\n",
    "    source_path_widget=widgets.Dropdown(\n",
    "        options=current_archives,\n",
    "        value=current_archives[-1] if len(current_archives) else None,\n",
    "        description='Corpus:' #, **drop_style\n",
    "    )\n",
    "    force_corpus_update_widget=widgets.ToggleButton(\n",
    "        description='Force Update',\n",
    "        tooltip='Force refresh of saved corpus cache (a performance feature).\\\n",
    "        Use when ZIP-archive has been updated.',\n",
    "        value=False #, **toggle_style\n",
    "    )\n",
    "    progress_widget=wf.create_int_progress_widget(min=0, max=5, step=1, value=0)\n",
    "\n",
    "    wi = widgets.interactive(\n",
    "        store_mm_corpora,\n",
    "        source_path=source_path_widget,\n",
    "        force=force_corpus_update_widget,\n",
    "        languages='en,it,fr,de'\n",
    "    )\n",
    "\n",
    "    display(\n",
    "        widgets.VBox([widgets.HBox([source_path_widget, force_corpus_update_widget, progress_widget]), wi.children[-1]])\n",
    "    )\n",
    "\n",
    "    wi.update()\n",
    "    \n",
    "prepare_treaty_text_corpora('../data/*.zip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def specify_corpus_reader_interactor(treaties):\n",
    "    \n",
    "    def get_treaties_filenames():\n",
    "        \n",
    "        return []\n",
    "        \n",
    "    def specify_corpus_reader(treaties):\n",
    "        pass\n",
    "    \n",
    "    preselect_options = {\n",
    "        'Corpus A': 'corpus_a',\n",
    "        'Corpus B': 'corpus_b'\n",
    "    }\n",
    "    \n",
    "    preselect_widget=widgets.Dropdown(\n",
    "        options=preselect_options,\n",
    "        value=None,\n",
    "        description='Pre-selects:'\n",
    "    )\n",
    "    \n",
    "    wi = widgets.interactive(\n",
    "        specify_corpus_reader,\n",
    "        preselect=preselect_widget\n",
    "    )\n",
    "\n",
    "    display(\n",
    "        widgets.VBox([widgets.HBox([source_path_widget, force_corpus_update_widget, progress_widget]), wi.children[-1]])\n",
    "    )\n",
    "\n",
    "    wi.update()\n",
    "    \n",
    "specify_corpus_reader_handler(treaties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Basic Corpus Statistics\n",
    "See https://www.nltk.org/book/ch01.html\n",
    "\n",
    "* Size of treaties over time\n",
    "* Unique word, unique words per word class\n",
    "* Lexical diversity\n",
    "* Frequency distribution\n",
    "* Average word length, sentence length\n",
    "\n",
    "\n",
    "```python\n",
    " \t\n",
    ">>> len(texts) / count(docs)\n",
    "0.06230453042623537\n",
    ">>>\n",
    "\n",
    ">>> len(set(text3)) / len(text3)\n",
    "0.06230453042623537\n",
    ">>>\n",
    "\n",
    ">>> > def lexical_diversity(text): [1]\n",
    "...     return len(set(text)) / len(text) [2]\n",
    "...\n",
    ">>> def percentage(count, total): [3]\n",
    "...     return 100 * count / total\n",
    "\n",
    "# Most common words\n",
    "fdist1 = FreqDist(text1)\n",
    "fdist1.most_common(50)\n",
    "\n",
    "# Word length frequencies\n",
    ">>> fdist = FreqDist(len(w) for w in text1)  [2]\n",
    ">>> print(fdist)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6450da94eb514198ab38a61213c8c489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Language:', layout=Layout(width='260px'), options={'Englisâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code \n",
    "\n",
    "corpus = None\n",
    "def display_token_toplist_interact(source_folder):\n",
    "    global corpus\n",
    "    progress_widget = None\n",
    "    \n",
    "    def display_token_toplist(source_folder, language, statistics='', remove_stopwords=False):\n",
    "        global corpus\n",
    "\n",
    "        try:\n",
    "\n",
    "            progress_widget.value = 1\n",
    "\n",
    "            corpus = TreatyCorpusSaveLoad(source_folder=source_folder, lang=language[0]).load_mm_corpus()\n",
    "\n",
    "            progress_widget.value = 2\n",
    "            service = MmCorpusStatisticsService(corpus, dictionary=corpus.dictionary, language=language)\n",
    "\n",
    "            print(\"Corpus consists of {} documents, {} words in total and a vocabulary size of {} tokens.\"\\\n",
    "                      .format(len(corpus), corpus.dictionary.num_pos, len(corpus.dictionary)))\n",
    "\n",
    "            progress_widget.value = 3\n",
    "            if statistics == 'word_freqs':\n",
    "                display(service.compute_word_frequencies(remove_stopwords))\n",
    "            elif statistics == 'documents':\n",
    "                display(service.compute_document_stats())\n",
    "            elif statistics == 'word_count':\n",
    "                display(service.compute_word_stats())\n",
    "            else:\n",
    "                print('Unknown: ' + statistics)\n",
    "\n",
    "        except Exception as ex:\n",
    "            logger.error(ex)\n",
    "\n",
    "        progress_widget.value = 5\n",
    "        progress_widget.value = 0\n",
    "        return corpus\n",
    "    \n",
    "    language_widget=widgets.Dropdown(\n",
    "        options={\n",
    "            'English': ('en', 'english'),\n",
    "            'French': ('fr', 'french'),\n",
    "            'German': ('de', 'german'),\n",
    "            'Italian': ('it', 'italian')\n",
    "        },\n",
    "        value=('en', 'english'),\n",
    "        description='Language:', **dict(layout=widgets.Layout(width='260px'))\n",
    "    )\n",
    "    \n",
    "    statistics_widget=widgets.Dropdown(\n",
    "        options={\n",
    "            'Word freqs': 'word_freqs',\n",
    "            'Documents': 'documents',\n",
    "            'Word count': 'word_count'\n",
    "        },\n",
    "        value='word_count',\n",
    "        description='Statistics:', **dict(layout=widgets.Layout(width='260px'))\n",
    "    )\n",
    "    \n",
    "    remove_stopwords_widget=widgets.ToggleButton(\n",
    "        description='Remove stopwords', value=True,\n",
    "        tooltip='Do not include stopwords in token toplist'\n",
    "    )\n",
    "    \n",
    "    progress_widget=wf.create_int_progress_widget(min=0, max=5, step=1, value=0) #, layout=widgets.Layout(width='100%')),\n",
    "\n",
    "    wi = widgets.interactive(\n",
    "        display_token_toplist,\n",
    "        source_folder=source_folder,\n",
    "        language=language_widget,\n",
    "        statistics=statistics_widget,\n",
    "        remove_stopwords=remove_stopwords_widget\n",
    "    )\n",
    "\n",
    "    boxes = widgets.HBox(\n",
    "        [\n",
    "            language_widget, statistics_widget, remove_stopwords_widget, progress_widget\n",
    "        ]\n",
    "    )\n",
    "    display(widgets.VBox([boxes, wi.children[-1]]))\n",
    "    wi.update()\n",
    "\n",
    "display_token_toplist_interact('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_predicate = None\n",
    "filename_predicate = filename_predicate or (lambda x: True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: red'>WORK IN PROGRESS</span> Task: Treaty Keyword Extraction (using TF-IDF weighing)\n",
    "- [ML Wiki.org](http://mlwiki.org/index.php/TF-IDF)\n",
    "- [Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "- SpÃ¤rck Jones, K. (1972). \"A Statistical Interpretation of Term Specificity and Its Application in Retrieval\".\n",
    "- Manning, C.D.; Raghavan, P.; Schutze, H. (2008). \"Scoring, term weighting, and the vector space model\". ([PDF](http://nlp.stanford.edu/IR-book/pdf/06vect.pdf))\n",
    "- https://markroxor.github.io/blog/tfidf-pivoted_norm/\n",
    "$\\frac{tf-idf}{\\sqrt(rowSums( tf-idf^2 ) )}$\n",
    "- https://nlp.stanford.edu/IR-book/html/htmledition/pivoted-normalized-document-length-1.html\n",
    "\n",
    "Neural Network Methods in Natural Language Processing, Yoav Goldberg:\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2bd4d39be54eb08a67fb69cc66730f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='Language:', index=3, layout=Layout(width='260px'), options={'German': ('de', 'german'), 'French': ('fr', 'french'), 'Italian': ('it', 'italian'), 'English': ('en', 'english')}, value=('en', 'english')), Dropdown(description='Period:', index=3, layout=Layout(width='260px'), options={'': None, 'Alt. division': 'signed_period_alt', 'Year': 'signed_year', 'Default division': 'signed_period'}, value='signed_period'))), VBox(children=(IntSlider(value=5, continuous_update=False, description='Top #:', max=25, min=1), FloatSlider(value=0.001, continuous_update=False, description='Threshold:', max=0.5, readout_format='.3f', step=0.01))), VBox(children=(IntProgress(value=0, max=5), Dropdown(description='Output:', index=3, layout=Layout(width='260px'), options={'': None, 'Alt. division': 'signed_period_alt', 'Year': 'signed_year', 'Default division': 'signed_period'}, value='signed_period'))))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code\n",
    "from scipy.sparse import csr_matrix\n",
    "%timeit\n",
    "\n",
    "    \n",
    "def get_top_tfidf_words(data, n_top=5):\n",
    "    top_list = data.groupby(['treaty_id'])\\\n",
    "        .apply(lambda x: x.nlargest(n_top, 'score'))\\\n",
    "        .reset_index(level=0, drop=True)\n",
    "    return top_list\n",
    "\n",
    "def compute_tfidf_scores(corpus, dictionary, smartirs='ntc'):\n",
    "    #model = gensim.models.logentropy_model.LogEntropyModel(corpus, normalize=True)\n",
    "    model = gensim.models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary, normalize=True) #, smartirs=smartirs)\n",
    "    rows, cols, scores = [], [], []\n",
    "    for r, document in enumerate(corpus): \n",
    "        vector = model[document]\n",
    "        c, v = zip(*vector)\n",
    "        rows += (len(c) * [ int(r) ])\n",
    "        cols += c\n",
    "        scores += v\n",
    "        \n",
    "    return csr_matrix((scores, (rows, cols)))\n",
    "    \n",
    "if True: #'tfidf_cache' not in globals():\n",
    "    tfidf_cache = {\n",
    "    }\n",
    "    \n",
    "def display_tfidf_scores(source_folder, language, period, n_top=5, threshold=0.001):\n",
    "    \n",
    "    global state, tfw, tfidf_cache\n",
    "    \n",
    "    try:\n",
    "        treaties = state.treaties\n",
    "\n",
    "        tfw.progress.value = 0\n",
    "        tfw.progress.value += 1\n",
    "        if language[0] not in tfidf_cache.keys():\n",
    "            corpus = TreatyCorpusSaveLoad(source_folder=source_folder, lang=language[0])\\\n",
    "                .load_mm_corpus(normalize_by_D=True)\n",
    "            document_names = corpus.document_names\n",
    "            dictionary = corpus.dictionary\n",
    "            _ = dictionary[0]\n",
    "\n",
    "            tfw.progress.value += 1\n",
    "            A = compute_tfidf_scores(corpus, dictionary)\n",
    "\n",
    "            tfw.progress.value += 1\n",
    "            scores = pd.DataFrame(\n",
    "                [ (i, j, dictionary.id2token[j], A[i, j]) for i, j in zip(*A.nonzero())],\n",
    "                columns=['document_id', 'token_id', 'token', 'score']\n",
    "            )\n",
    "            tfw.progress.value += 1\n",
    "            scores = scores.merge(document_names, how='inner', left_on='document_id', right_index=True)\\\n",
    "                .drop(['document_id', 'token_id', 'document_name'], axis=1)\n",
    "\n",
    "            scores = scores[['treaty_id', 'token', 'score']]\\\n",
    "                .sort_values(['treaty_id', 'score'], ascending=[True, False])\n",
    "\n",
    "            tfidf_cache[language[0]] = scores\n",
    "\n",
    "        scores = tfidf_cache[language[0]]\n",
    "        if threshold > 0:\n",
    "            scores = scores.loc[scores.score >= threshold]\n",
    "\n",
    "        tfw.progress.value += 1\n",
    "\n",
    "        #scores = get_top_tfidf_words(scores, n_top=5)\n",
    "        #scores = scores.groupby(['treaty_id']).sum() \n",
    "\n",
    "        scores = scores.groupby(['treaty_id'])\\\n",
    "            .apply(lambda x: x.nlargest(n_top, 'score'))\\\n",
    "            .reset_index(level=0, drop=True)\\\n",
    "            .set_index('treaty_id')\n",
    "\n",
    "        if period is not None:\n",
    "            periods = state.treaties[period]\n",
    "            scores = scores.merge(periods.to_frame(), left_index=True, right_index=True, how='inner')\\\n",
    "                .groupby([period, 'token']).score.agg([np.mean])\\\n",
    "                .reset_index().rename(columns={0:'score'}) #.sort_values('token')\n",
    "\n",
    "        #['token'].apply(' '.join)\n",
    "\n",
    "        display(scores)\n",
    "    except Exception as ex:\n",
    "        logger.error(ex)\n",
    "        \n",
    "    tfw.progress.value = 0\n",
    "\n",
    "#if 'tfidf_scores' not in globals():\n",
    "#    tfidf_scores = compute_document_tfidf(corpus, corpus.dictionary, state.treaties)\n",
    "#    tfidf_scores = tfidf_scores.sort_values(['treaty_id', 'score'], ascending=[True, False])\n",
    "\n",
    "tfw = BaseWidgetUtility(\n",
    "    language=widgets.Dropdown(\n",
    "        options={\n",
    "            'English': ('en', 'english'),\n",
    "            'French': ('fr', 'french'),\n",
    "            'German': ('de', 'german'),\n",
    "            'Italian': ('it', 'italian')\n",
    "        },\n",
    "        value=('en', 'english'),\n",
    "        description='Language:', **drop_style\n",
    "    ),\n",
    "    remove_stopwords=widgets.ToggleButton(\n",
    "        description='Remove stopwords', value=True,\n",
    "        tooltip='Do not include stopwords in token toplist', **toggle_style\n",
    "    ),    \n",
    "    n_top=widgets.IntSlider(\n",
    "        value=5, min=1, max=25, step=1,\n",
    "        description='Top #:',\n",
    "        continuous_update=False\n",
    "    ),\n",
    "    threshold=widgets.FloatSlider(\n",
    "        value=0.001, min=0.0, max=0.5, step=0.01,\n",
    "        description='Threshold:',\n",
    "        tooltip='Word having a TF-IDF score below this value is filtered out',\n",
    "        continuous_update=False,\n",
    "        readout_format='.3f',\n",
    "    ), \n",
    "    period=widgets.Dropdown(\n",
    "        options={\n",
    "            '': None,\n",
    "            'Year': 'signed_year',\n",
    "            'Default division': 'signed_period',\n",
    "            'Alt. division': 'signed_period_alt'\n",
    "        },\n",
    "        value='signed_period',\n",
    "        description='Period:', **drop_style\n",
    "    ),\n",
    "    output=widgets.Dropdown(\n",
    "        options={\n",
    "            '': None,\n",
    "            'Year': 'signed_year',\n",
    "            'Default division': 'signed_period',\n",
    "            'Alt. division': 'signed_period_alt'\n",
    "        },\n",
    "        value='signed_period',\n",
    "        description='Output:', **drop_style\n",
    "    ),\n",
    "    progress=widgets.IntProgress(min=0, max=5, step=1, value=0) #, layout=widgets.Layout(width='100%')),\n",
    ")\n",
    "\n",
    "itfw = widgets.interactive(\n",
    "    display_tfidf_scores,\n",
    "    source_folder='./data',\n",
    "    language=tfw.language,\n",
    "    n_top=tfw.n_top,\n",
    "    threshold=tfw.threshold,\n",
    "    period=tfw.period\n",
    ")\n",
    "\n",
    "boxes = widgets.HBox(\n",
    "    [\n",
    "        widgets.VBox([tfw.language, tfw.period]),\n",
    "        widgets.VBox([tfw.n_top, tfw.threshold]),\n",
    "        widgets.VBox([tfw.progress, tfw.output])\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(widgets.VBox([boxes, itfw.children[-1]]))\n",
    "itfw.update()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 655.4,
   "position": {
    "height": "886px",
    "left": "1049px",
    "right": "20px",
    "top": "110px",
    "width": "654px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
