{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Culture of International Relations - Text Analysis\n",
    "### <span style='color: green'>SETUP </span> Prepare and Setup Notebook <span style='float: right; color: red'>MANDATORY</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-16 07:26:05,212 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2018-12-16 07:26:05,717 : INFO : WTI index loaded!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os, collections, zipfile\n",
    "import re, typing.re\n",
    "\n",
    "sys.path = list(set(['.', '..']) - set(sys.path)) + sys.path\n",
    "\n",
    "import nltk, textacy, spacy \n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import bokeh, bokeh.plotting, bokeh.models, matplotlib.pyplot as plt\n",
    "import common.utility as utility\n",
    "import common.widgets_utility as widgets_utility\n",
    "import common.widgets_config as widgets_config\n",
    "import common.config as config\n",
    "import common.utility as utility\n",
    "import common.treaty_utility as treaty_utility\n",
    "import common.treaty_state as treaty_repository\n",
    "import treaty_corpus\n",
    "import types, glob\n",
    "import textacy.keyterms\n",
    "import qgrid\n",
    "\n",
    "from beakerx.object import beakerx\n",
    "from beakerx import *\n",
    "from IPython.display import display, set_matplotlib_formats\n",
    "\n",
    "logger = utility.getLogger('corpus_text_analysis')\n",
    "\n",
    "import pickle\n",
    "import topic_model\n",
    "import topic_model_utility\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "#pd.options.display.max_colwidth = -1\n",
    "pd.options.display.colheader_justify = 'left'\n",
    "#pd.options.display.precision = 4\n",
    "\n",
    "DATA_FOLDER = '../data'\n",
    "PATTERN = '*.txt'\n",
    "PERIOD_GROUP = 'years_1945-1972'\n",
    "DF_TAGSET = pd.read_csv('../data/tagset.csv', sep='\\t').fillna('')\n",
    "\n",
    "FIXED_STOPWORDS = ['', '\\n', 'et', 'al', 'et.al.' ]\n",
    "WTI_INDEX = treaty_repository.load_wti_index(data_folder=DATA_FOLDER)\n",
    "\n",
    "%matplotlib inline\n",
    "# set_matplotlib_formats('svg')   \n",
    "bokeh.plotting.output_notebook()\n",
    "\n",
    "def trunc_year_by(series, divisor):\n",
    "    return (series - series.mod(divisor)).astype(int) \n",
    "\n",
    "TREATY_TIME_GROUPINGS = {\n",
    "    'treaty_id': { 'column': 'treaty_id', 'divisor': None, 'title': 'Treaty', 'fx': None},\n",
    "    'signed_year': { 'column': 'signed_year', 'divisor': 1, 'title': 'Year', 'fx': None },\n",
    "    'signed_lustrum': { 'column': 'signed_lustrum', 'divisor': 5, 'title': 'Lustrum', 'fx': lambda df: trunc_year_by(df.signed_year, 5) },\n",
    "    'signed_decade': { 'column': 'signed_decade', 'divisor': 10, 'title': 'Decade', 'fx': lambda df: trunc_year_by(df.signed_year, 10) }\n",
    "}\n",
    "\n",
    "class TopicModelNotComputed(Exception):\n",
    "    @staticmethod\n",
    "    def check():\n",
    "        if 'TM_GUI_MODEL' in globals():\n",
    "            gui =  globals()['TM_GUI_MODEL']\n",
    "            if None not in (gui, gui.model):\n",
    "                return True\n",
    "        msg = 'A topic model must be computed using step \"MODEL Compute a Topic Model\"'\n",
    "        raise TopicModelNotComputed(msg)\n",
    "        \n",
    "class CorpusNotLoaded(Exception):\n",
    "    pass\n",
    "\n",
    "def get_current_model():\n",
    "    TopicModelNotComputed.check()\n",
    "    return globals()['TM_GUI_MODEL'].model\n",
    "\n",
    "def get_current_corpus():\n",
    "    if 'CURRENT_CORPUS' in globals():\n",
    "        if globals()['CURRENT_CORPUS'].textacy_corpus is not None:\n",
    "            return globals()['CURRENT_CORPUS']\n",
    "    raise CorpusNotLoaded('Corpus not loaded or computed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>PREPARE </span> Load and Prepare Corpus <span style='float: right; color: red'>MANDATORY</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d039b89c7d4a81b86d800c1539c2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, layout=Layout(width='90%'), max=5), HBox(children=(Dropdown(description='C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import textacy_corpus_utility as textacy_utility\n",
    "import textacy_corpus_gui\n",
    "\n",
    "if 'CURRENT_CORPUS' not in globals():\n",
    "    CURRENT_CORPUS = types.SimpleNamespace(\n",
    "        language=None,\n",
    "        source_path=None,\n",
    "        prepped_source_path=None,\n",
    "        textacy_corpus_path=None,\n",
    "        textacy_corpus=None,\n",
    "        nlp=None\n",
    "    )\n",
    "\n",
    "try:\n",
    "    textacy_corpus_gui.display_corpus_load_gui(DATA_FOLDER, WTI_INDEX, CURRENT_CORPUS)\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "vec_args = dict(apply_idf=False)\n",
    "term_args = dict(\n",
    "    args=dict(\n",
    "        ngrams=2,\n",
    "        named_entities=False,\n",
    "        normalize='lemma',\n",
    "        as_strings=True\n",
    "    ),\n",
    "    kwargs=dict(\n",
    "        filter_nums=False,\n",
    "        drop_determiners=False,\n",
    "        min_freq=2,\n",
    "        include_pos=[ 'NOUN', 'PROPN' ],\n",
    "        filter_stops=False,\n",
    "        filter_punct=True\n",
    "    ),\n",
    "    extra_stop_words=[]\n",
    ")\n",
    "\n",
    "tm_args = dict(n_topics=10, max_iter=600, learning_method='online', n_jobs=1)\n",
    "# gui.model = topic_model.compute(corpus=corpus, tick=utility.noop, method='gensim_lda', vec_args=vec_args, term_args=term_args, tm_args=tm_args )\n",
    "\n",
    "def terms_iter(corpus, term_args=None):\n",
    "    \n",
    "    n_gram_size = term_args.get('args', {}).get('ngrams', 1)\n",
    "\n",
    "    fx_doc_iter = lambda: ( textacy_utility.textacy_filter_terms(doc, term_args) for doc in corpus )\n",
    "    \n",
    "    doc_iter = ( doc for doc in fx_doc_iter() )\n",
    "    \n",
    "    if n_gram_size in (2, 3):\n",
    "        bigram = gensim.models.Phrases(fx_doc_iter())\n",
    "        bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "        #if n_gram_size == 3:\n",
    "        # trigram = gensim.models.Phrases(bigram[fx_doc_iter()], threshold=100) \n",
    "        #    trigram = gensim.models.Phrases(bigram[fx_doc_iter()], threshold=100)\n",
    "        doc_iter = bigram_model[fx_doc_iter()]\n",
    "\n",
    "    return doc_iter\n",
    "\n",
    "corpus = get_current_corpus().textacy_corpus\n",
    "\n",
    "list([ x for x in terms_iter(corpus, term_args) ][1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>PREPARE/DESCRIBE </span> Find Key Terms <span style='float: right; color: green'>OPTIONAL</span>\n",
    "- [TextRank]\tMihalcea, R., & Tarau, P. (2004, July). TextRank: Bringing order into texts. Association for Computational Linguistics.\n",
    "- [SingleRank]\tHasan, K. S., & Ng, V. (2010, August). Conundrums in unsupervised keyphrase extraction: making sense of the state-of-the-art. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters (pp. 365-373). Association for Computational Linguistics.\n",
    "- [RAKE]\tRose, S., Engel, D., Cramer, N., & Cowley, W. (2010). Automatic Keyword Extraction from Individual Documents. In M. W. Berry & J. Kogan (Eds.), Text Mining: Theory and Applications: John Wiley & Son\n",
    "https://github.com/csurfer/rake-nltk\n",
    "https://github.com/aneesha/RAKE\n",
    "https://github.com/vgrabovets/multi_rake\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color: green'>PREPARE/DESCRIBE </span>RAKE <span style='float: right; color: green'>WORK IN PROGRESS</span>\n",
    "\n",
    "https://github.com/JRC1995/RAKE-Keyword-Extraction\n",
    "https://github.com/JRC1995/TextRank-Keyword-Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1afd1287bad40dd9a19a5102af60ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, layout=Layout(width='95%'), max=1), HBox(children=(Dropdown(description='T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Document Key Terms\n",
    "from rake_nltk import Rake, Metric\n",
    "import string\n",
    "import textacy_corpus_utility as textacy_utility\n",
    "import gui_utility\n",
    "\n",
    "def textacy_rake(doc, language='english', normalize='lemma', n_keyterms=20, stopwords=None, metric=Metric.DEGREE_TO_FREQUENCY_RATIO):\n",
    "    punctuations = string.punctuation + \"\\\"\"\n",
    "    r = Rake(\n",
    "        stopwords=stopwords,  # NLTK stopwords if None\n",
    "        punctuations=punctuations, # NLTK by default\n",
    "        language=language,\n",
    "        ranking_metric=metric,\n",
    "        max_length=100000,\n",
    "        min_length=1\n",
    "    )\n",
    "    text = ' '.join([ x.lemma_ for x in doc.spacy_doc ] if normalize == 'lemma' else [ x.lower_ for x in doc.spacy_doc ])\n",
    "    r.extract_keywords_from_text(doc.text)\n",
    "    keyterms = [ (y, x) for (x, y) in r.get_ranked_phrases_with_scores() ]\n",
    "    return keyterms[:n_keyterms]\n",
    "\n",
    "\n",
    "def display_rake_gui(corpus, language):\n",
    "    \n",
    "    document_options = gui_utility.get_treaty_dropdown_options(WTI_INDEX, corpus)\n",
    "    metric_options = [\n",
    "        ('Degree / Frequency', Metric.DEGREE_TO_FREQUENCY_RATIO),\n",
    "        ('Degree', Metric.WORD_DEGREE),\n",
    "        ('Frequency', Metric.WORD_FREQUENCY)\n",
    "    ]\n",
    "    gui = types.SimpleNamespace(\n",
    "        progress=widgets.IntProgress(min=0, max=1, step=1, layout=widgets.Layout(width='95%')),\n",
    "        output=widgets.Output(layout={'border': '1px solid black'}),\n",
    "        n_keyterms=widgets.IntSlider(description='#words', min=10, max=500, value=10, step=1, layout=widgets.Layout(width='340px')),\n",
    "        document_id=widgets.Dropdown(description='Treaty', options=document_options, value=document_options[1][1], layout=widgets.Layout(width='40%')),\n",
    "        metric=widgets.Dropdown(description='Metric', options=metric_options, value=Metric.DEGREE_TO_FREQUENCY_RATIO, layout=widgets.Layout(width='300px')),\n",
    "        normalize=widgets.Dropdown(description='Normalize', options=[ 'lemma', 'lower' ], value='lemma', layout=widgets.Layout(width='160px'))\n",
    "    )\n",
    "    \n",
    "    def compute_textacy_rake(corpus, treaty_id, language, normalize, n_keyterms, metric):\n",
    "        gui.output.clear_output()\n",
    "        with gui.output:\n",
    "            doc = textacy_utility.get_treaty_doc(corpus, treaty_id)\n",
    "            phrases = textacy_rake(doc, language=language, normalize=normalize, n_keyterms=n_keyterms, stopwords=None, metric=metric)\n",
    "            df = pd.DataFrame(phrases, columns=['phrase', 'score'])\n",
    "            display(df.set_index('phrase'))\n",
    "            return df\n",
    "    \n",
    "    itw = widgets.interactive(\n",
    "        compute_textacy_rake,\n",
    "        corpus=widgets.fixed(corpus),\n",
    "        treaty_id=gui.document_id,\n",
    "        language=widgets.fixed(language),\n",
    "        normalize=gui.normalize,\n",
    "        n_keyterms=gui.n_keyterms,\n",
    "        metric=gui.metric\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        gui.progress,\n",
    "        widgets.HBox([gui.document_id, gui.metric, gui.normalize]),\n",
    "        widgets.HBox([gui.n_keyterms]),\n",
    "        gui.output\n",
    "    ]))\n",
    "\n",
    "    itw.update()\n",
    "\n",
    "try:\n",
    "    corpus = get_current_corpus().textacy_corpus\n",
    "    display_rake_gui(corpus, language='english')\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color: green'>PREPARE/DESCRIBE </span>TextRank/SingleRank <span style='float: right; color: green'>OPTIONAL</span>\n",
    "\n",
    "https://github.com/JRC1995/TextRank-Keyword-Extraction\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed96883b9ed42ee9eecde3c252f0cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, layout=Layout(width='95%'), max=1), HBox(children=(Dropdown(description='T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gui_utility\n",
    "import textacy_corpus_utility as textacy_utility\n",
    "\n",
    "def display_document_key_terms_gui(corpus, wti_index):\n",
    "    \n",
    "    methods = { 'RAKE': textacy_rake, 'SingleRank': textacy.keyterms.singlerank, 'TextRank': textacy.keyterms.textrank }\n",
    "    document_options = [('All Treaties', None)] + gui_utility.get_treaty_dropdown_options(wti_index, corpus)\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        progress=widgets.IntProgress(min=0, max=1, step=1, layout=widgets.Layout(width='95%')),\n",
    "        output=widgets.Output(layout={'border': '1px solid black'}),\n",
    "        n_keyterms=widgets.IntSlider(description='#words', min=10, max=500, value=100, step=1, layout=widgets.Layout(width='240px')),\n",
    "        document_id=widgets.Dropdown(description='Treaty', options=document_options, value=document_options[1][1], layout=widgets.Layout(width='40%')),\n",
    "        method=widgets.Dropdown(description='Algorithm', options=[ 'RAKE', 'TextRank', 'SingleRank' ], value='TextRank', layout=widgets.Layout(width='180px')),\n",
    "        normalize=widgets.Dropdown(description='Normalize', options=[ 'lemma', 'lower' ], value='lemma', layout=widgets.Layout(width='160px'))\n",
    "    )\n",
    "    \n",
    "    def get_keyterms(method, doc, normalize, n_keyterms):\n",
    "        keyterms = methods[method](doc, normalize=normalize, n_keyterms=n_keyterms)\n",
    "        terms = ', '.join([ x for x, y in keyterms ])\n",
    "        gui.progress.value += 1\n",
    "        return terms\n",
    "    \n",
    "    def get_document_key_terms(corpus, method='TextRank', document_id=None, normalize='lemma', n_keyterms=10):\n",
    "        treaty_ids = [ document_id ] if document_id is not None else [ doc.metadata['treaty_id'] for doc in corpus ]\n",
    "        gui.progress.value = 0\n",
    "        gui.progress.max = len(treaty_ids)\n",
    "        keyterms = [\n",
    "            get_keyterms(method, textacy_utility.get_treaty_doc(corpus, treaty_id), normalize, n_keyterms) for treaty_id in treaty_ids\n",
    "        ]\n",
    "        df = pd.DataFrame({ 'treaty_id': treaty_ids, 'keyterms': keyterms}).set_index('treaty_id')\n",
    "        gui.progress.value = 0\n",
    "        return df\n",
    "\n",
    "    def display_document_key_terms(corpus, method='TextRank', document_id=None, normalize='lemma', n_keyterms=10):\n",
    "        gui.output.clear_output()\n",
    "        with gui.output:\n",
    "            df = get_document_key_terms(corpus, method, document_id, normalize, n_keyterms)\n",
    "            #qgrid_widget = qgrid.show_grid(df, show_toolbar=False)\n",
    "            #display(qgrid_widget)\n",
    "            table = TableDisplay(df)\n",
    "            display(table)\n",
    "            \n",
    "    itw = widgets.interactive(\n",
    "        display_document_key_terms,\n",
    "        corpus=widgets.fixed(corpus),\n",
    "        method=gui.method,\n",
    "        document_id=gui.document_id,\n",
    "        normalize=gui.normalize,\n",
    "        n_keyterms=gui.n_keyterms,\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        gui.progress,\n",
    "        widgets.HBox([gui.document_id, gui.method, gui.normalize, gui.n_keyterms]),\n",
    "        gui.output\n",
    "    ]))\n",
    "\n",
    "    itw.update()\n",
    "\n",
    "display_document_key_terms_gui(CURRENT_CORPUS.textacy_corpus, WTI_INDEX)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>PREPARE/DESCRIBE </span> Clean Up the Text <span style='float: right; color: green'>TRY IT</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234a79a26bbd4c1cb83cebc6444d63a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, layout=Layout(width='90%'), max=5), HBox(children=(VBox(children=(Dropdown…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gui_utility\n",
    "import textacy_corpus_utility as textacy_utility\n",
    "\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches':'tight'}\n",
    "\n",
    "def plot_xy_data(data, title='', xlabel='', ylabel='', **kwargs):\n",
    "    x, y = list(data[0]), list(data[1])\n",
    "    labels = x\n",
    "    plt.figure(figsize=(8, 9 / 1.618))\n",
    "    plt.plot(x, y, 'ro', **kwargs)\n",
    "    plt.xticks(x, labels, rotation='75')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "    \n",
    "def display_cleaned_up_text(container, gui, display_type, treaty_id, **kwargs): # ngrams, named_entities, normalize, include_pos):\n",
    "    \n",
    "    corpus = container.textacy_corpus\n",
    "    \n",
    "    gui.output_text.clear_output()\n",
    "    gui.output_statistics.clear_output()\n",
    "    \n",
    "    doc = textacy_utility.get_treaty_doc(corpus, treaty_id)\n",
    "    \n",
    "    if doc is None:\n",
    "        return\n",
    "    \n",
    "    terms = [ x for x in doc.to_terms_list(as_strings=True, **kwargs) ]\n",
    "    \n",
    "    if display_type.startswith('source_text'):\n",
    "        \n",
    "        source_files = {\n",
    "            'source_text_raw': { 'filename': container.source_path, 'description': 'Raw text from PDF: Automatic text extraction using pdfminer Python package. ' },\n",
    "            'source_text_edited': { 'filename': container.source_path, 'description': 'Manually edited text: List of references, index, notes and page headers etc. removed.' },\n",
    "            'source_text_preprocessed': { 'filename': container.prepped_source_path, 'description': 'Preprocessed text: Normalized whitespaces. Unicode fixes. Urls, emails and phonenumbers removed. Accents removed.' }\n",
    "        }        \n",
    "        \n",
    "        source_filename = source_files[display_type]['filename']\n",
    "        description =  source_files[display_type]['description']\n",
    "        text = utility.zip_get_text(source_filename, doc.metadata['filename'])\n",
    "        \n",
    "        with gui.output_text:\n",
    "            #print('{}\\n.................\\n(NOT SHOWN TEXT)\\n.................\\n{}'.format(document[:2500], document[-250:]))\n",
    "            #print(doc)\n",
    "            print('[ ' + description.upper() + ' ]')\n",
    "            print(text)\n",
    "        return\n",
    "\n",
    "    if len(terms) == 0:\n",
    "        with gui.output_text:\n",
    "            print(\"No text. Please change selection.\")\n",
    "        return\n",
    "    \n",
    "    if display_type in ['sanitized_text', 'statistics']:\n",
    "\n",
    "        if display_type == 'sanitized_text':\n",
    "            with gui.output_text:\n",
    "                #display('{}\\n.................\\n(NOT SHOWN TEXT)\\n.................\\n{}'.format(\n",
    "                #    ' '.join(tokens[:word_count]),\n",
    "                #    ' '.join(tokens[-word_count:])\n",
    "                #))\n",
    "                print(' '.join([ t.replace(' ', '_') for t in terms ]))\n",
    "                return\n",
    "\n",
    "        if display_type == 'statistics':\n",
    "\n",
    "            wf = nltk.FreqDist(terms)\n",
    "\n",
    "            with gui.output_text:\n",
    "\n",
    "                df = pd.DataFrame(wf.most_common(25), columns=['token','count'])\n",
    "                print('Token count: {} Vocab count: {}'.format(wf.N(), wf.B()))\n",
    "                display(df)\n",
    " \n",
    "            with gui.output_statistics:\n",
    "\n",
    "                data = list(zip(*wf.most_common(25)))\n",
    "                plot_xy_data(data, title='Word distribution', xlabel='Word', ylabel='Word count')\n",
    "\n",
    "                wf = nltk.FreqDist([len(x) for x in terms])\n",
    "                data = list(zip(*wf.most_common(25)))\n",
    "                plot_xy_data(data, title='Word length distribution', xlabel='Word length', ylabel='Word count')\n",
    "\n",
    "def display_cleanup_text_gui(container, wti_index):\n",
    "    \n",
    "    corpus = container.textacy_corpus\n",
    "    document_options = [('All Treaties', None)] + gui_utility.get_treaty_dropdown_options(wti_index, corpus)\n",
    "    \n",
    "    #pos_options = [ x for x in DF_TAGSET.POS.unique() if x not in ['PUNCT', '', 'DET', 'X', 'SPACE', 'PART', 'CONJ', 'SYM', 'INTJ', 'PRON']]  # groupby(['POS'])['DESCRIPTION'].apply(list).apply(lambda x: ', '.join(x)).to_dict()\n",
    "    pos_tags = DF_TAGSET.groupby(['POS'])['DESCRIPTION'].apply(list).apply(lambda x: ', '.join(x[:1])).to_dict()\n",
    "    pos_options = [('(All)', None)] + sorted([(k + ' (' + v + ')', k) for k,v in pos_tags.items() ])\n",
    "    display_options = {\n",
    "        'Source text (raw)': 'source_text_raw',\n",
    "        'Source text (edited)': 'source_text_edited',\n",
    "        'Source text (processed)': 'source_text_preprocessed',\n",
    "        'Sanitized text': 'sanitized_text',\n",
    "        'Statistics': 'statistics'\n",
    "    }\n",
    "    ngrams_options = { '1': [1], '1,2': [1,2], '1,2,3': [1,2,3]}\n",
    "    gui = types.SimpleNamespace(\n",
    "        treaty_id=widgets.Dropdown(description='Treaty', options=document_options, value=None, layout=widgets.Layout(width='400px')),\n",
    "        progress=widgets.IntProgress(value=0, min=0, max=5, step=1, description='', layout=widgets.Layout(width='90%')),\n",
    "        min_freq=widgets.FloatSlider(value=0, min=0, max=1.0, step=0.01, description='Min frequency', layout=widgets.Layout(width='400px')),\n",
    "        ngrams=widgets.Dropdown(description='n-grams', options=ngrams_options, value=[1], layout=widgets.Layout(width='180px')),\n",
    "        min_word=widgets.Dropdown(description='Min length', options=[1,2,3,4], value=1, layout=widgets.Layout(width='180px')),\n",
    "        normalize=widgets.Dropdown(description='Normalize', options=[ False, 'lemma', 'lower' ], value=False, layout=widgets.Layout(width='180px')),\n",
    "        filter_stops=widgets.ToggleButton(value=False, description='Filter stops',  tooltip='Filter out stopwords', icon='check'),\n",
    "        filter_nums=widgets.ToggleButton(value=False, description='Filter nums',  tooltip='Filter out stopwords', icon='check'),\n",
    "        filter_punct=widgets.ToggleButton(value=False, description='Filter punct',  tooltip='Filter out punctuations', icon='check'),\n",
    "        named_entities=widgets.ToggleButton(value=False, description='Merge entities',  tooltip='Merge entities', icon='check'),\n",
    "        drop_determiners=widgets.ToggleButton(value=False, description='Drop determiners',  tooltip='Drop determiners', icon='check'),\n",
    "        include_pos=widgets.SelectMultiple(description='POS', options=pos_options, value=list(), rows=10, layout=widgets.Layout(width='400px')),\n",
    "        display_type=widgets.Dropdown(description='Show', value='statistics', options=display_options, layout=widgets.Layout(width='180px')),\n",
    "        output_text=widgets.Output(layout={'height': '500px'}),\n",
    "        output_statistics = widgets.Output(),\n",
    "        boxes=None\n",
    "    )\n",
    "    \n",
    "    uix = widgets.interactive(\n",
    "\n",
    "        display_cleaned_up_text,\n",
    "\n",
    "        container=widgets.fixed(container),\n",
    "        gui=widgets.fixed(gui),\n",
    "        display_type=gui.display_type,\n",
    "        treaty_id=gui.treaty_id,\n",
    "        \n",
    "        ngrams=gui.ngrams,\n",
    "        named_entities=gui.named_entities,\n",
    "        normalize=gui.normalize,\n",
    "        filter_stops=gui.filter_stops,\n",
    "        filter_punct=gui.filter_punct,\n",
    "        filter_nums=gui.filter_nums,\n",
    "        include_pos=gui.include_pos,\n",
    "        min_freq=gui.min_freq,\n",
    "        drop_determiners=gui.drop_determiners\n",
    "    )\n",
    "    \n",
    "    gui.boxes = widgets.VBox([\n",
    "        gui.progress,\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([\n",
    "                gui.treaty_id,\n",
    "                widgets.HBox([gui.display_type, gui.normalize]),\n",
    "                widgets.HBox([gui.ngrams, gui.min_word]),\n",
    "                gui.min_freq\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                gui.include_pos\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                gui.filter_stops,\n",
    "                gui.filter_nums,\n",
    "                gui.filter_punct,\n",
    "                gui.named_entities,\n",
    "                gui.drop_determiners\n",
    "            ])\n",
    "        ]),\n",
    "        widgets.HBox([\n",
    "            gui.output_text, gui.output_statistics\n",
    "        ]),\n",
    "        uix.children[-1]\n",
    "    ])\n",
    "    \n",
    "    display(gui.boxes)\n",
    "                                  \n",
    "    uix.update()\n",
    "    return gui, uix\n",
    "\n",
    "try:\n",
    "    xgui, xuix = display_cleanup_text_gui(get_current_corpus(), WTI_INDEX)\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: green;'>DESCRIBE</span> Most Discriminating Terms<span style='color: blue; float: right'>OPTIONAL</span>\n",
    "References\n",
    "King, Gary, Patrick Lam, and Margaret Roberts. “Computer-Assisted Keyword and Document Set Discovery from Unstructured Text.” (2014). http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.458.1445&rep=rep1&type=pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7c44ed477a4979bbd3d8f1744a27a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(SelectMultiple(description='Group 1', layout=Layout(width='250px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "def compute_most_discriminating_terms(\n",
    "    wti_index,\n",
    "    corpus,\n",
    "    gui,\n",
    "    group1=None,\n",
    "    group2=None,\n",
    "    top_n_terms=25,\n",
    "    max_n_terms=1000,\n",
    "    include_pos=None,\n",
    "    period1=None,\n",
    "    period2=None,\n",
    "    closed_region=False,\n",
    "    normalize=spacy.attrs.LEMMA\n",
    "):\n",
    "    def get_token_attr(token, feature):\n",
    "        if feature == spacy.attrs.LEMMA:\n",
    "            return token.lemma_\n",
    "        if feature == spacy.attrs.LOWER:\n",
    "            return token.lower_\n",
    "        return token.orth_\n",
    "    \n",
    "    def get_term_list(corpus, region=None, period=None, closed_region=False):\n",
    "        \n",
    "        region = set(region or [])\n",
    "        docs = ( x for x in corpus )\n",
    "        \n",
    "        if len(region) > 0:\n",
    "            if closed_region:\n",
    "                docs = ( x for x in docs if (x.metadata['party1'] in region or x.metadata['party2'] in region) )\n",
    "            else:\n",
    "                docs = ( x for x in docs if (x.metadata['party1'] in region and x.metadata['party2'] in region) )\n",
    "\n",
    "        if period is not None:\n",
    "            docs = (x for x in docs if (period[0] <= x.metadata['signed_year']) and (x.metadata['signed_year'] <= period[1]))\n",
    "        \n",
    "        return [[ get_token_attr(x, normalize) for x in doc if x.pos_ in include_pos and len(x) > 1 ] for doc in docs]\n",
    "        \n",
    "    docs1 = get_term_list(corpus, group1, period1, closed_region)\n",
    "    docs2 = get_term_list(corpus, group2, period2, closed_region)\n",
    "    \n",
    "    docs = docs1 + docs2\n",
    "    \n",
    "    in_group1 = [True] * len(docs1) + [False] * len(docs2)   \n",
    "    \n",
    "    terms = textacy.keyterms.most_discriminating_terms(docs, in_group1, top_n_terms=top_n_terms, max_n_terms=max_n_terms)\n",
    "    min_terms = min(len(terms[0]), len(terms[1]))\n",
    "    df = pd.DataFrame({'Group 1': terms[0][:min_terms], 'Group 2': terms[1][:min_terms] })\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def display_most_discriminating_terms(gui, df):\n",
    "    display(df)\n",
    "        \n",
    "def most_discriminating_terms_gui(wti_index, corpus, compute_callback, display_callback):\n",
    "    \n",
    "    lw = lambda w: widgets.Layout(width=w)   \n",
    "    \n",
    "    include_pos_tags = [ 'ADJ', 'VERB', 'NUM', 'ADV', 'NOUN', 'PROPN' ]\n",
    "    normalize_options = { 'Lemma': spacy.attrs.LEMMA, 'Lower': spacy.attrs.LOWER, 'Orth': spacy.attrs.ORTH }\n",
    "    party_preset_options = wti_index.get_party_preset_options()\n",
    "    parties_options = [ x for x in wti_index.get_countries_list() if x != 'ALL OTHER' ]\n",
    "    \n",
    "    signed_years = { d.metadata['signed_year'] for d in corpus }\n",
    "    period_default = (min(signed_years), max(signed_years))\n",
    "\n",
    "    gui = types.SimpleNamespace(\n",
    "        progress=widgets.IntProgress(value=0, min=0, max=5, step=1, description='', layout=lw('90%')),\n",
    "        group1=widgets.SelectMultiple(description='Group 1', options=parties_options, value=[], rows=7, layout=lw('250px')),\n",
    "        group2=widgets.SelectMultiple(description='Group 2', options=parties_options, value=[], rows=7, layout=lw('250px')),\n",
    "        group1_preset=widgets_config.dropdown('Presets', party_preset_options, None, layout=lw('250px')),\n",
    "        group2_preset=widgets_config.dropdown('Presets', party_preset_options, None, layout=lw('250px')),\n",
    "        top_n_terms=widgets.IntSlider(description='#terms', min=10, max=1000, value=100, tooltip='The total number of most discriminating terms to return for each group'),\n",
    "        max_n_terms=widgets.IntSlider(description='#top', min=1, max=2000, value=2000, tooltip='Only consider terms whose document frequency is within the top # terms out of all terms'),\n",
    "        include_pos=widgets.SelectMultiple(description='POS', options=include_pos_tags, value=include_pos_tags, rows=7, layout=lw('150px')),\n",
    "        period1=widgets.IntRangeSlider(description='Period', min=period_default[0], max=period_default[1], value=period_default, layout=lw('250px')),\n",
    "        period2=widgets.IntRangeSlider(description='Period', min=period_default[0], max=period_default[1], value=period_default, layout=lw('250px')),\n",
    "        closed_region=widgets.ToggleButton(description='Closed regions', icon='check', value=True, disabled=False, layout=lw('140px')),\n",
    "        sync_period=widgets.ToggleButton(description='Sync period', icon='check', value=False, disabled=False, layout=lw('140px'), tooltop='HEJ'),\n",
    "        normalize=widgets.Dropdown(description='Normalize', options=normalize_options, value=spacy.attrs.LEMMA, layout=lw('200px')),\n",
    "        compute=widgets.Button(description='Compute', icon='', button_style='Success', layout=lw('120px')),\n",
    "        output=widgets.Output(layout={'border': '1px solid black'})\n",
    "    )\n",
    "    \n",
    "    boxes = widgets.VBox([\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([\n",
    "                gui.group1,\n",
    "                gui.group1_preset,\n",
    "                gui.period1\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                gui.group2,\n",
    "                gui.group2_preset,\n",
    "                gui.period2\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                gui.include_pos,\n",
    "                gui.closed_region,\n",
    "                gui.sync_period,\n",
    "            ], layout=widgets.Layout(align_items='flex-end')),\n",
    "            widgets.VBox([\n",
    "                gui.top_n_terms,\n",
    "                gui.max_n_terms,\n",
    "                gui.normalize\n",
    "            ]), # layout=widgets.Layout(align_items='flex-end')),\n",
    "            widgets.VBox([\n",
    "                gui.compute,\n",
    "                widgets.HTML(\n",
    "                    '<b>#terms</b> is the  number of most discriminating<br>terms to return for each group.<br>' +\n",
    "                    '<b>#top</b> Consider only terms with a frequency<br>within the top #top terms out of all terms<br>'\n",
    "                    '<b>Closed region</b> If checked, then <u>both</u> treaty parties<br>must be within selected region'\n",
    "                )\n",
    "            ])\n",
    "        ]),\n",
    "        gui.output\n",
    "    ])\n",
    "    \n",
    "    display(boxes)\n",
    "    \n",
    "    def on_group1_preset_change(change):\n",
    "        if gui.group1_preset.value is None:\n",
    "            return\n",
    "        gui.group1.value = gui.group1.options if 'ALL' in gui.group1_preset.value else gui.group1_preset.value   \n",
    "    \n",
    "    def on_group2_preset_change(change):\n",
    "        if gui.group2_preset.value is None:\n",
    "            return\n",
    "        gui.group2.value = gui.group2.options if 'ALL' in gui.group2_preset.value else gui.group2_preset.value\n",
    "        \n",
    "    def on_period1_change(change):\n",
    "        if gui.sync_period.value:\n",
    "            gui.period2.value = gui.period1.value\n",
    "            \n",
    "    def on_period2_change(change):\n",
    "        if gui.sync_period.value:\n",
    "            gui.period1.value = gui.period2.value\n",
    "            \n",
    "    gui.group1_preset.observe(on_group1_preset_change, names='value') \n",
    "    gui.group2_preset.observe(on_group2_preset_change, names='value')\n",
    "    \n",
    "    gui.period1.observe(on_period1_change, names='value')\n",
    "    gui.period2.observe(on_period2_change, names='value')\n",
    "    \n",
    "    def compute_callback_handler(*_args):\n",
    "        gui.output.clear_output()\n",
    "        with gui.output:\n",
    "            try:\n",
    "                gui.compute.disabled = True\n",
    "                df = compute_callback(\n",
    "                    wti_index=wti_index,\n",
    "                    corpus=corpus,\n",
    "                    gui=gui,\n",
    "                    group1=gui.group1.value,\n",
    "                    group2=gui.group2.value,\n",
    "                    top_n_terms=gui.top_n_terms.value,\n",
    "                    max_n_terms=gui.max_n_terms.value,\n",
    "                    include_pos=gui.include_pos.value,\n",
    "                    period1=gui.period1.value,\n",
    "                    period2=gui.period2.value,\n",
    "                    closed_region=gui.closed_region.value,\n",
    "                    normalize=gui.normalize.value\n",
    "                )\n",
    "                display_callback(gui, df)\n",
    "            finally:\n",
    "                gui.compute.disabled = False\n",
    "                \n",
    "    gui.compute.on_click(compute_callback_handler)\n",
    "    return gui\n",
    "                \n",
    "try:\n",
    "    most_discriminating_terms_gui(\n",
    "        WTI_INDEX,\n",
    "        get_current_corpus().textacy_corpus,\n",
    "        compute_callback=compute_most_discriminating_terms,\n",
    "        display_callback=display_most_discriminating_terms\n",
    "    )\n",
    "except Exception as ex:\n",
    "    raise\n",
    "    logger.error(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>DESCRIBE</span> Corpus Statistics<span style='color: blue; float: right'>OPTIONAL</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: green;'>DESCRIBE</span> List of Most Frequent Words<span style='color: blue; float: right'>OPTIONAL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27351223ddd146b58169c0cf440384e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, layout=Layout(width='90%'), max=5), HBox(children=(VBox(children=(Dropdown…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "ADDITIONAL_STOPWORDS = []\n",
    "\n",
    "def compute_list_of_most_frequent_words(\n",
    "    corpus,\n",
    "    gui,\n",
    "    group_by_column='signed_year',\n",
    "    parties=None,\n",
    "    target='lemma',\n",
    "    weighting='count',\n",
    "    include_pos=None,\n",
    "    stop_words=None,\n",
    "    display_score=False\n",
    "):\n",
    "    stop_words = stop_words or set()\n",
    "    \n",
    "    def include(token):\n",
    "        flag = True\n",
    "        if not include_pos is None:\n",
    "             flag = flag and token.pos_ in include_pos\n",
    "        flag = flag and token.lemma_ not in stop_words\n",
    "        return flag\n",
    "    \n",
    "    gui.progress.max = len(corpus)\n",
    "    \n",
    "    df_freqs = pd.DataFrame({ 'treaty_id': [], 'signed_year': [], 'token': [], 'score': [] })\n",
    "    \n",
    "    parties_set = set(parties or [])\n",
    "    \n",
    "    docs = corpus if len(parties_set) == 0 \\\n",
    "        else ( x for x in corpus if len(set((x.metadata['party1'], x.metadata['party2'])) & parties_set) > 0 )\n",
    "                                                   \n",
    "    for doc in docs:\n",
    "        \n",
    "        doc_freqs = textacy_utility.textacy_doc_to_bow(doc, target=target, weighting=weighting, as_strings=True, include=include)\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'treaty_id': doc.metadata['treaty_id'],\n",
    "            'signed_year': int(doc.metadata['signed_year']),\n",
    "            'token': list(doc_freqs.keys()),\n",
    "            'score': list(doc_freqs.values())\n",
    "        })\n",
    "        \n",
    "        df_freqs = df_freqs.append(df)\n",
    "        gui.progress.value = gui.progress.value + 1\n",
    "        \n",
    "    df_freqs['signed_year'] = df_freqs.signed_year.astype(int)\n",
    "    \n",
    "    for key, group in TREATY_TIME_GROUPINGS.items():\n",
    "        if key in df_freqs.columns:\n",
    "            continue\n",
    "        df_freqs[key] = (group['fx'])(df_freqs)\n",
    "        \n",
    "    df_freqs['term'] = df_freqs.token # if True else df_freqs.token\n",
    "    \n",
    "    df_freqs = df_freqs.groupby([group_by_column, 'term']).sum().reset_index()[[group_by_column, 'term', 'score']]\n",
    "    \n",
    "    if display_score is True:\n",
    "        df_freqs['term'] = df_freqs.term + '*' + (df_freqs.score.apply('{:,.3f}'.format) if weighting == 'freq' else df_freqs.score.astype(str))\n",
    "        \n",
    "    df_freqs['position'] = df_freqs.sort_values(by=[group_by_column, 'score'], ascending=False).groupby([group_by_column]).cumcount() + 1\n",
    "    \n",
    "    gui.progress.value = 0\n",
    "    \n",
    "    return df_freqs\n",
    "    \n",
    "def display_list_of_most_frequent_words(gui, df):\n",
    "    if gui.output_type.value == 'table':\n",
    "        display(df)\n",
    "    elif gui.output_type.value == 'rank':\n",
    "        group_by_column = gui.group_by_column.value\n",
    "        df = df[df.position <= gui.n_tokens.value]\n",
    "        df_unstacked_freqs = df[[group_by_column, 'position', 'term']].set_index([group_by_column, 'position']).unstack()\n",
    "        display(df_unstacked_freqs)\n",
    "    else:\n",
    "        filename = '../data/word_trend_data.xlsx'\n",
    "        df.to_excel(filename)\n",
    "        print('Excel written: ' + filename)\n",
    "        \n",
    "def word_frequency_gui(wti_index, corpus, compute_callback, display_callback):\n",
    "    \n",
    "    lw = lambda w: widgets.Layout(width=w)\n",
    "    \n",
    "    include_pos_tags = [ 'ADJ', 'VERB', 'NUM', 'ADV', 'NOUN', 'PROPN' ]\n",
    "    weighting_options = { 'Count': 'count', 'Frequency': 'freq' }\n",
    "    normalize_options = { '':  False, 'Lemma': 'lemma', 'Lower': 'lower' }\n",
    "    #pos_tags = DF_TAGSET[DF_TAGSET.POS.isin(include_pos_tags)].groupby(['POS'])['DESCRIPTION'].apply(list).apply(lambda x: ', '.join(x[:1])).to_dict()\n",
    "    #pos_options = { k + ' (' + v + ')': k for k,v in pos_tags.items() }\n",
    "    pos_options = include_pos_tags\n",
    "    \n",
    "    counter = collections.Counter(corpus.word_freqs(normalize='lemma', weighting='count', as_strings=True))\n",
    "    default_include_pos = ['NOUN', 'PROPN']\n",
    "    frequent_words = [ x[0] for x in textacy_utility.get_most_frequent_words(corpus, 100, include_pos=default_include_pos) ]\n",
    "\n",
    "    group_by_options = { TREATY_TIME_GROUPINGS[k]['title']: k for k in TREATY_TIME_GROUPINGS }\n",
    "    output_type_options = [ ( 'List', 'table' ), ( 'Rank', 'rank' ), ( 'Excel', 'excel' ), ]\n",
    "    ngrams_options = { '-': None, '1': [1], '1,2': [1,2], '1,2,3': [1,2,3]}\n",
    "    party_preset_options = wti_index.get_party_preset_options()\n",
    "    parties_options = [ x for x in wti_index.get_countries_list() if x != 'ALL OTHER' ]\n",
    "    gui = types.SimpleNamespace(\n",
    "        progress=widgets.IntProgress(value=0, min=0, max=5, step=1, description='', layout=lw('90%')),\n",
    "        parties=widgets.SelectMultiple(description='Parties', options=parties_options, value=[], rows=7, layout=lw('200px')),\n",
    "        party_preset=widgets_config.dropdown('Presets', party_preset_options, None, layout=lw('200px')),\n",
    "        ngrams=widgets.Dropdown(description='n-grams', options=ngrams_options, value=None, layout=lw('200px')),\n",
    "        min_word=widgets.Dropdown(description='Min length', options=[1,2,3,4], value=1, layout=lw('200px')),\n",
    "        normalize=widgets.Dropdown(description='Normalize', options=normalize_options, value='lemma', layout=lw('200px')),\n",
    "        weighting=widgets.Dropdown(description='Weighting', options=weighting_options, value='freq', layout=lw('200px')),\n",
    "        include_pos=widgets.SelectMultiple(description='POS', options=pos_options, value=default_include_pos, rows=7, layout=lw('150px')),\n",
    "        stop_words=widgets.SelectMultiple(description='STOP', options=frequent_words, value=list([]), rows=7, layout=lw('200px')),\n",
    "        group_by_column=widgets.Dropdown(description='Group by', value='signed_year', options=group_by_options, layout=lw('200px')),\n",
    "        output_type=widgets.Dropdown(description='Output', value='rank', options=output_type_options, layout=lw('200px')),\n",
    "        n_tokens=widgets.IntSlider(description='#tokens', value=25, min=3, max=500, layout=lw('250px')),\n",
    "        compute=widgets.Button(description='Compute', button_style='Success', layout=lw('120px')),\n",
    "        display_score=widgets.ToggleButton(description='Display score', icon='check', value=False, layout=lw('120px')),\n",
    "        output=widgets.Output(layout={'border': '1px solid black'})\n",
    "    )\n",
    "    \n",
    "    boxes = widgets.VBox([\n",
    "        gui.progress,\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([\n",
    "                gui.normalize,\n",
    "                gui.ngrams,\n",
    "                gui.weighting,\n",
    "                gui.group_by_column,\n",
    "                gui.output_type,\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                gui.parties,\n",
    "                gui.party_preset,\n",
    "            ]),\n",
    "            gui.include_pos,\n",
    "            gui.stop_words,\n",
    "            widgets.VBox([\n",
    "                gui.n_tokens,\n",
    "                gui.display_score,\n",
    "                gui.compute,\n",
    "            ], layout=widgets.Layout(align_items='flex-end')),\n",
    "        ]),\n",
    "        gui.output\n",
    "    ])\n",
    "    \n",
    "    display(boxes)\n",
    "    \n",
    "    def on_party_preset_change(change):  # pylint: disable=W0613\n",
    "        if gui.party_preset.value is None:\n",
    "            return\n",
    "        gui.parties.value = gui.parties.options if 'ALL' in gui.party_preset.value else gui.party_preset.value\n",
    "            \n",
    "    gui.party_preset.observe(on_party_preset_change, names='value')\n",
    "    \n",
    "    def pos_change_handler(*args):\n",
    "        with gui.output:\n",
    "            gui.compute.disabled = True\n",
    "            selected = set(gui.stop_words.value)\n",
    "            frequent_words = [\n",
    "                x[0] for x in textacy_utility.get_most_frequent_words(\n",
    "                    corpus,\n",
    "                    100,\n",
    "                    normalize=gui.normalize.value,\n",
    "                    include_pos=gui.include_pos.value,\n",
    "                    weighting=gui.weighting.value\n",
    "                )\n",
    "            ]\n",
    "            gui.stop_words.options = frequent_words\n",
    "            selected = selected & set(gui.stop_words.options)\n",
    "            gui.stop_words.value = list(selected)\n",
    "            gui.compute.disabled = False\n",
    "        \n",
    "    gui.include_pos.observe(pos_change_handler, 'value')    \n",
    "    gui.weighting.observe(pos_change_handler, 'value')    \n",
    "    \n",
    "    def compute_callback_handler(*_args):\n",
    "        gui.output.clear_output()\n",
    "        with gui.output:\n",
    "            try:\n",
    "                gui.compute.disabled = True\n",
    "                df_freqs = compute_callback(\n",
    "                    corpus=corpus,\n",
    "                    gui=gui,\n",
    "                    target=gui.normalize.value,\n",
    "                    group_by_column=gui.group_by_column.value,\n",
    "                    parties=gui.parties.value,\n",
    "                    weighting=gui.weighting.value,\n",
    "                    include_pos=gui.include_pos.value,\n",
    "                    stop_words=set(gui.stop_words.value),\n",
    "                    display_score=gui.display_score.value\n",
    "                )\n",
    "                display_callback(gui, df_freqs)\n",
    "            finally:\n",
    "                gui.compute.disabled = False\n",
    "\n",
    "    gui.compute.on_click(compute_callback_handler)\n",
    "    return gui\n",
    "                \n",
    "try:\n",
    "    word_frequency_gui(\n",
    "        WTI_INDEX,\n",
    "        get_current_corpus().textacy_corpus,\n",
    "        compute_callback=compute_list_of_most_frequent_words,\n",
    "        display_callback=display_list_of_most_frequent_words\n",
    "    )\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: green;'>DESCRIBE</span> Corpus and Document Sizes<span style='color: blue; float: right'>OPTIONAL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec141f2477c4b67840f2df3c3421455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='Group by', index=3, layout=Layout(width='20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import attrs\n",
    "%matplotlib inline\n",
    "\n",
    "def compute_corpus_statistics(\n",
    "    data_folder,\n",
    "    wti_index,\n",
    "    container,\n",
    "    gui,\n",
    "    group_by_column='signed_year',\n",
    "    parties=None,\n",
    "    target='lemma',\n",
    "    include_pos=None,\n",
    "    stop_words=None\n",
    "):\n",
    "    \n",
    "    corpus = container.textacy_corpus\n",
    "\n",
    "    value_columns = list(textacy_utility.POS_NAMES) if (len(include_pos or [])) == 0 else list(include_pos)\n",
    "    \n",
    "    documents = textacy_utility.get_corpus_documents(corpus)\n",
    "\n",
    "    if len(parties or []) > 0:\n",
    "        documents = documents[documents.party1.isin(parties)|documents.party2.isin(parties)]\n",
    "\n",
    "    documents['signed_lustrum'] = (documents.signed_year - documents.signed_year.mod(5)).astype(int) \n",
    "    documents['signed_decade'] = (documents.signed_year - documents.signed_year.mod(10)).astype(int)\n",
    "    documents['total'] = documents[value_columns].apply(sum, axis=1)\n",
    "\n",
    "    #documents = documents.groupby(group_by_column).agg(sum) #.reset_index()\n",
    "    aggregates = { x: ['sum'] for x in value_columns }\n",
    "    aggregates['total'] = ['sum', 'mean', 'min', 'max', 'size' ]\n",
    "    #if group_by_column != 'treaty_id':\n",
    "    documents = documents.groupby(group_by_column).agg(aggregates)\n",
    "    documents.columns = [ ('Total, ' + x[1].lower()) if x[0] == 'total' else x[0] for x in documents.columns ]\n",
    "    columns = sorted(value_columns) + sorted([ x for x in documents.columns if x.startswith('Total')])\n",
    "    return documents[columns]\n",
    "        \n",
    "def corpus_statistics_gui(data_folder, wti_index, container, compute_callback, display_callback):\n",
    "    \n",
    "    lw = lambda w: widgets.Layout(width=w)\n",
    "    \n",
    "    corpus = container.textacy_corpus\n",
    "    \n",
    "    include_pos_tags =  list(textacy_utility.POS_NAMES)\n",
    "    pos_options = include_pos_tags\n",
    "    \n",
    "    counter = collections.Counter(corpus.word_freqs(normalize='lemma', weighting='count', as_strings=True))\n",
    "    frequent_words = [ x[0] for x in textacy_utility.get_most_frequent_words(corpus, 100) ]\n",
    "\n",
    "    group_by_options = { TREATY_TIME_GROUPINGS[k]['title']: k for k in TREATY_TIME_GROUPINGS }\n",
    "    # output_type_options = [ ( 'Table', 'table' ), ( 'Pivot', 'pivot' ), ( 'Excel', 'excel' ), ]\n",
    "    ngrams_options = { '1': [1], '1,2': [1,2], '1,2,3': [1,2,3]}\n",
    "    party_preset_options = wti_index.get_party_preset_options()\n",
    "    parties_options = [ x for x in wti_index.get_countries_list() if x != 'ALL OTHER' ]\n",
    "    gui = types.SimpleNamespace(\n",
    "        parties=widgets.SelectMultiple(description='Parties', options=parties_options, value=[], rows=7, layout=lw('180px')),\n",
    "        party_preset=widgets_config.dropdown('Presets', party_preset_options, None, layout=lw('200px')),\n",
    "        target=widgets.Dropdown(description='Normalize', options={ '':  False, 'Lemma': 'lemma', 'Lower': 'lower' }, value='lemma', layout=lw('200px')),\n",
    "        include_pos=widgets.SelectMultiple(description='POS', options=pos_options, value=list([]), rows=7, layout=widgets.Layout(width='180px')),\n",
    "        group_by_column=widgets.Dropdown(description='Group by', value='signed_year', options=group_by_options, layout=lw('200px')),\n",
    "        #output_type=widgets.Dropdown(description='Output', value='table', options=output_type_options, layout=widgets.Layout(width='200px')),\n",
    "        compute=widgets.Button(description='Compute', layout=lw('120px')),\n",
    "        output=widgets.Output(layout={'border': '1px solid black'})\n",
    "    )\n",
    "    \n",
    "    boxes = widgets.VBox([\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([\n",
    "                gui.group_by_column,\n",
    "                #gui.output_type,\n",
    "                gui.party_preset,\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                gui.parties,\n",
    "            ]),\n",
    "            gui.include_pos,\n",
    "            widgets.VBox([\n",
    "                gui.compute\n",
    "            ]),\n",
    "        ]),\n",
    "        gui.output\n",
    "    ])\n",
    "    \n",
    "    display(boxes)\n",
    "    \n",
    "    def on_party_preset_change(change):  # pylint: disable=W0613\n",
    "        if gui.party_preset.value is None:\n",
    "            return\n",
    "        gui.parties.value = gui.parties.options if 'ALL' in gui.party_preset.value else gui.party_preset.value\n",
    "            \n",
    "    gui.party_preset.observe(on_party_preset_change, names='value')\n",
    "\n",
    "    def compute_callback_handler(*_args):\n",
    "        gui.output.clear_output()\n",
    "        with gui.output:\n",
    "            df_freqs = compute_callback(\n",
    "                data_folder=data_folder,\n",
    "                wti_index=wti_index,\n",
    "                container=container,\n",
    "                gui=gui,\n",
    "                target=gui.target.value,\n",
    "                group_by_column=gui.group_by_column.value,\n",
    "                parties=gui.parties.value,\n",
    "                include_pos=gui.include_pos.value,\n",
    "            )\n",
    "            display_callback(gui, df_freqs)\n",
    "\n",
    "    gui.compute.on_click(compute_callback_handler)\n",
    "    return gui\n",
    "\n",
    "def plot_simple(xs, ys, **figopts):\n",
    "    source = bokeh.models.ColumnDataSource(dict(x=xs, y=ys))\n",
    "    figopts = utility.extend(dict(title='', toolbar_location=\"right\"), figopts)\n",
    "    p = bokeh.plotting.figure(**figopts)\n",
    "    glyph = p.line(source=source, x='x', y='y', line_color=\"#b3de69\")\n",
    "    return p\n",
    "\n",
    "def display_corpus_statistics(gui, df):\n",
    "    display(df)\n",
    "    #with gui.output:\n",
    "    #    plotopts=dict(plot_width=1000, plot_height=500, title='', tools='box_zoom,wheel_zoom,pan,reset')\n",
    "    #    p = plot_simple(X.index, X['Total, mean'], **plotopts)\n",
    "    #    bokeh.plotting.show(p)\n",
    "\n",
    "try:\n",
    "    gui = corpus_statistics_gui(DATA_FOLDER, WTI_INDEX, get_current_corpus(), compute_callback=compute_corpus_statistics, display_callback=display_corpus_statistics)\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>MODEL</span> Display Named Entities<span style='color: green; float: right'>SKIP</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8629b92f5e4f1f893817f2713ec6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Treaty', index=1, layout=Layout(width='80%'), options=(('All Treaties', N…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Named Entities\n",
    "import gui_utility\n",
    "import textacy_corpus_utility as textacy_utility\n",
    "from spacy import displacy\n",
    "\n",
    "def display_document_entities_gui(corpus, wti_index):\n",
    "    \n",
    "    def display_document_entities(corpus, treaty_id):\n",
    "        \n",
    "        doc = textacy_utility.get_treaty_doc(corpus, treaty_id)\n",
    "        \n",
    "        displacy.render(doc.spacy_doc, style='ent', jupyter=True)\n",
    "\n",
    "    document_options = [('All Treaties', None)] + gui_utility.get_treaty_dropdown_options(wti_index, corpus)\n",
    "            \n",
    "    treaty_ids = widgets.Dropdown(description='Treaty', options=document_options, value=document_options[1][1], layout=widgets.Layout(width='80%'))\n",
    "\n",
    "    itw = widgets.interactive(\n",
    "        display_document_entities,\n",
    "        corpus=widgets.fixed(corpus),\n",
    "        treaty_id=treaty_ids\n",
    "    )\n",
    "    \n",
    "    display(widgets.VBox([\n",
    "        treaty_ids,\n",
    "        widgets.VBox([itw.children[-1]], layout=widgets.Layout(margin_top='20px', height='500px',width='100%'))\n",
    "    ]))\n",
    "\n",
    "    itw.update()\n",
    "    \n",
    "try:\n",
    "    corpus = get_current_corpus().textacy_corpus\n",
    "    display_document_entities_gui(corpus, WTI_INDEX)\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>MODEL</span> Compute or Load a Topic Model<span style='color: red; float: right'>MANDATORY RUN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: green;'>MODEL</span> Compute a new Topic Model<span style='color: red; float: right'>OPTIONAL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fec47c9408479f81632ddda1a727d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, layout=Layout(width='90%'), max=5), HBox(children=(VBox(children=(IntSlide…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import topic_model_gui\n",
    "\n",
    "try:\n",
    "    TM_GUI_MODEL = topic_model_gui.display_topic_model_gui(get_current_corpus().textacy_corpus, DF_TAGSET)\n",
    "except Exception as ex:\n",
    "    raise\n",
    "    logger.error(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = TM_GUI_MODEL.payload['models']\n",
    "models[0].perplexity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f611221eac8>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame([ {\n",
    "    'n_topics': int(model.tm_model.num_topics),\n",
    "    'perplexity_score': model.perplexity_score,\n",
    "    'coherence_score': model.coherence_score\n",
    "  } for model in models ])\n",
    "df['n_topics'] = df.n_topics.astype(int)\n",
    "df = df.set_index('n_topics')\n",
    "df['coherence_score'].plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: green;'>MODEL</span> Store or Load a Topic Model<span style='color: red; float: right'>OPTIONAL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cd98db88c84c38af5aa453604d11a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Path', layout=Layout(width='40%'), options=('../data/topic…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import topic_model\n",
    "import topic_model_utility\n",
    "\n",
    "def get_persisted_model_paths():\n",
    "    return sorted([ x for x in glob.glob(os.path.join(DATA_FOLDER, '*.pickle')) ])\n",
    "\n",
    "def load_model(gui, model_container, *args):\n",
    "    \n",
    "    gui.output.clear_output()\n",
    "    \n",
    "    with gui.output:\n",
    "       \n",
    "        if gui.stored_path.value is None:\n",
    "            print(\"Please specify which model to load.\")\n",
    "            return\n",
    "\n",
    "        model_container.model = topic_model.load_model(gui.stored_path.value)\n",
    "    \n",
    "        topics = topic_model_utility.get_lda_topics(model_container.model.tm_model, n_tokens=20)\n",
    "        \n",
    "        display(topics)\n",
    "        \n",
    "        print('Model was loaded!')\n",
    "        \n",
    "def store_model(gui, model_container, *args):\n",
    "    \n",
    "    gui.output.clear_output()\n",
    "    \n",
    "    with gui.output:\n",
    "        if gui.identifier.value == '':\n",
    "            print(\"Please specify a unique identifier for the model.\")\n",
    "            return\n",
    "\n",
    "        if gui.identifier.value != utility.filename_whitelist(gui.identifier.value):\n",
    "            print(\"Please use ONLY valid filename characters in identifier.\")\n",
    "            return\n",
    "\n",
    "        filename = os.path.join(DATA_FOLDER, 'topic_model.pickle')\n",
    "        filename = utility.path_add_date(filename)\n",
    "        filename = utility.path_add_suffix(filename, gui.identifier.value)\n",
    "\n",
    "        topic_model.store_model(model_container.model, filename)\n",
    "\n",
    "        gui.stored_path.options = get_persisted_model_paths()\n",
    "        gui.stored_path.value = filename if filename in gui.stored_path.options else None\n",
    "        \n",
    "        print('Model stored in file {}'.format(filename))\n",
    "    \n",
    "def display_persist_topic_model_gui(model_container):\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        stored_path=widgets.Dropdown(description='Path', options=get_persisted_model_paths(), layout=widgets.Layout(width='40%')),\n",
    "        load=widgets.Button(description='Load', button_style='Success', layout=widgets.Layout(width='80px')),\n",
    "        store=widgets.Button(description='Store', button_style='Success', layout=widgets.Layout(width='80px')),\n",
    "        identifier=widgets.Text(description='Identifier', layout=widgets.Layout(width='300px')),\n",
    "        output=widgets.Output()\n",
    "    )\n",
    "    \n",
    "    boxes = widgets.VBox([\n",
    "        widgets.HBox([gui.stored_path, gui.load, gui.store, gui.identifier ]),\n",
    "        widgets.HBox([\n",
    "            widgets.Label(value=\"\", layout=widgets.Layout(width='40%')),\n",
    "            widgets.Label(value=\"Stored models will be named ./data/topic_model_yyyymmdd_$identifier$.pickle\", layout=widgets.Layout(width='40%')),\n",
    "        ]),\n",
    "        widgets.VBox([gui.output])\n",
    "    ])\n",
    "    \n",
    "    fx = lambda *args: load_model(gui, model_container, *args)\n",
    "    gui.load.on_click(fx)\n",
    "\n",
    "    fy = lambda *args: store_model(gui, model_container, *args)\n",
    "    gui.store.on_click(fy)\n",
    "    \n",
    "    display(boxes)\n",
    "\n",
    "if 'TM_GUI_MODEL' not in globals():\n",
    "    TM_GUI_MODEL = types.SimpleNamespace(\n",
    "        model=None\n",
    "    )\n",
    "    \n",
    "display_persist_topic_model_gui(TM_GUI_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic's Word Distribution as a Wordcloud<span style='color: red; float: right'>TRY IT</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba3d053275e4fb3a2ecb49500533248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='tx02'></span>\", placeholder=''), HBox(children=(Button(description='<<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display LDA topic's token wordcloud\n",
    "opts = { 'max_font_size': 100, 'background_color': 'white', 'width': 900, 'height': 600 }\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_wordcloud_gui(callback, tm_data, text_id, output_options=None, word_count=(1, 100, 50)):\n",
    "    model = tm_data.tm_model\n",
    "    output_options = output_options or []\n",
    "    wf = widgets_utility.wf\n",
    "    wc = widgets_utility.WidgetUtility(\n",
    "        n_topics=model.num_topics,\n",
    "        text_id=text_id,\n",
    "        text=wf.create_text_widget(text_id),\n",
    "        topic_id=widgets.IntSlider(\n",
    "            description='Topic ID', min=0, max=model.num_topics - 1, step=1, value=0, continuous_update=False),\n",
    "        word_count=widgets.IntSlider(\n",
    "            description='#Words', min=word_count[0], max=word_count[1], step=1, value=word_count[2], continuous_update=False),\n",
    "        output_format=wf.create_select_widget('Format', output_options, default=output_options[0], layout=widgets.Layout(width=\"200px\")),\n",
    "        progress = widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\"))\n",
    "    )\n",
    "\n",
    "    wc.prev_topic_id = wc.create_prev_id_button('topic_id', model.num_topics)\n",
    "    wc.next_topic_id = wc.create_next_id_button('topic_id', model.num_topics)\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        callback,\n",
    "        tm_data=widgets.fixed(tm_data),\n",
    "        topic_id=wc.topic_id,\n",
    "        n_words=wc.word_count,\n",
    "        output_format=wc.output_format,\n",
    "        widget_container=widgets.fixed(wc)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        wc.text,\n",
    "        widgets.HBox([wc.prev_topic_id, wc.next_topic_id, wc.topic_id, wc.word_count, wc.output_format]),\n",
    "        wc.progress,\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "\n",
    "def plot_wordcloud(df_data, token='token', weight='weight', figsize=(14, 14/1.618), **args):\n",
    "    token_weights = dict({ tuple(x) for x in df_data[[token, weight]].values })\n",
    "    image = wordcloud.WordCloud(**args,)\n",
    "    image.fit_words(token_weights)\n",
    "    plt.figure(figsize=figsize) #, dpi=100)\n",
    "    plt.imshow(image, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def display_wordcloud(\n",
    "    tm_data,\n",
    "    topic_id=0,\n",
    "    n_words=100,\n",
    "    output_format='Wordcloud',\n",
    "    widget_container=None\n",
    "):\n",
    "    container = tm_data.compiled_data\n",
    "    widget_container.progress.value = 1\n",
    "    df_temp = container.topic_token_weights.loc[(container.topic_token_weights.topic_id == topic_id)]\n",
    "    tokens = topic_model_utility.get_topic_title(container.topic_token_weights, topic_id, n_words=n_words)\n",
    "    widget_container.value = 2\n",
    "    widget_container.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "    if output_format == 'Wordcloud':\n",
    "        plot_wordcloud(df_temp, 'token', 'weight', max_words=n_words, **opts)\n",
    "    elif output_format == 'Table':\n",
    "        widget_container.progress.value = 3\n",
    "        df_temp = topic_model_utility.get_topic_tokens(container.topic_token_weights, topic_id=topic_id, n_words=n_words)\n",
    "        widget_container.progress.value = 4\n",
    "        display(HTML(df_temp.to_html()))\n",
    "    widget_container.progress.value = 0\n",
    "\n",
    "try:\n",
    "    tm_data = get_current_model()\n",
    "    display_wordcloud_gui(display_wordcloud, tm_data, 'tx02', ['Wordcloud', 'Table'])\n",
    "except TopicModelNotComputed as ex:\n",
    "    logger.info(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic's Word Distribution as a Chart<span style='color: red; float: right'>TRY IT</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9a9331c3844854b3115b02e59436c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='wc01'></span>\", placeholder=''), HBox(children=(Button(description='<<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display topic's word distribution\n",
    "import numpy as np\n",
    "\n",
    "def plot_topic_word_distribution(tokens, **args):\n",
    "\n",
    "    source = bokeh.models.ColumnDataSource(tokens)\n",
    "\n",
    "    p = bokeh.plotting.figure(toolbar_location=\"right\", **args)\n",
    "\n",
    "    cr = p.circle(x='xs', y='ys', source=source)\n",
    "\n",
    "    label_style = dict(level='overlay', text_font_size='8pt', angle=np.pi/6.0)\n",
    "\n",
    "    text_aligns = ['left', 'right']\n",
    "    for i in [0, 1]:\n",
    "        label_source = bokeh.models.ColumnDataSource(tokens.iloc[i::2])\n",
    "        labels = bokeh.models.LabelSet(x='xs', y='ys', text_align=text_aligns[i], text='token', text_baseline='middle',\n",
    "                          y_offset=5*(1 if i == 0 else -1),\n",
    "                          x_offset=5*(1 if i == 0 else -1),\n",
    "                          source=label_source, **label_style)\n",
    "        p.add_layout(labels)\n",
    "\n",
    "    p.xaxis[0].axis_label = 'Token #'\n",
    "    p.yaxis[0].axis_label = 'Probability%'\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"6pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    return p\n",
    "\n",
    "def display_topic_tokens(tm_data, topic_id=0, n_words=100, output_format='Chart', widget_container=None):\n",
    "    widget_container.forward()\n",
    "    container = tm_data.compiled_data\n",
    "    tokens = topic_model_utility.get_topic_tokens(container.topic_token_weights, topic_id=topic_id).\\\n",
    "        copy()\\\n",
    "        .drop('topic_id', axis=1)\\\n",
    "        .assign(weight=lambda x: 100.0 * x.weight)\\\n",
    "        .sort_values('weight', axis=0, ascending=False)\\\n",
    "        .reset_index()\\\n",
    "        .head(n_words)\n",
    "    if output_format == 'Chart':\n",
    "        widget_container.forward()\n",
    "        tokens = tokens.assign(xs=tokens.index, ys=tokens.weight)\n",
    "        p = plot_topic_word_distribution(tokens, plot_width=1000, plot_height=500, title='', tools='box_zoom,wheel_zoom,pan,reset')\n",
    "        bokeh.plotting.show(p)\n",
    "        widget_container.forward()\n",
    "    elif output_format == 'Table':\n",
    "        #display(tokens)\n",
    "        display(tokens)\n",
    "    else:\n",
    "        display(pivot_ui(tokens))\n",
    "        \n",
    "    # Added code for missing method: widget_container.reset()\n",
    "    if 'progress' in widget_container.__dict__.keys():\n",
    "        widget_container.progress.value = 0\n",
    "    \n",
    "    \n",
    "def display_topic_distribution_widgets(callback, tm_data, text_id, output_options=None, word_count=(1, 100, 50)):\n",
    "    \n",
    "    output_options = output_options or []\n",
    "    model = tm_data.tm_model\n",
    "    wf = widgets_utility.wf\n",
    "    wc = widgets_utility.WidgetUtility(\n",
    "        n_topics=model.num_topics,\n",
    "        text_id=text_id,\n",
    "        text=wf.create_text_widget(text_id),\n",
    "        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=model.num_topics - 1, step=1, value=0),\n",
    "        word_count=widgets.IntSlider(description='#Words', min=word_count[0], max=word_count[1], step=1, value=word_count[2]),\n",
    "        output_format=wf.create_select_widget('Format', output_options, default=output_options[0], layout=widgets.Layout(width=\"200px\")),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\"))\n",
    "    )\n",
    "\n",
    "    wc.prev_topic_id = wc.create_prev_id_button('topic_id', model.num_topics)\n",
    "    wc.next_topic_id = wc.create_next_id_button('topic_id', model.num_topics)\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        callback,\n",
    "        tm_data=widgets.fixed(tm_data),\n",
    "        topic_id=wc.topic_id,\n",
    "        n_words=wc.word_count,\n",
    "        output_format=wc.output_format,\n",
    "        widget_container=widgets.fixed(wc)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        wc.text,\n",
    "        widgets.HBox([wc.prev_topic_id, wc.next_topic_id, wc.topic_id, wc.word_count, wc.output_format]),\n",
    "        wc.progress,\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "\n",
    "display_topic_distribution_widgets(display_topic_tokens, get_current_model(), 'wc01', ['Chart', 'Table'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic's Trend Over Time or Documents<span style='color: red; float: right'>RUN</span>\n",
    "- Displays topic's share over documents.\n",
    "\n",
    "- BUGG? Values > 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cba171b7c74cd7ad6dba8616a05967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='topic_share_plot'></span>\", placeholder=''), HBox(children=(Button(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a topic's yearly weight over time in selected LDA topic model\n",
    "import math\n",
    "\n",
    "def plot_topic_trend(df, category_column, value_column, x_label=None, y_label=None, **figopts):\n",
    "    \n",
    "    xs = df[category_column].astype(np.str)\n",
    "    ys = df[value_column]\n",
    "    \n",
    "    figopts = utility.extend(dict(title='', toolbar_location=\"right\"), figopts)\n",
    "    \n",
    "    p = bokeh.plotting.figure(**figopts)\n",
    "\n",
    "    glyph = p.vbar(x=xs, top=ys, width=0.5, fill_color=\"#b3de69\")\n",
    "    \n",
    "    p.xaxis.major_label_orientation = math.pi/4\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.xaxis[0].axis_label = (x_label or category_column.title().replace('_', ' ')).title()\n",
    "    p.yaxis[0].axis_label = (y_label or value_column.title().replace('_', ' ')).title()\n",
    "    p.y_range.start = 0.0\n",
    "    p.x_range.range_padding = 0.01\n",
    "    \n",
    "    return p\n",
    "\n",
    "def display_topic_trend(\n",
    "    topic_id,\n",
    "    year,\n",
    "    year_aggregate,\n",
    "    gui,\n",
    "    output_format='Chart',\n",
    "    document_topic_weights=None,\n",
    "    topic_token_weights=None,\n",
    "    threshold=0.01\n",
    "):\n",
    "    figopts = dict(plot_width=1000, plot_height=700, title='', toolbar_location=\"right\")\n",
    "\n",
    "    tokens = topic_model_utility.get_topic_title(topic_token_weights, topic_id, n_words=200)\n",
    "    gui.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "    \n",
    "    pivot_column = 'signed_year' if year is None else None\n",
    "    value_column = year_aggregate if year is None else 'weight'\n",
    "\n",
    "    df = document_topic_weights[(document_topic_weights.topic_id == topic_id)]\n",
    "    \n",
    "    if year is not None:\n",
    "        df = df[(df.signed_year == year)]\n",
    "        \n",
    "    df = df[(df.weight > threshold)].reset_index()\n",
    "    \n",
    "    if pivot_column is not None:\n",
    "        df = df.groupby([pivot_column, 'topic_id']).agg([np.mean, np.max])['weight'].reset_index()\n",
    "        df.columns = [pivot_column, 'topic_id', 'mean', 'max']\n",
    "        category_column = pivot_column\n",
    "        min_year = document_topic_weights.signed_year.min()\n",
    "        max_year = document_topic_weights.signed_year.max()\n",
    "        figopts['x_range'] = list(map(str, range(min_year, max_year+1))) # utility.complete_value_range(df[category_column].unique(), str)\n",
    "    else:\n",
    "        df['treaty'] = df.treaty_id + ' ' + df.party1 + ' ' + df.party2\n",
    "        category_column = 'treaty'\n",
    "        figopts['x_range'] = df['treaty'].unique()\n",
    "        \n",
    "    if output_format == 'Table':\n",
    "        display(df)\n",
    "    else:\n",
    "        p = plot_topic_trend(df, category_column, value_column, **figopts)\n",
    "        bokeh.plotting.show(p)\n",
    "\n",
    "def create_topic_trend_widgets(tm_data):\n",
    "    \n",
    "    model = tm_data.tm_model\n",
    "    model_data = tm_data.compiled_data\n",
    "    document_topic_weights = tm_data.compiled_data.document_topic_weights\n",
    "    topic_token_weights = tm_data.compiled_data.topic_token_weights\n",
    "\n",
    "    year_options = [ ('all years', None) ] + [ (x,x) for x in range(model_data.year_period[0], model_data.year_period[1] + 1)]\n",
    "    \n",
    "    element_id = 'topic_share_plot'\n",
    "    gui = widgets_utility.WidgetUtility(\n",
    "        n_topics=model.num_topics,\n",
    "        text_id=element_id,\n",
    "        text=widgets_config.text(dom_id=element_id),\n",
    "        year=widgets.Dropdown(description='Year', options=year_options, value=None),\n",
    "        year_aggregate=widgets.Dropdown(description='Aggregate', options=['mean', 'max'], value='max'),\n",
    "        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=0.25, step=0.01, value=0.10, continuous_update=False),\n",
    "        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=model.num_topics - 1, step=1, value=0, continuous_update=False),\n",
    "        output_format=widgets.Dropdown(description='Format', options=['Chart', 'Table'], value='Chart'),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"50%\")),\n",
    "    )\n",
    "    \n",
    "    gui.prev_topic_id = gui.create_prev_id_button('topic_id', model.num_topics)\n",
    "    gui.next_topic_id = gui.create_next_id_button('topic_id', model.num_topics)\n",
    "    \n",
    "    iw = widgets.interactive(\n",
    "        display_topic_trend,\n",
    "        topic_id=gui.topic_id,\n",
    "        year=gui.year,\n",
    "        year_aggregate=gui.year_aggregate,\n",
    "        gui=widgets.fixed(gui),\n",
    "        output_format=gui.output_format,\n",
    "        document_topic_weights=widgets.fixed(model_data.document_topic_weights),\n",
    "        topic_token_weights=widgets.fixed(model_data.topic_token_weights),\n",
    "        threshold=gui.threshold\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        gui.text,\n",
    "        widgets.HBox([gui.prev_topic_id, gui.next_topic_id, gui.year, gui.year_aggregate, gui.output_format]),\n",
    "        widgets.HBox([gui.topic_id, gui.threshold, gui.progress]),\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "    \n",
    "    iw.update()\n",
    "\n",
    "tm_data = get_current_model()\n",
    "create_topic_trend_widgets(tm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic to Document Network<span style='color: red; float: right'>TRY IT</span>\n",
    "The green nodes are documents, and blue nodes are topics. The edges (lines) indicates the strength of a topic in the connected document. The width of the edge is proportinal to the strength of the connection. Note that only edges with a strength above the certain threshold are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd1503360bc434f9288fc07e2160622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='nx_id1'></span>\", placeholder=''), HBox(children=(VBox(children=(Dropd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize year-to-topic network by means of topic-document-weights\n",
    "from common.plot_utility import layout_algorithms, PlotNetworkUtility\n",
    "from common.network_utility import NetworkUtility, DISTANCE_METRICS, NetworkMetricHelper\n",
    "\n",
    "def plot_document_topic_network(network, layout, scale=1.0, titles=None):\n",
    "    tools = \"pan,wheel_zoom,box_zoom,reset,hover,previewsave\"\n",
    "    year_nodes, topic_nodes = NetworkUtility.get_bipartite_node_set(network, bipartite=0)  \n",
    "    \n",
    "    year_source = NetworkUtility.get_node_subset_source(network, layout, year_nodes)\n",
    "    topic_source = NetworkUtility.get_node_subset_source(network, layout, topic_nodes)\n",
    "    lines_source = NetworkUtility.get_edges_source(network, layout, scale=6.0, normalize=False)\n",
    "    \n",
    "    edges_alphas = NetworkMetricHelper.compute_alpha_vector(lines_source.data['weights'])\n",
    "    \n",
    "    lines_source.add(edges_alphas, 'alphas')\n",
    "    \n",
    "    p = bokeh.plotting.figure(plot_width=1000, plot_height=600, x_axis_type=None, y_axis_type=None, tools=tools)\n",
    "    \n",
    "    r_lines = p.multi_line(\n",
    "        'xs', 'ys', line_width='weights', alpha='alphas', color='black', source=lines_source\n",
    "    )\n",
    "    r_years = p.circle(\n",
    "        'x','y', size=40, source=year_source, color='lightgreen', level='overlay', line_width=1,alpha=1.0\n",
    "    )\n",
    "    \n",
    "    r_topics = p.circle('x','y', size=25, source=topic_source, color='skyblue', level='overlay', alpha=1.00)\n",
    "    \n",
    "    p.add_tools(bokeh.models.HoverTool(renderers=[r_topics], tooltips=None, callback=widgets_utility.wf.\\\n",
    "        glyph_hover_callback(topic_source, 'node_id', text_ids=titles.index, text=titles, element_id='nx_id1'))\n",
    "    )\n",
    "\n",
    "    text_opts = dict(x='x', y='y', text='name', level='overlay', x_offset=0, y_offset=0, text_font_size='8pt')\n",
    "    \n",
    "    p.add_layout(\n",
    "        bokeh.models.LabelSet(\n",
    "            source=year_source, text_color='black', text_align='center', text_baseline='middle', **text_opts\n",
    "        )\n",
    "    )\n",
    "    p.add_layout(\n",
    "        bokeh.models.LabelSet(\n",
    "            source=topic_source, text_color='black', text_align='center', text_baseline='middle', **text_opts\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return p\n",
    "        \n",
    "def display_document_topic_network(layout_algorithm, tm_data, threshold=0.10, parties=None, period=None, ignores=None, scale=1.0, output_format='network', tick=utility.noop):\n",
    "\n",
    "    tick(1)\n",
    "    \n",
    "    container = tm_data.compiled_data\n",
    "    \n",
    "    titles = topic_model_utility.get_topic_titles(container.topic_token_weights)\n",
    "\n",
    "    df = container.document_topic_weights[container.document_topic_weights.weight > threshold].reset_index()\n",
    "\n",
    "    if len(parties or []) > 0:\n",
    "        df = df[df.party1.isin(parties) | df.party2.isin(parties)]\n",
    "\n",
    "    if len(period or []) == 2:\n",
    "        df = df[(df.signed_year>=period[0]) & (df.signed_year<=period[1])]\n",
    "        \n",
    "    if len(ignores or []) > 0:\n",
    "        df = df[~df.topic_id.isin(ignores)]\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print('No data')\n",
    "        return\n",
    "    \n",
    "    df['title'] = df.treaty_id + ' ' + df.party1 + ' ' + df.party2\n",
    "\n",
    "    network = NetworkUtility.create_bipartite_network(df, 'title', 'topic_id')\n",
    "    tick()\n",
    "\n",
    "    if output_format == 'network':\n",
    "        args = PlotNetworkUtility.layout_args(layout_algorithm, network, scale)\n",
    "        layout = (layout_algorithms[layout_algorithm])(network, **args)\n",
    "        tick()\n",
    "        p = plot_document_topic_network(network, layout, scale=scale, titles=titles)\n",
    "        bokeh.plotting.show(p)\n",
    "\n",
    "    elif output_format == 'table':\n",
    "        display(df)\n",
    "\n",
    "    tick(0)\n",
    "        \n",
    "def document_topic_network_gui(wti_index, tm_data):\n",
    "    \n",
    "    lw = lambda w: widgets.Layout(width=w)\n",
    "    \n",
    "    model = tm_data.tm_model\n",
    "    text_id = 'nx_id1'\n",
    "    layout_options = [ 'Circular', 'Kamada-Kawai', 'Fruchterman-Reingold']\n",
    "    party_preset_options = wti_index.get_party_preset_options()\n",
    "    parties_options = [ x for x in wti_index.get_countries_list() if x != 'ALL OTHER' ]\n",
    "    year_min, year_max = tm_data.compiled_data.year_period\n",
    "    \n",
    "    n_topics = tm_data.tm_model.num_topics\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        text=widgets_utility.wf.create_text_widget(text_id),\n",
    "        period=widgets.IntRangeSlider(description='Time', min=year_min, max=year_max, step=1, value=(year_min, year_max), continues_update=False),\n",
    "        scale=widgets.FloatSlider(description='Scale', min=0.0, max=1.0, step=0.01, value=0.1, continues_update=False),\n",
    "        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=1.0, step=0.01, value=0.50, continues_update=False),\n",
    "        output_format=widgets_utility.dropdown('Output', { 'Network': 'network', 'Table': 'table' }, 'network', layout=lw('200px')),\n",
    "        layout=widgets_utility.dropdown('Layout', layout_options, 'Fruchterman-Reingold', layout=lw('250px')),\n",
    "        parties=widgets.SelectMultiple(description='Parties', options=parties_options, value=[], rows=7, layout=lw('180px')),\n",
    "        party_preset=widgets_config.dropdown('Presets', party_preset_options, None, layout=lw('180px')),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"99%\")),\n",
    "        ignores=widgets.SelectMultiple(description='Ignore', options=[('', None)] + [ ('Topic #'+str(i), i) for i in range(0, n_topics) ], value=[], rows=8, layout=lw('180px')),\n",
    "    )\n",
    "    \n",
    "    def tick(x=None):\n",
    "        gui.progress.value = gui.progress.value + 1 if x is None else x\n",
    "        \n",
    "    def on_party_preset_change(change):  # pylint: disable=W0613\n",
    "        if gui.party_preset.value is None:\n",
    "            return\n",
    "        gui.parties.value = gui.parties.options if 'ALL' in gui.party_preset.value else gui.party_preset.value\n",
    "            \n",
    "    gui.party_preset.observe(on_party_preset_change, names='value')\n",
    "    \n",
    "    iw = widgets.interactive(\n",
    "        display_document_topic_network,\n",
    "        layout_algorithm=gui.layout,\n",
    "        tm_data=widgets.fixed(tm_data),\n",
    "        threshold=gui.threshold,\n",
    "        parties=gui.parties,\n",
    "        period=gui.period,\n",
    "        ignores=gui.ignores,\n",
    "        scale=gui.scale,\n",
    "        output_format=gui.output_format,\n",
    "        tick=widgets.fixed(tick)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        gui.text,\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([gui.layout, gui.threshold, gui.scale, gui.period]), \n",
    "            widgets.VBox([gui.parties, gui.party_preset]), \n",
    "            widgets.VBox([gui.ignores]), \n",
    "            widgets.VBox([gui.output_format, gui.progress]),\n",
    "        ]),\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "    iw.update()\n",
    "\n",
    "try:\n",
    "    tm_data = get_current_model()\n",
    "    document_topic_network_gui(WTI_INDEX, tm_data)\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Topic Trends Overview<span style='color: red; float: right'>TRY IT</span>\n",
    "\n",
    "- The topic shares  displayed as a scattered heatmap plot using gradient color based on topic's weight in document.\n",
    "- [Stanford’s Termite software](http://vis.stanford.edu/papers/termite) uses a similar visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae61fa92b614e1186beffa21263f726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Year', layout=Layout(width='160px'), options=(('all years'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_topic_relevance_by_year\n",
    "import bokeh.transform\n",
    "\n",
    "def isint(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def get_topic_weight_by_year_or_document(document_topic_weights, key='mean', year=None):\n",
    "    pivot_column = 'year' if year is None else 'document_id'\n",
    "    #if df[(df.year == year)]\n",
    "    df = self.get_document_topic_weights(year) \\\n",
    "        .groupby([pivot_column,'topic_id']) \\\n",
    "        .agg(config.AGGREGATES[key])[['weight']].reset_index()\n",
    "    return df, pivot_column\n",
    "    \n",
    "def setup_glyph_coloring(df):\n",
    "    max_weight = df.weight.max()\n",
    "    #colors = list(reversed(bokeh.palettes.Greens[9]))\n",
    "    colors = ['#ffffff', '#f7fcf5', '#e5f5e0', '#c7e9c0', '#a1d99b', '#74c476', '#41ab5d', '#238b45', '#006d2c', '#00441b']\n",
    "    mapper = bokeh.models.LinearColorMapper(palette=colors, low=0.0, high=1.0) # low=df.weight.min(), high=max_weight)\n",
    "    color_transform = bokeh.transform.transform('weight', mapper)\n",
    "    color_bar = bokeh.models.ColorBar(color_mapper=mapper, location=(0, 0),\n",
    "                         ticker=bokeh.models.BasicTicker(desired_num_ticks=len(colors)),\n",
    "                         formatter=bokeh.models.PrintfTickFormatter(format=\" %5.2f\"))\n",
    "    return color_transform, color_bar\n",
    "\n",
    "def compute_int_range_categories(values):\n",
    "    categories = values.unique()\n",
    "    if all(map(utility.isint, categories)):\n",
    "        categories = sorted(list(map(int, categories)))\n",
    "        return list(map(str, categories))\n",
    "    else:\n",
    "        return sorted(list(categories))\n",
    "\n",
    "HEATMAP_FIGOPTS = dict(title=\"Topic heatmap\", toolbar_location=\"right\",  x_axis_location=\"above\", plot_width=1000)\n",
    "\n",
    "def plot_topic_relevance_by_year(df, xs, ys, flip_axis, titles, text_id, **figopts):\n",
    "\n",
    "    line_height = 7\n",
    "    if flip_axis is True:\n",
    "        xs, ys = ys, xs\n",
    "        line_height = 10\n",
    "\n",
    "    x_range = compute_int_range_categories(df[xs])\n",
    "    y_range = compute_int_range_categories(df[ys])\n",
    "    \n",
    "    color_transform, color_bar = setup_glyph_coloring(df)\n",
    "    \n",
    "    source = bokeh.models.ColumnDataSource(df)\n",
    "\n",
    "    if x_range is not None:\n",
    "        figopts['x_range'] = x_range\n",
    "\n",
    "    if y_range is not None:\n",
    "        figopts['y_range'] = y_range\n",
    "        figopts['plot_height'] = max(len(y_range) * line_height, 500)\n",
    "    \n",
    "    p = bokeh.plotting.figure(**figopts)\n",
    "\n",
    "    args = dict(x=xs, y=ys, source=source, alpha=1.0, hover_color='red')\n",
    "    \n",
    "    cr = p.rect(width=1, height=1, line_color=None, fill_color=color_transform, **args)\n",
    "\n",
    "    p.x_range.range_padding = 0\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"8pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    p.xaxis.major_label_orientation = 1.0\n",
    "    p.add_layout(color_bar, 'right')\n",
    "    \n",
    "    p.add_tools(bokeh.models.HoverTool(tooltips=None, callback=widgets_utility.WidgetUtility.glyph_hover_callback(\n",
    "        source, 'topic_id', titles.index, titles, text_id), renderers=[cr]))\n",
    "    \n",
    "    return p\n",
    "\n",
    "def display_doc_topic_heatmap(model_data, key='max', flip_axis=False, glyph='Circle', year=None, year_aggregate=None, output_format=None):\n",
    "    try:\n",
    "\n",
    "        titles = topic_model_utility.get_topic_titles(model_data.topic_token_weights, n_words=100)\n",
    "        \n",
    "        df = model_data.document_topic_weights.copy()\n",
    "\n",
    "        if year is not None:\n",
    "            df = df[(df.signed_year == year)]\n",
    "\n",
    "        if year is None:\n",
    "            \n",
    "            ''' Display aggregate value grouped by year  '''\n",
    "            df = df.groupby(['signed_year', 'topic_id']).agg([np.mean, np.max])['weight'].reset_index()\n",
    "            df.columns = ['signed_year', 'topic_id', 'mean', 'max']\n",
    "            df['weight'] = df[year_aggregate]\n",
    "            df['signed_year'] = df.signed_year.astype(str)\n",
    "            category_column = 'signed_year'\n",
    "            \n",
    "        else:\n",
    "            ''' Display individual treaties for selected year  '''\n",
    "            df['treaty'] = df.treaty_id + ' ' + df.party1 + ' ' + df.party2\n",
    "            df = df[['treaty', 'treaty_id', 'topic_id', 'weight']]\n",
    "            category_column = 'treaty'  \n",
    "        \n",
    "        df['document_id'] = df.index.astype(str)\n",
    "        df['topic_id'] = df.topic_id.astype(str)\n",
    "         \n",
    "        if output_format.lower() == 'heatmap':\n",
    "            \n",
    "            p = plot_topic_relevance_by_year(\n",
    "                df,\n",
    "                xs=category_column,\n",
    "                ys='topic_id',\n",
    "                flip_axis=flip_axis,\n",
    "                titles=titles,\n",
    "                text_id='topic_relevance',\n",
    "                **HEATMAP_FIGOPTS)\n",
    "\n",
    "            bokeh.plotting.show(p)\n",
    "            \n",
    "        else:\n",
    "            display(df)\n",
    "        \n",
    "    except Exception as ex:\n",
    "        raise\n",
    "        logger.error(ex)\n",
    "        \n",
    "def doc_topic_heatmap_gui(model_data):\n",
    "\n",
    "    lw = lambda w: widgets.Layout(width=w)\n",
    "    \n",
    "    text_id = 'topic_relevance'\n",
    "    \n",
    "    def text_widget(element_id=None, default_value='', style='', line_height='20px'):\n",
    "        value = \"<span class='{}' style='line-height: {};{}'>{}</span>\".format(element_id, line_height, style, default_value) if element_id is not None else ''\n",
    "        return widgets.HTML(value=value, placeholder='', description='', layout=widgets.Layout(height='150px'))\n",
    "    \n",
    "    year_options = [ ('all years', None) ] + [ (x,x) for x in range(model_data.year_period[0], model_data.year_period[1] + 1)]\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        text_id=text_id,\n",
    "        text=text_widget(text_id),\n",
    "        flip_axis=widgets.ToggleButton(value=True, description='Flip', icon='', layout=lw(\"80px\")),\n",
    "        year=widgets.Dropdown(description='Year', options=year_options, value=None, layout=lw(\"160px\")),\n",
    "        year_aggregate=widgets.Dropdown(description='Aggregate', options=['mean', 'max'], value='max', layout=lw(\"160px\")),\n",
    "        output_format=widgets.Dropdown(description='Output', options=['Heatmap', 'Table'], value='Heatmap', layout=lw(\"180px\"))\n",
    "    )\n",
    "    \n",
    "    iw = widgets.interactive(\n",
    "        display_doc_topic_heatmap,\n",
    "        model_data=widgets.fixed(model_data),\n",
    "        flip_axis=gui.flip_axis,\n",
    "        year=gui.year,\n",
    "        year_aggregate=gui.year_aggregate,\n",
    "        output_format=gui.output_format\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([gui.year, gui.year_aggregate, gui.output_format, gui.flip_axis ]),\n",
    "        widgets.HBox([iw.children[-1]]), gui.text\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "\n",
    "try:\n",
    "    doc_topic_heatmap_gui(get_current_model().compiled_data)\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Topic Cooccurrence<span style='color: red; float: right'>TRY IT</span>\n",
    "\n",
    "Computes weighted graph of topics co-occurring in the same document. Topics are defined as co-occurring if they both exists  in the same document both having weights above threshold. Weight are number of co-occurrences (binary yes or no). Node size reflects topic proportions over the entire corpus (normalized document) length, and are computed in accordance to how node sizes are computed in LDAvis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"36255\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"36255\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"36255\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '36255' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"36255\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"36255\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"36255\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '36255' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"36255\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d3fec513aa41b996da1f05bd851daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='cooc_id'></span>\", placeholder=''), HBox(children=(VBox(children=(Drop…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize topic co-occurrence\n",
    "\n",
    "import common.plot_utility as plot_utility\n",
    "import common.network_utility as network_utility\n",
    "import bokeh.plotting # import figure, show, output_notebook, output_file\n",
    "\n",
    "bokeh.plotting.output_notebook()\n",
    "\n",
    "def get_topic_titles(topic_token_weights, topic_id=None, n_words=100):\n",
    "    df_temp = topic_token_weights if topic_id is None else topic_token_weights[(topic_token_weights.topic_id==topic_id)]\n",
    "    df = df_temp\\\n",
    "            .sort_values('weight', ascending=False)\\\n",
    "            .groupby('topic_id')\\\n",
    "            .apply(lambda x: ' '.join(x.token[:n_words].str.title()))\n",
    "    return df\n",
    "\n",
    "# FIXME: add doc token length to df_documents\n",
    "def get_topic_proportions(corpus_documents, document_topic_weights):\n",
    "    topic_proportion = topic_model.compute_topic_proportions(document_topic_weights, corpus_documents)\n",
    "    return topic_proportion\n",
    "    \n",
    "def display_topic_co_occurrence_network(\n",
    "    tm_data,\n",
    "    parties=None,\n",
    "    period=None,\n",
    "    ignores=None,\n",
    "    threshold=0.10,\n",
    "    layout='Fruchterman-Reingold',\n",
    "    scale=1.0,\n",
    "    output_format='table'\n",
    "):\n",
    "    try:\n",
    "        \n",
    "        model_data = tm_data.compiled_data\n",
    "        \n",
    "        titles = topic_model_utility.get_topic_titles(model_data.topic_token_weights)\n",
    "        df = model_data.document_topic_weights\n",
    "        df['document_id'] = df.index\n",
    "        \n",
    "        node_sizes = topic_model.compute_topic_proportions(df, model_data.documents)\n",
    "\n",
    "        if ignores is not None:\n",
    "            df = df[~df.topic_id.isin(ignores)]\n",
    "            \n",
    "        if len(parties or []) > 0:\n",
    "            df = df[df.party1.isin(parties) | df.party2.isin(parties)]\n",
    "            \n",
    "        if period is not None:\n",
    "            df = df[df.signed_year.between(period[0], period[1], inclusive=True)]\n",
    "            \n",
    "        df = df.loc[(df.weight >= threshold)]\n",
    "        df = pd.merge(df, df, how='inner', left_on='document_id', right_on='document_id')\n",
    "        df = df.loc[(df.topic_id_x < df.topic_id_y)]\n",
    "        df = df.groupby([df.topic_id_x, df.topic_id_y]).size().reset_index()\n",
    "        df.columns = ['source', 'target', 'weight']\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            print('No data. Please change selections.')\n",
    "            return\n",
    "        \n",
    "        if output_format == 'table':\n",
    "            display(df)\n",
    "        else:\n",
    "            network = network_utility.NetworkUtility.create_network(df, source_field='source', target_field='target', weight='weight')\n",
    "            p = plot_utility.PlotNetworkUtility.plot_network(\n",
    "                network=network,\n",
    "                layout_algorithm=layout,\n",
    "                scale=scale,\n",
    "                threshold=0.0,\n",
    "                node_description=titles,\n",
    "                node_proportions=node_sizes,\n",
    "                weight_scale=10.0,\n",
    "                normalize_weights=True,\n",
    "                element_id='cooc_id',\n",
    "                figsize=(900,500)\n",
    "            )\n",
    "            bokeh.plotting.show(p)\n",
    "\n",
    "    except Exception as x:\n",
    "        raise\n",
    "        print(\"No data: please adjust filters\")\n",
    "\n",
    "def topic_coocurrence_network_gui(wti_index, tm_data):\n",
    "    \n",
    "    lw = lambda w: widgets.Layout(width=w)\n",
    "    n_topics = tm_data.tm_model.num_topics\n",
    "    \n",
    "    model = tm_data.tm_model\n",
    "    text_id = 'cooc_id'\n",
    "    layout_options = [ 'Circular', 'Kamada-Kawai', 'Fruchterman-Reingold']\n",
    "    party_preset_options = wti_index.get_party_preset_options()\n",
    "    parties_options = [ x for x in wti_index.get_countries_list() if x != 'ALL OTHER' ]\n",
    "    year_min, year_max = tm_data.compiled_data.year_period\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        n_topics=n_topics,\n",
    "        text=widgets_utility.wf.create_text_widget(text_id),\n",
    "        period=widgets.IntRangeSlider(description='Time', min=year_min, max=year_max, step=1, value=(year_min, year_max), continues_update=False),\n",
    "        scale=widgets.FloatSlider(description='Scale', min=0.0, max=1.0, step=0.01, value=0.1, continues_update=False),\n",
    "        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=1.0, step=0.01, value=0.20, continues_update=False),\n",
    "        output_format=widgets_utility.dropdown('Output', { 'Network': 'network', 'Table': 'table' }, 'network', layout=lw('200px')),\n",
    "        layout=widgets_utility.dropdown('Layout', layout_options, 'Fruchterman-Reingold', layout=lw('250px')),\n",
    "        parties=widgets.SelectMultiple(description='Parties', options=parties_options, value=[], rows=7, layout=lw('180px')),\n",
    "        party_preset=widgets_config.dropdown('Presets', party_preset_options, None, layout=lw('180px')),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"99%\")),\n",
    "        ignores=widgets.SelectMultiple(description='Ignore', options=[('', None)] + [ ('Topic #'+str(i), i) for i in range(0, n_topics) ], value=[], rows=8, layout=lw('180px')),\n",
    "    )\n",
    "    def tick(x=None):\n",
    "        gui.progress.value = gui.progress.value + 1 if x is None else x\n",
    "        \n",
    "    def on_party_preset_change(change):  # pylint: disable=W0613\n",
    "        if gui.party_preset.value is None:\n",
    "            return\n",
    "        gui.parties.value = gui.parties.options if 'ALL' in gui.party_preset.value else gui.party_preset.value\n",
    "            \n",
    "    gui.party_preset.observe(on_party_preset_change, names='value')\n",
    "     \n",
    "    iw = widgets.interactive(\n",
    "        display_topic_co_occurrence_network,\n",
    "        tm_data=widgets.fixed(tm_data),\n",
    "        parties=gui.parties,\n",
    "        period=gui.period,\n",
    "        ignores=gui.ignores,\n",
    "        threshold=gui.threshold,\n",
    "        layout=gui.layout,\n",
    "        scale=gui.scale,\n",
    "        output_format=gui.output_format\n",
    "    )\n",
    "    display(widgets.VBox([\n",
    "        gui.text,\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([gui.layout, gui.threshold, gui.scale, gui.period]), \n",
    "            widgets.VBox([gui.parties, gui.party_preset]), \n",
    "            widgets.VBox([gui.ignores]), \n",
    "            widgets.VBox([gui.output_format, gui.progress]),\n",
    "        ]),\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "    iw.update()\n",
    "    \n",
    "try:\n",
    "    tm_data = get_current_model()\n",
    "    topic_coocurrence_network_gui(WTI_INDEX, tm_data)\n",
    "except Exception as ex:\n",
    "    logger.error(ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 655.4,
   "position": {
    "height": "886px",
    "left": "1049px",
    "right": "20px",
    "top": "110px",
    "width": "654px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
