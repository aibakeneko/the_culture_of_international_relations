{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Culture of International Relations - Corpus statistics\n",
    "\n",
    "#### About this notebook\n",
    "tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".jupyter-widgets, .widget-dropdown > select, .widget-label, .widget-toggle-button > button {\n",
       "    font-size: 8pt;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".jupyter-widgets, .widget-dropdown > select, .widget-label, .widget-toggle-button > button {\n",
    "    font-size: 8pt;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:blue'>**Mandatory Prepare Step**</span>: Setup Notebook\n",
    "The following code cell must to be executed once for each user session. The step loads utility Python code stored in separate files, and imports dependencies to external libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "#%run ../common/file_utility\n",
    "#%run ../common/network_utility\n",
    "import sys\n",
    "sys.path.insert(1, '../common')\n",
    "\n",
    "import widgets_utility\n",
    "import configuration_elements\n",
    "import utility\n",
    "import treaty_state\n",
    "\n",
    "logger = getLogger('corpus_text_analysis')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport widgets_utility, treaty_state\n",
    "\n",
    "treaty_state = load_treaty_state(data_folder='../data')\n",
    "\n",
    "# Multiple notebooks can be attached to same kernal (Change kernal command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style='color:blue'>**Mandatory Step**</span>: Convert Treaty Text Corpora to MM Format\n",
    "\n",
    "This code cell is a mandatory step for subsequent text corpus statistics. \n",
    "\n",
    "This step processes the treaty text for from given compressed archive (ZIP-file), each language , and stores in an efficient Market-Matrix (MM) corpus format. The corpora is only stored if it is not previously stored, or the \"Force Update\" is specified. Note that an update MUST be forced whenever the treaty archive is updated - otherwise the text in the new archive is ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     119,
     200,
     219
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'widgets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-80c2e0ead8de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mprepare_treaty_text_corpora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/*.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-80c2e0ead8de>\u001b[0m in \u001b[0;36mprepare_treaty_text_corpora\u001b[0;34m(source_pattern)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcurrent_archives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mls_sorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_pattern\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     source_path_widget=widgets.Dropdown(\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_archives\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_archives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_archives\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'widgets' is not defined"
     ]
    }
   ],
   "source": [
    "# Code\n",
    "%run ./treaty_corpus\n",
    "def prepare_treaty_text_corpora(source_pattern):\n",
    "    \n",
    "    def store_mm_corpora(source_path, force, languages):\n",
    "        try:\n",
    "            progress_widget.value = 1\n",
    "            tokenizer = nltk.tokenize.word_tokenize\n",
    "            source_folder = os.path.split(source_path)[0]\n",
    "            for language in languages.split(','):\n",
    "                progress_widget.value += 1\n",
    "                loader = TreatyCorpusSaveLoad(source_folder, language)\n",
    "                if not loader.exists() or force:\n",
    "                    progress_widget.description = 'Processing: {}'.format(language)\n",
    "                    stream = CompressedFileReader(source_path, filename_pattern='*_{}*.txt'.format(language))\n",
    "                    treaty_corpus = TreatyCorpus(stream, tokenizer=tokenizer)        \n",
    "                    loader.store_as_mm_corpus(treaty_corpus)\n",
    "            progress_widget.description = ''\n",
    "            progress_widget.value = 0\n",
    "        except Exception as ex:\n",
    "            logger.error(ex)\n",
    "        \n",
    "    current_archives = (ls_sorted(source_pattern) or [])\n",
    "\n",
    "    source_path_widget=widgets.Dropdown(\n",
    "        options=current_archives,\n",
    "        value=current_archives[-1] if len(current_archives) else None,\n",
    "        description='Corpus:' #, **drop_style\n",
    "    )\n",
    "    force_corpus_update_widget=widgets.ToggleButton(\n",
    "        description='Force Update',\n",
    "        tooltip='Force refresh of saved corpus cache (a performance feature).\\\n",
    "        Use when ZIP-archive has been updated.',\n",
    "        value=False #, **toggle_style\n",
    "    )\n",
    "    progress_widget = widgets.IntProgress(min=0, max=5, step=1, value=0)\n",
    "\n",
    "    wi = widgets.interactive(\n",
    "        store_mm_corpora,\n",
    "        source_path=source_path_widget,\n",
    "        force=force_corpus_update_widget,\n",
    "        languages='en,it,fr,de'\n",
    "    )\n",
    "\n",
    "    display(\n",
    "        widgets.VBox([widgets.HBox([source_path_widget, force_corpus_update_widget, progress_widget]), wi.children[-1]])\n",
    "    )\n",
    "\n",
    "    wi.update()\n",
    "    \n",
    "prepare_treaty_text_corpora('../data/*.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259bdc38a5e14195918e296e2f27a8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Please specify corpus', description='caption'),)), HBox(children=(Dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "%run ./treaty_corpus\n",
    "%run ../common/treaty_state\n",
    "\n",
    "treaty_state = load_treaty_state(data_folder='../data')\n",
    "\n",
    "def specify_corpus_reader(archive_filename, corpus_option, language, caption, treaty_state=None):\n",
    "    \n",
    "    def get_document_names(archive_filename):\n",
    "        document_names = CompressedFileReader(zip_archive=archive_filename).archive_filenames\n",
    "        df = pd.DataFrame([[x] + re.split('_|\\.',x)[:2] for x in document_names],\n",
    "                          columns=['filename', 'treaty_id', 'language'])\n",
    "        df = df.set_index('treaty_id')\n",
    "        df['is_corr'] = df.filename.apply(lambda z: \"_corr\" in z)\n",
    "        return df\n",
    "    \n",
    "    if corpus_option is None:\n",
    "        caption.value = 'Please select corpus'\n",
    "        return\n",
    "\n",
    "    df_documents = get_document_names(archive_filename)\n",
    "    df_treaties = treaty_state.get_treaty_subset(corpus_option, language).join(df_documents)\n",
    "\n",
    "    display(HTML(df_treaties.to_html()))\n",
    "\n",
    "    return df_treaties\n",
    "    \n",
    "def specify_corpus_reader_interactor(source_pattern, treaty_state):\n",
    "    \n",
    "    current_archives = (ls_sorted(source_pattern) or [])\n",
    "    \n",
    "    progress_widget=widgets.IntProgress(min=0, max=5, step=1, value=0, layout=widgets.Layout(width='99%'))\n",
    "\n",
    "    archive_filename_widget=widgets.Dropdown(\n",
    "        options=current_archives,\n",
    "        value=current_archives[-1] if len(current_archives) else None,\n",
    "        description='Text archive:' #, **drop_style\n",
    "    )\n",
    "      \n",
    "    corpus_options = {\n",
    "        'UNTS 1946-1972': dict(source=['UNTS', 'UNXX'], from_year=1946, to_year=1972,\n",
    "                               parties=None, lang=['en', 'fr']),\n",
    "        'Party of Five': dict(source=None, from_year=1915, to_year=1972,\n",
    "                              parties=parties_of_interest, lang=['en', 'fr', 'de', 'it'])\n",
    "    }\n",
    "    \n",
    "    corpus_widget=widgets.Dropdown(\n",
    "        options=corpus_options,\n",
    "        value=corpus_options[list(corpus_options.keys())[0]],\n",
    "        description='Corpus:'\n",
    "    )\n",
    "\n",
    "    language_widget=widgets.Dropdown(\n",
    "        options=['en', 'fr', 'it', 'de'],\n",
    "        value='en',\n",
    "        description='Language:'\n",
    "    )\n",
    "    \n",
    "    caption = widgets.Label(value='Please specify corpus')\n",
    "    \n",
    "    w = widgets.interactive(\n",
    "        specify_corpus_reader,\n",
    "        archive_filename=archive_filename_widget,\n",
    "        corpus_option=corpus_widget,\n",
    "        language=language_widget,\n",
    "        caption=caption,\n",
    "        treaty_state=widgets.fixed(treaty_state)\n",
    "    )\n",
    "\n",
    "    display(\n",
    "        widgets.VBox([\n",
    "            widgets.HBox([caption]),\n",
    "            widgets.HBox([archive_filename_widget, corpus_widget, language_widget]),\n",
    "            widgets.HBox([progress_widget]),\n",
    "            w.children[-1]])\n",
    "    )\n",
    "    \n",
    "    #def corpus_widget_change(change):\n",
    "    #    current_value = language_widget.value\n",
    "    #    languages = None if corpus_widget.value is None else corpus_widget.value['lang']\n",
    "    #    language_widget.options = languages or []\n",
    "    #    caption.value = str(lang)\n",
    "                 \n",
    "    #corpus_widget.observe(corpus_widget_change, names='value')\n",
    "\n",
    "    return w\n",
    "\n",
    "treaties_select_widget = specify_corpus_reader_interactor('../data/*.zip', treaty_state)\n",
    "treaties_select_widget.update()\n",
    "\n",
    "#print(treaties_select_widget)\n",
    "#def data_changed(change):\n",
    "#    raise Exception(\"HEJ\")\n",
    "#    \n",
    "#treaties_select_widget.observe(data_changed, names='value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Basic Corpus Statistics\n",
    "See https://www.nltk.org/book/ch01.html\n",
    "\n",
    "* Size of treaties over time\n",
    "* Unique word, unique words per word class\n",
    "* Lexical diversity\n",
    "* Frequency distribution\n",
    "* Average word length, sentence length\n",
    "\n",
    "\n",
    "```python\n",
    " \t\n",
    ">>> len(texts) / count(docs)\n",
    "0.06230453042623537\n",
    ">>>\n",
    "\n",
    ">>> len(set(text3)) / len(text3)\n",
    "0.06230453042623537\n",
    ">>>\n",
    "\n",
    ">>> > def lexical_diversity(text): [1]\n",
    "...     return len(set(text)) / len(text) [2]\n",
    "...\n",
    ">>> def percentage(count, total): [3]\n",
    "...     return 100 * count / total\n",
    "\n",
    "# Most common words\n",
    "fdist1 = FreqDist(text1)\n",
    "fdist1.most_common(50)\n",
    "\n",
    "# Word length frequencies\n",
    ">>> fdist = FreqDist(len(w) for w in text1)  [2]\n",
    ">>> print(fdist)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6450da94eb514198ab38a61213c8c489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Language:', layout=Layout(width='260px'), options={'Englisâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code \n",
    "\n",
    "corpus = None\n",
    "def display_token_toplist_interact(source_folder):\n",
    "    global corpus\n",
    "    progress_widget = None\n",
    "    \n",
    "    def display_token_toplist(source_folder, language, statistics='', remove_stopwords=False):\n",
    "        global corpus\n",
    "\n",
    "        try:\n",
    "\n",
    "            progress_widget.value = 1\n",
    "\n",
    "            corpus = TreatyCorpusSaveLoad(source_folder=source_folder, lang=language[0]).load_mm_corpus()\n",
    "\n",
    "            progress_widget.value = 2\n",
    "            service = MmCorpusStatisticsService(corpus, dictionary=corpus.dictionary, language=language)\n",
    "\n",
    "            print(\"Corpus consists of {} documents, {} words in total and a vocabulary size of {} tokens.\"\\\n",
    "                      .format(len(corpus), corpus.dictionary.num_pos, len(corpus.dictionary)))\n",
    "\n",
    "            progress_widget.value = 3\n",
    "            if statistics == 'word_freqs':\n",
    "                display(service.compute_word_frequencies(remove_stopwords))\n",
    "            elif statistics == 'documents':\n",
    "                display(service.compute_document_stats())\n",
    "            elif statistics == 'word_count':\n",
    "                display(service.compute_word_stats())\n",
    "            else:\n",
    "                print('Unknown: ' + statistics)\n",
    "\n",
    "        except Exception as ex:\n",
    "            logger.error(ex)\n",
    "\n",
    "        progress_widget.value = 5\n",
    "        progress_widget.value = 0\n",
    "        return corpus\n",
    "    \n",
    "    language_widget=widgets.Dropdown(\n",
    "        options={\n",
    "            'English': ('en', 'english'),\n",
    "            'French': ('fr', 'french'),\n",
    "            'German': ('de', 'german'),\n",
    "            'Italian': ('it', 'italian')\n",
    "        },\n",
    "        value=('en', 'english'),\n",
    "        description='Language:', **dict(layout=widgets.Layout(width='260px'))\n",
    "    )\n",
    "    \n",
    "    statistics_widget=widgets.Dropdown(\n",
    "        options={\n",
    "            'Word freqs': 'word_freqs',\n",
    "            'Documents': 'documents',\n",
    "            'Word count': 'word_count'\n",
    "        },\n",
    "        value='word_count',\n",
    "        description='Statistics:', **dict(layout=widgets.Layout(width='260px'))\n",
    "    )\n",
    "    \n",
    "    remove_stopwords_widget=widgets.ToggleButton(\n",
    "        description='Remove stopwords', value=True,\n",
    "        tooltip='Do not include stopwords in token toplist'\n",
    "    )\n",
    "    \n",
    "    progress_widget=wf.create_int_progress_widget(min=0, max=5, step=1, value=0) #, layout=widgets.Layout(width='100%')),\n",
    "\n",
    "    wi = widgets.interactive(\n",
    "        display_token_toplist,\n",
    "        source_folder=source_folder,\n",
    "        language=language_widget,\n",
    "        statistics=statistics_widget,\n",
    "        remove_stopwords=remove_stopwords_widget\n",
    "    )\n",
    "\n",
    "    boxes = widgets.HBox(\n",
    "        [\n",
    "            language_widget, statistics_widget, remove_stopwords_widget, progress_widget\n",
    "        ]\n",
    "    )\n",
    "    display(widgets.VBox([boxes, wi.children[-1]]))\n",
    "    wi.update()\n",
    "\n",
    "display_token_toplist_interact('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_predicate = None\n",
    "filename_predicate = filename_predicate or (lambda x: True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: red'>WORK IN PROGRESS</span> Task: Treaty Keyword Extraction (using TF-IDF weighing)\n",
    "- [ML Wiki.org](http://mlwiki.org/index.php/TF-IDF)\n",
    "- [Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "- SpÃ¤rck Jones, K. (1972). \"A Statistical Interpretation of Term Specificity and Its Application in Retrieval\".\n",
    "- Manning, C.D.; Raghavan, P.; Schutze, H. (2008). \"Scoring, term weighting, and the vector space model\". ([PDF](http://nlp.stanford.edu/IR-book/pdf/06vect.pdf))\n",
    "- https://markroxor.github.io/blog/tfidf-pivoted_norm/\n",
    "$\\frac{tf-idf}{\\sqrt(rowSums( tf-idf^2 ) )}$\n",
    "- https://nlp.stanford.edu/IR-book/html/htmledition/pivoted-normalized-document-length-1.html\n",
    "\n",
    "Neural Network Methods in Natural Language Processing, Yoav Goldberg:\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2bd4d39be54eb08a67fb69cc66730f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='Language:', index=3, layout=Layout(width='260px'), options={'German': ('de', 'german'), 'French': ('fr', 'french'), 'Italian': ('it', 'italian'), 'English': ('en', 'english')}, value=('en', 'english')), Dropdown(description='Period:', index=3, layout=Layout(width='260px'), options={'': None, 'Alt. division': 'signed_period_alt', 'Year': 'signed_year', 'Default division': 'signed_period'}, value='signed_period'))), VBox(children=(IntSlider(value=5, continuous_update=False, description='Top #:', max=25, min=1), FloatSlider(value=0.001, continuous_update=False, description='Threshold:', max=0.5, readout_format='.3f', step=0.01))), VBox(children=(IntProgress(value=0, max=5), Dropdown(description='Output:', index=3, layout=Layout(width='260px'), options={'': None, 'Alt. division': 'signed_period_alt', 'Year': 'signed_year', 'Default division': 'signed_period'}, value='signed_period'))))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code\n",
    "from scipy.sparse import csr_matrix\n",
    "%timeit\n",
    "\n",
    "    \n",
    "def get_top_tfidf_words(data, n_top=5):\n",
    "    top_list = data.groupby(['treaty_id'])\\\n",
    "        .apply(lambda x: x.nlargest(n_top, 'score'))\\\n",
    "        .reset_index(level=0, drop=True)\n",
    "    return top_list\n",
    "\n",
    "def compute_tfidf_scores(corpus, dictionary, smartirs='ntc'):\n",
    "    #model = gensim.models.logentropy_model.LogEntropyModel(corpus, normalize=True)\n",
    "    model = gensim.models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary, normalize=True) #, smartirs=smartirs)\n",
    "    rows, cols, scores = [], [], []\n",
    "    for r, document in enumerate(corpus): \n",
    "        vector = model[document]\n",
    "        c, v = zip(*vector)\n",
    "        rows += (len(c) * [ int(r) ])\n",
    "        cols += c\n",
    "        scores += v\n",
    "        \n",
    "    return csr_matrix((scores, (rows, cols)))\n",
    "    \n",
    "if True: #'tfidf_cache' not in globals():\n",
    "    tfidf_cache = {\n",
    "    }\n",
    "    \n",
    "def display_tfidf_scores(source_folder, language, period, n_top=5, threshold=0.001):\n",
    "    \n",
    "    global state, tfw, tfidf_cache\n",
    "    \n",
    "    try:\n",
    "        treaties = state.treaties\n",
    "\n",
    "        tfw.progress.value = 0\n",
    "        tfw.progress.value += 1\n",
    "        if language[0] not in tfidf_cache.keys():\n",
    "            corpus = TreatyCorpusSaveLoad(source_folder=source_folder, lang=language[0])\\\n",
    "                .load_mm_corpus(normalize_by_D=True)\n",
    "            document_names = corpus.document_names\n",
    "            dictionary = corpus.dictionary\n",
    "            _ = dictionary[0]\n",
    "\n",
    "            tfw.progress.value += 1\n",
    "            A = compute_tfidf_scores(corpus, dictionary)\n",
    "\n",
    "            tfw.progress.value += 1\n",
    "            scores = pd.DataFrame(\n",
    "                [ (i, j, dictionary.id2token[j], A[i, j]) for i, j in zip(*A.nonzero())],\n",
    "                columns=['document_id', 'token_id', 'token', 'score']\n",
    "            )\n",
    "            tfw.progress.value += 1\n",
    "            scores = scores.merge(document_names, how='inner', left_on='document_id', right_index=True)\\\n",
    "                .drop(['document_id', 'token_id', 'document_name'], axis=1)\n",
    "\n",
    "            scores = scores[['treaty_id', 'token', 'score']]\\\n",
    "                .sort_values(['treaty_id', 'score'], ascending=[True, False])\n",
    "\n",
    "            tfidf_cache[language[0]] = scores\n",
    "\n",
    "        scores = tfidf_cache[language[0]]\n",
    "        if threshold > 0:\n",
    "            scores = scores.loc[scores.score >= threshold]\n",
    "\n",
    "        tfw.progress.value += 1\n",
    "\n",
    "        #scores = get_top_tfidf_words(scores, n_top=5)\n",
    "        #scores = scores.groupby(['treaty_id']).sum() \n",
    "\n",
    "        scores = scores.groupby(['treaty_id'])\\\n",
    "            .apply(lambda x: x.nlargest(n_top, 'score'))\\\n",
    "            .reset_index(level=0, drop=True)\\\n",
    "            .set_index('treaty_id')\n",
    "\n",
    "        if period is not None:\n",
    "            periods = state.treaties[period]\n",
    "            scores = scores.merge(periods.to_frame(), left_index=True, right_index=True, how='inner')\\\n",
    "                .groupby([period, 'token']).score.agg([np.mean])\\\n",
    "                .reset_index().rename(columns={0:'score'}) #.sort_values('token')\n",
    "\n",
    "        #['token'].apply(' '.join)\n",
    "\n",
    "        display(scores)\n",
    "    except Exception as ex:\n",
    "        logger.error(ex)\n",
    "        \n",
    "    tfw.progress.value = 0\n",
    "\n",
    "#if 'tfidf_scores' not in globals():\n",
    "#    tfidf_scores = compute_document_tfidf(corpus, corpus.dictionary, state.treaties)\n",
    "#    tfidf_scores = tfidf_scores.sort_values(['treaty_id', 'score'], ascending=[True, False])\n",
    "\n",
    "tfw = BaseWidgetUtility(\n",
    "    language=widgets.Dropdown(\n",
    "        options={\n",
    "            'English': ('en', 'english'),\n",
    "            'French': ('fr', 'french'),\n",
    "            'German': ('de', 'german'),\n",
    "            'Italian': ('it', 'italian')\n",
    "        },\n",
    "        value=('en', 'english'),\n",
    "        description='Language:', **drop_style\n",
    "    ),\n",
    "    remove_stopwords=widgets.ToggleButton(\n",
    "        description='Remove stopwords', value=True,\n",
    "        tooltip='Do not include stopwords in token toplist', **toggle_style\n",
    "    ),    \n",
    "    n_top=widgets.IntSlider(\n",
    "        value=5, min=1, max=25, step=1,\n",
    "        description='Top #:',\n",
    "        continuous_update=False\n",
    "    ),\n",
    "    threshold=widgets.FloatSlider(\n",
    "        value=0.001, min=0.0, max=0.5, step=0.01,\n",
    "        description='Threshold:',\n",
    "        tooltip='Word having a TF-IDF score below this value is filtered out',\n",
    "        continuous_update=False,\n",
    "        readout_format='.3f',\n",
    "    ), \n",
    "    period=widgets.Dropdown(\n",
    "        options={\n",
    "            '': None,\n",
    "            'Year': 'signed_year',\n",
    "            'Default division': 'signed_period',\n",
    "            'Alt. division': 'signed_period_alt'\n",
    "        },\n",
    "        value='signed_period',\n",
    "        description='Period:', **drop_style\n",
    "    ),\n",
    "    output=widgets.Dropdown(\n",
    "        options={\n",
    "            '': None,\n",
    "            'Year': 'signed_year',\n",
    "            'Default division': 'signed_period',\n",
    "            'Alt. division': 'signed_period_alt'\n",
    "        },\n",
    "        value='signed_period',\n",
    "        description='Output:', **drop_style\n",
    "    ),\n",
    "    progress=widgets.IntProgress(min=0, max=5, step=1, value=0) #, layout=widgets.Layout(width='100%')),\n",
    ")\n",
    "\n",
    "itfw = widgets.interactive(\n",
    "    display_tfidf_scores,\n",
    "    source_folder='./data',\n",
    "    language=tfw.language,\n",
    "    n_top=tfw.n_top,\n",
    "    threshold=tfw.threshold,\n",
    "    period=tfw.period\n",
    ")\n",
    "\n",
    "boxes = widgets.HBox(\n",
    "    [\n",
    "        widgets.VBox([tfw.language, tfw.period]),\n",
    "        widgets.VBox([tfw.n_top, tfw.threshold]),\n",
    "        widgets.VBox([tfw.progress, tfw.output])\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(widgets.VBox([boxes, itfw.children[-1]]))\n",
    "itfw.update()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 655.4,
   "position": {
    "height": "886px",
    "left": "1049px",
    "right": "20px",
    "top": "110px",
    "width": "654px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
