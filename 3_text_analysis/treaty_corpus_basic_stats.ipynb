{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Culture of International Relations - Corpus statistics\n",
    "\n",
    "#### About this notebook\n",
    "spaCy tutorial: https://github.com/NirantK/nlp-python-deep-learning/blob/master/Part-03%20NLP%20with%20spaCy%20and%20Textacy.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-21 13:30:36,392 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2018-11-21 13:30:36,921 : INFO : Data loaded!\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import typing.re\n",
    "import collections\n",
    "\n",
    "sys.path = list(set(['.', '..']) - set(sys.path)) + sys.path\n",
    "\n",
    "import textacy, spacy \n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import zipfile\n",
    "import common.utility as utility\n",
    "import common.widgets_config as widgets_config\n",
    "import common.config as config\n",
    "import common.utility as utility\n",
    "import common.treaty_utility as treaty_utility\n",
    "import common.treaty_state as treaty_repository\n",
    "import treaty_corpus\n",
    "\n",
    "logger = utility.getLogger('corpus_text_analysis')\n",
    "\n",
    "PERIOD_GROUP = 'years_1945-1972'\n",
    "DATA_FOLDER = '../data'\n",
    "CORPUS_PATH = os.path.join(DATA_FOLDER, 'treaty_text_corpora_20181115.zip')\n",
    "PREPPED_CORPUS_PATH = os.path.join(DATA_FOLDER, 'treaty_text_corpora_20181115_preprocessed.zip')\n",
    "PATTERN = '*.txt'\n",
    "LANGUAGE = 'en'\n",
    "LANGUAGE_MAP = { 'en': 'english', 'fr': 'french', 'it': 'other', 'de': 'other' }\n",
    "LANGUAGE_MODEL_MAP = { 'en': 'en_core_web_sm', 'fr': 'fr_core_web_sm', 'it': 'it_core_web_sm', 'de': 'de_core_web_sm' }\n",
    "\n",
    "WTI_INDEX = treaty_repository.load_wti_index(data_folder=DATA_FOLDER)\n",
    "\n",
    "# sudo python3 -m spacy download en_core_web_lg\n",
    "# nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def get_filenames(zip_filename, extension='.txt'):\n",
    "    with zipfile.ZipFile(zip_filename, mode='r') as zf:\n",
    "        return [ x for x in zf.namelist() if x.endswith(extension) ]\n",
    "    \n",
    "def get_text(zip_filename, filename):\n",
    "    with zipfile.ZipFile(zip_filename, mode='r') as zf:\n",
    "        return zf.read(filename).decode(encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Treaty data utilities\n",
    "def get_treaties(wti_index, language, period_group='years_1945-1972', treaty_filter='is_cultural', parties=None):\n",
    "    period_group = config.PERIOD_GROUPS_ID_MAP[period_group]\n",
    "    treaties = wti_index.get_treaties_within_division(\n",
    "        period_group=period_group,\n",
    "        treaty_filter=treaty_filter,\n",
    "        recode_is_cultural=False,\n",
    "        parties=parties\n",
    "    )\n",
    "    treaties = treaties[treaties[LANGUAGE_MAP[language]]==language]\n",
    "    return treaties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-21 13:30:38,977 : INFO : Loading model: en...\n",
      "2018-11-21 13:30:45,605 : INFO : Using pipeline: tagger parser ner\n",
      "2018-11-21 13:30:45,607 : INFO : Working: Computing new corpus ../data/treaty_text_corpora_20181115_preprocessed_en_.pkl...\n",
      "2018-11-21 13:35:01,826 : INFO : Working: Merging named entities...\n",
      "2018-11-21 13:35:05,863 : INFO : Done!\n"
     ]
    }
   ],
   "source": [
    "# %writefile: spacy_utility\n",
    "from spacy.language import Language\n",
    "from textacy.spacier.utils import merge_spans\n",
    "\n",
    "HYPHEN_REGEXP = re.compile(r'\\b(\\w+)-\\s*\\r?\\n\\s*(\\w+)\\b', re.UNICODE)\n",
    "\n",
    "def preprocess_text(source_filename, target_filename):\n",
    "    filenames = get_filenames(source_filename)\n",
    "    texts = ( (filename, get_text(source_filename, filename)) for filename in filenames )\n",
    "    with zipfile.ZipFile(target_filename, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "        for filename, text in texts:\n",
    "            logger.info('Processing ' + filename)\n",
    "            text = re.sub(HYPHEN_REGEXP, r\"\\1\\2\\n\", text)\n",
    "            text = textacy.preprocess.normalize_whitespace(text)   \n",
    "            text = textacy.preprocess.fix_bad_unicode(text)   \n",
    "            text = textacy.preprocess.replace_currency_symbols(text)\n",
    "            text = textacy.preprocess.unpack_contractions(text)\n",
    "            #text = textacy.preprocess.replace_urls(text)\n",
    "            #text = textacy.preprocess.replace_emails(text)\n",
    "            #text = textacy.preprocess.replace_phone_numbers(text)\n",
    "            text = textacy.preprocess.remove_accents(text)\n",
    "            zf.writestr(filename, text)\n",
    "\n",
    "def get_document_stream(corpus_path, lang, wti_index, period_group, treaty_filter='is_cultural', parties=None):\n",
    "\n",
    "    treaties = get_treaties(wti_index, language=lang, period_group=period_group, treaty_filter=treaty_filter, parties=parties)\n",
    "    treaties['treaty_id'] = treaties.index\n",
    "    treaty_ids = list(treaties.index)\n",
    "    \n",
    "    documents = treaty_corpus.TreatyCompressedFileReader(corpus_path, lang, treaty_ids)\n",
    "\n",
    "    for treaty_id, language, filename, text in documents:\n",
    "        assert language == lang\n",
    "        metadata = treaties.loc[treaty_id]\n",
    "        yield filename, text, metadata\n",
    "        \n",
    "def create_textacy_corpus(documents, nlp): #, preprocess_args=None):\n",
    "    corpus = textacy.Corpus(nlp)\n",
    "    for filename, text, metadata in documents:\n",
    "        #if not preprocess_args is None:\n",
    "        #    text = re.sub(HYPHEN_REGEXP, r\"\\1\\2\\n\", text)\n",
    "        #    text = textacy.preprocess.preprocess_text(text, **preprocess_args)\n",
    "        corpus.add_text(text, utility.extend(dict(filename=filename), metadata))\n",
    "    return corpus\n",
    "\n",
    "def get_textacy_corpus_filename(source_path, language, nlp_args=None, preprocess_args=None):\n",
    "    nlp_args = nlp_args or {}\n",
    "    preprocess_args = preprocess_args or {}\n",
    "    disabled_pipes = nlp_args.get('disable', [])\n",
    "    suffix = '_{}_{}{}'.format(\n",
    "        language,\n",
    "        '_'.join([ k for k in preprocess_args if preprocess_args[k] ]),\n",
    "        '_disable({})'.format(','.join(disabled_pipes)) if len(disabled_pipes) > 0 else ''\n",
    "    )\n",
    "    return utility.path_add_suffix(source_path, suffix, new_extension='.pkl')\n",
    "\n",
    "def setup_nlp_language_model(language, **nlp_args):\n",
    "    \n",
    "    def remove_whitespace_entities(doc):\n",
    "        doc.ents = [ e for e in doc.ents if not e.text.isspace() ]\n",
    "        return doc\n",
    "\n",
    "    logger.info('Loading model: %s...', language)\n",
    "    \n",
    "    Language.factories['remove_whitespace_entities'] = lambda nlp, **cfg: remove_whitespace_entities\n",
    "    \n",
    "    nlp = textacy.load_spacy(LANGUAGE_MODEL_MAP[language], **nlp_args)\n",
    "    pipeline = lambda: [ x[0] for x in nlp.pipeline ]\n",
    "    \n",
    "    logger.info('Using pipeline: ' + ' '.join(pipeline()))\n",
    "    \n",
    "    return nlp\n",
    "\n",
    "def get_current_document_stream():\n",
    "    return get_document_stream(PREPPED_CORPUS_PATH, LANGUAGE, WTI_INDEX, PERIOD_GROUP, treaty_filter='is_cultural', parties=None)\n",
    "\n",
    "def generate_textacy_corpus(source_path, language, merge_named_entities, force=False):\n",
    "    \n",
    "    textacy_corpus_filename = get_textacy_corpus_filename(source_path, language)\n",
    "    nlp = setup_nlp_language_model(language) #, options.get('nlp_args', {}))\n",
    "    \n",
    "    if force or not os.path.isfile(textacy_corpus_filename):\n",
    "        logger.info('Working: Computing new corpus ' + textacy_corpus_filename + '...')\n",
    "        document_stream = get_current_document_stream()\n",
    "        corpus = create_textacy_corpus(document_stream, nlp)\n",
    "        corpus.save(textacy_corpus_filename)\n",
    "    else:\n",
    "        logger.info('Working: Loading corpus ' + textacy_corpus_filename + '...')\n",
    "        corpus = textacy.Corpus.load(textacy_corpus_filename)\n",
    "        \n",
    "    if merge_named_entities:\n",
    "        logger.info('Working: Merging named entities...')\n",
    "        for doc in corpus:\n",
    "            named_entities = textacy.extract.named_entities(doc)\n",
    "            merge_spans(named_entities, doc.spacy_doc)\n",
    "    else:\n",
    "        logger.info('Note: named entities not merged')\n",
    "        \n",
    "    logger.info('Done!')\n",
    "    \n",
    "    return textacy_corpus_filename, corpus\n",
    "\n",
    "def propagate_document_attributes(corpus):\n",
    "    for doc in corpus:\n",
    "        doc.spacy_doc.user_data['title'] = doc.metadata['treaty_id']\n",
    "        doc.spacy_doc.user_data['treaty_id'] = doc.metadata['treaty_id']\n",
    "    \n",
    "def get_corpus_documents(corpus):\n",
    "    df = pd.DataFrame([\n",
    "        (document_id, doc.metadata['treaty_id'], doc.metadata['filename'])\n",
    "                for document_id, doc in enumerate(corpus) ], columns=['treaty_id', 'title', 'filename']\n",
    "    ).set_index('treaty_id')\n",
    "    return df\n",
    "\n",
    "if not os.path.isfile(PREPPED_CORPUS_PATH):\n",
    "    preprocess_text(CORPUS_PATH, PREPPED_CORPUS_PATH)\n",
    "\n",
    "\n",
    "TEXTACY_CORPUS_FILENAME, CORPUS = generate_textacy_corpus(\n",
    "    PREPPED_CORPUS_PATH,\n",
    "    LANGUAGE,\n",
    "    merge_named_entities=True,\n",
    "    force=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Key Terms \n",
    "- [TextRank]\tMihalcea, R., & Tarau, P. (2004, July). TextRank: Bringing order into texts. Association for Computational Linguistics.\n",
    "- [SingleRank]\tHasan, K. S., & Ng, V. (2010, August). Conundrums in unsupervised keyphrase extraction: making sense of the state-of-the-art. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters (pp. 365-373). Association for Computational Linguistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8a78cde4604272b90846137dc4daa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Paper', index=322, layout=Layout(width='40%'), options={'1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Document Key Terms\n",
    "\n",
    "import textacy.keyterms\n",
    "import types\n",
    "def display_document_key_terms_gui(corpus):\n",
    "    \n",
    "    df_documents = get_corpus_documents(corpus)\n",
    "    methods = { 'SingleRank': textacy.keyterms.singlerank, 'TextRank': textacy.keyterms.textrank }\n",
    "    document_options = {v: k for k, v in df_documents['title'].to_dict().items()}\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        output=widgets.Output(layout={'border': '1px solid black'}),\n",
    "        n_keyterms=widgets.IntSlider(description='#words', min=10, max=500, value=100, step=1, layout=widgets.Layout(width='240px')),\n",
    "        document_id=widgets.Dropdown(description='Paper', options=document_options, value=0, layout=widgets.Layout(width='40%')),\n",
    "        method=widgets.Dropdown(description='Algorithm', options=[ 'TextRank', 'SingleRank' ], value='TextRank', layout=widgets.Layout(width='180px')),\n",
    "        normalize=widgets.Dropdown(description='Normalize', options=[ 'lemma', 'lower' ], value='lemma', layout=widgets.Layout(width='160px'))\n",
    "    )\n",
    "    \n",
    "    def display_document_key_terms(corpus, method='TextRank', document_id=0, normalize='lemma', n_keyterms=10):\n",
    "        keyterms = methods[method](corpus[document_id], normalize=normalize, n_keyterms=n_keyterms)\n",
    "        terms = ', '.join([ x for x, y in keyterms ])\n",
    "        gui.output.clear_output()\n",
    "        with gui.output:\n",
    "            print(terms)\n",
    "\n",
    "    itw = widgets.interactive(\n",
    "        display_document_key_terms,\n",
    "        corpus=widgets.fixed(corpus),\n",
    "        method=gui.method,\n",
    "        document_id=gui.document_id,\n",
    "        normalize=gui.normalize,\n",
    "        n_keyterms=gui.n_keyterms,\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([gui.document_id, gui.method, gui.normalize, gui.n_keyterms]),\n",
    "        gui.output\n",
    "    ]))\n",
    "\n",
    "    itw.update()\n",
    "\n",
    "display_document_key_terms_gui(CORPUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>PREPARE/DESCRIBE </span> Clean Up the Text <span style='float: right; color: green'>TRY IT</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c42b54707f044a5b6b888a4b7d42cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, layout=Layout(width='90%'), max=5), HBox(children=(VBox(children=(Dropdown…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean Up the Text\n",
    "\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches':'tight'}\n",
    "import bokeh, bokeh.plotting, bokeh.models, matplotlib.pyplot as plt\n",
    "\n",
    "HYPHEN_REGEXP = re.compile(r'\\b(\\w+)-\\s*\\r?\\n\\s*(\\w+)\\b', re.UNICODE)\n",
    "DF_TAGSET = pd.read_csv('../data/tagset.csv', sep='\\t').fillna('')\n",
    "\n",
    "SOURCE_FILES = {\n",
    "    'source_text_raw': { 'filename': CORPUS_PATH, 'description': 'Raw text from PDF: Automatic text extraction using pdfminer Python package. ' },\n",
    "    'source_text_edited': { 'filename': CORPUS_PATH, 'description': 'Manually edited text: List of references, index, notes and page headers etc. removed.' },\n",
    "    'source_text_preprocessed': { 'filename': PREPPED_CORPUS_PATH, 'description': 'Preprocessed text: Normalized whitespaces. Unicode fixes. Urls, emails and phonenumbers removed. Accents removed.' }\n",
    "}\n",
    "\n",
    "def display_cleanup_text_gui(corpus, callback):\n",
    "    \n",
    "    documents = get_corpus_documents(corpus)\n",
    "    document_options = {v: k for k, v in documents['title'].to_dict().items()}\n",
    "    \n",
    "    #pos_options = [ x for x in DF_TAGSET.POS.unique() if x not in ['PUNCT', '', 'DET', 'X', 'SPACE', 'PART', 'CONJ', 'SYM', 'INTJ', 'PRON']]  # groupby(['POS'])['DESCRIPTION'].apply(list).apply(lambda x: ', '.join(x)).to_dict()\n",
    "    pos_tags = DF_TAGSET.groupby(['POS'])['DESCRIPTION'].apply(list).apply(lambda x: ', '.join(x[:1])).to_dict()\n",
    "    pos_options = { k + ' (' + v + ')': k for k,v in pos_tags.items() }\n",
    "    display_options = {\n",
    "        'Source text (raw)': 'source_text_raw',\n",
    "        'Source text (edited)': 'source_text_edited',\n",
    "        'Source text (processed)': 'source_text_preprocessed',\n",
    "        'Sanitized text': 'sanitized_text',\n",
    "        'Statistics': 'statistics'\n",
    "    }\n",
    "    ngrams_options = { '1': [1], '1,2': [1,2], '1,2,3': [1,2,3]}\n",
    "    gui = types.SimpleNamespace(\n",
    "        document_id=widgets.Dropdown(description='Paper', options=document_options, value=0, layout=widgets.Layout(width='400px')),\n",
    "        progress=widgets.IntProgress(value=0, min=0, max=5, step=1, description='', layout=widgets.Layout(width='90%')),\n",
    "        min_freq=widgets.FloatSlider(value=0, min=0, max=1.0, step=0.01, description='Min frequency', layout=widgets.Layout(width='400px')),\n",
    "        ngrams=widgets.Dropdown(description='n-grams', options=ngrams_options, value=[1], layout=widgets.Layout(width='180px')),\n",
    "        min_word=widgets.Dropdown(description='Min length', options=[1,2,3,4], value=1, layout=widgets.Layout(width='180px')),\n",
    "        normalize=widgets.Dropdown(description='Normalize', options=[ False, 'lemma', 'lower' ], value=False, layout=widgets.Layout(width='180px')),\n",
    "        filter_stops=widgets.ToggleButton(value=False, description='Filter stops',  tooltip='Filter out stopwords', icon='check'),\n",
    "        filter_nums=widgets.ToggleButton(value=False, description='Filter nums',  tooltip='Filter out stopwords', icon='check'),\n",
    "        filter_punct=widgets.ToggleButton(value=False, description='Filter punct',  tooltip='Filter out punctuations', icon='check'),\n",
    "        named_entities=widgets.ToggleButton(value=False, description='Merge entities',  tooltip='Merge entities', icon='check'),\n",
    "        drop_determiners=widgets.ToggleButton(value=False, description='Drop determiners',  tooltip='Drop determiners', icon='check'),\n",
    "        include_pos=widgets.SelectMultiple(description='POS', options=pos_options, value=list(), rows=10, layout=widgets.Layout(width='400px')),\n",
    "        display_type=widgets.Dropdown(description='Show', value='statistics', options=display_options, layout=widgets.Layout(width='180px')),\n",
    "        output_text=widgets.Output(layout={'height': '500px'}),\n",
    "        output_statistics = widgets.Output(),\n",
    "        boxes=None\n",
    "    )\n",
    "    \n",
    "    uix = widgets.interactive(\n",
    "\n",
    "        callback,\n",
    "\n",
    "        corpus=widgets.fixed(corpus),\n",
    "        gui=widgets.fixed(gui),\n",
    "        display_type=gui.display_type,\n",
    "        document_id=gui.document_id,\n",
    "        \n",
    "        ngrams=gui.ngrams,\n",
    "        named_entities=gui.named_entities,\n",
    "        normalize=gui.normalize,\n",
    "        filter_stops=gui.filter_stops,\n",
    "        filter_punct=gui.filter_punct,\n",
    "        filter_nums=gui.filter_nums,\n",
    "        include_pos=gui.include_pos,\n",
    "        min_freq=gui.min_freq,\n",
    "        drop_determiners=gui.drop_determiners\n",
    "    )\n",
    "    \n",
    "    gui.boxes = widgets.VBox([\n",
    "        gui.progress,\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([\n",
    "                gui.document_id,\n",
    "                widgets.HBox([gui.display_type, gui.normalize]),\n",
    "                widgets.HBox([gui.ngrams, gui.min_word]),\n",
    "                gui.min_freq\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                gui.include_pos\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                gui.filter_stops,\n",
    "                gui.filter_nums,\n",
    "                gui.filter_punct,\n",
    "                gui.named_entities,\n",
    "                gui.drop_determiners\n",
    "            ])\n",
    "        ]),\n",
    "        widgets.HBox([\n",
    "            gui.output_text, gui.output_statistics\n",
    "        ]),\n",
    "        uix.children[-1]\n",
    "    ])\n",
    "    \n",
    "    display(gui.boxes)\n",
    "                                  \n",
    "    uix.update()\n",
    "    return gui, uix\n",
    "\n",
    "def plot_xy_data(data, title='', xlabel='', ylabel='', **kwargs):\n",
    "    x, y = list(data[0]), list(data[1])\n",
    "    labels = x\n",
    "    plt.figure(figsize=(8, 9 / 1.618))\n",
    "    plt.plot(x, y, 'ro', **kwargs)\n",
    "    plt.xticks(x, labels, rotation='75')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "    \n",
    "def display_cleaned_up_text(corpus, gui, display_type, document_id, **kwargs): # ngrams, named_entities, normalize, include_pos):\n",
    "    \n",
    "    gui.output_text.clear_output()\n",
    "    gui.output_statistics.clear_output()\n",
    "    \n",
    "    #Additional candidates;\n",
    "    #is_alpha\tbool\tDoes the token consist of alphabetic characters? Equivalent to token.text.isalpha().\n",
    "    #is_ascii\tbool\tDoes the token consist of ASCII characters? Equivalent to [any(ord(c) >= 128 for c in token.text)].\n",
    "    #like_url\tbool\tDoes the token resemble a URL?\n",
    "    #like_email\tbool\tDoes the token resemble an email address?\n",
    "\n",
    "    doc = corpus[document_id]\n",
    "    \n",
    "    terms = [ x for x in doc.to_terms_list(as_strings=True, **kwargs) ]\n",
    "    \n",
    "    if display_type.startswith('source_text'):\n",
    "        \n",
    "        source_filename = SOURCE_FILES[display_type]['filename']\n",
    "        description =  SOURCE_FILES[display_type]['description']\n",
    "        text = get_text(source_filename, doc.metadata['filename'])\n",
    "        with gui.output_text:\n",
    "            #print('{}\\n.................\\n(NOT SHOWN TEXT)\\n.................\\n{}'.format(document[:2500], document[-250:]))\n",
    "            #print(doc)\n",
    "            print('[ ' + description.upper() + ' ]')\n",
    "            print(text)\n",
    "        return\n",
    "\n",
    "    if len(terms) == 0:\n",
    "        with gui.output_text:\n",
    "            print(\"No text. Please change selection.\")\n",
    "        return\n",
    "    \n",
    "    if display_type in ['sanitized_text', 'statistics']:\n",
    "\n",
    "        if display_type == 'sanitized_text':\n",
    "            with gui.output_text:\n",
    "                #display('{}\\n.................\\n(NOT SHOWN TEXT)\\n.................\\n{}'.format(\n",
    "                #    ' '.join(tokens[:word_count]),\n",
    "                #    ' '.join(tokens[-word_count:])\n",
    "                #))\n",
    "                print(' '.join([ t.replace(' ', '_') for t in terms ]))\n",
    "                return\n",
    "\n",
    "        if display_type == 'statistics':\n",
    "\n",
    "            wf = nltk.FreqDist(terms)\n",
    "\n",
    "            with gui.output_text:\n",
    "\n",
    "                print('Word count (number of terms): {}'.format(wf.N()))\n",
    "                print('Unique word count (vocabulary): {}'.format(wf.B()))\n",
    "                print(' ')\n",
    "\n",
    "                df = pd.DataFrame(wf.most_common(25), columns=['token','count'])\n",
    "                display(df)\n",
    "\n",
    "            with gui.output_statistics:\n",
    "\n",
    "                data = list(zip(*wf.most_common(25)))\n",
    "                plot_xy_data(data, title='Word distribution', xlabel='Word', ylabel='Word count')\n",
    "\n",
    "                wf = nltk.FreqDist([len(x) for x in terms])\n",
    "                data = list(zip(*wf.most_common(25)))\n",
    "                plot_xy_data(data, title='Word length distribution', xlabel='Word length', ylabel='Word count')\n",
    "\n",
    "xgui, xuix = display_cleanup_text_gui(CORPUS, display_cleaned_up_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>MODEL</span> Compute an Topic Model<span style='color: red; float: right'>MANDATORY RUN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1014\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1014\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1014\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1014' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.1.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1014\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1014\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1014\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1014' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.1.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.1.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.1.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.1.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1014\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0f32b9fd374a76b09a1ab8138e3fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, layout=Layout(width='90%'), max=5), HBox(children=(VBox(children=(IntSlide…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import types\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from gensim import corpora, models, matutils\n",
    "\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('svg') #'pdf', 'svg')\n",
    "    \n",
    "bokeh.plotting.output_notebook()\n",
    "\n",
    "class TopicModelNotComputed(Exception):\n",
    "    @staticmethod\n",
    "    def check():\n",
    "        if 'TM_GUI_MODEL' in globals():\n",
    "            gui =  globals()['TM_GUI_MODEL']\n",
    "            if None not in (gui, gui.model):\n",
    "                return True\n",
    "        msg = 'A topic model must be computed using step \"MODEL Compute an LDA Topic Model\"'\n",
    "        raise TopicModelNotComputed(msg)\n",
    "\n",
    "def get_current_model():\n",
    "    TopicModelNotComputed.check()\n",
    "    return globals()['TM_GUI_MODEL'].model\n",
    "\n",
    "DEFAULT_TERM_PARAMS = dict(\n",
    "    args=dict(ngrams=1, named_entities=True, normalize='lemma', as_strings=True),\n",
    "    kwargs=dict(filter_stops=True, filter_punct=True, filter_nums=True, min_freq=1, drop_determiners=True, include_pos=('NOUN', 'PROPN', ))\n",
    ")\n",
    "\n",
    "FIXED_STOPWORDS = ['', '\\n', 'et', 'al', 'et.al.' ]\n",
    "def filter_terms(doc, term_args, chunk_size=None, min_length=2):\n",
    "    kwargs = utility.extend({}, DEFAULT_TERM_PARAMS['kwargs'], term_args['kwargs'])\n",
    "    args = utility.extend({}, DEFAULT_TERM_PARAMS['args'], term_args['args'])\n",
    "    terms = (x for x in doc.to_terms_list(\n",
    "        args['ngrams'],\n",
    "        args['named_entities'],\n",
    "        args['normalize'],\n",
    "        args['as_strings'],\n",
    "        **kwargs\n",
    "    ) if len(x) >= min_length and x not in FIXED_STOPWORDS)\n",
    "    return terms\n",
    "\n",
    "class LdaDataCompiler():\n",
    "    \n",
    "    @staticmethod\n",
    "    def compile_dictionary(model):\n",
    "        logger.info('Compiling dictionary...')\n",
    "        token_ids, tokens = list(zip(*model.id2word.items()))\n",
    "        dfs = model.id2word.dfs.values() if model.id2word.dfs is not None else [0] * len(tokens)\n",
    "        dictionary = pd.DataFrame({\n",
    "            'token_id': token_ids,\n",
    "            'token': tokens,\n",
    "            'dfs': list(dfs)\n",
    "        }).set_index('token_id')[['token', 'dfs']]\n",
    "        return dictionary\n",
    "\n",
    "    @staticmethod\n",
    "    def compile_topic_token_weights(tm, dictionary, num_words=200):\n",
    "        logger.info('Compiling topic-tokens weights...')\n",
    "\n",
    "        df_topic_weights = pd.DataFrame(\n",
    "            [ (topic_id, token, weight)\n",
    "                for topic_id, tokens in (tm.show_topics(tm.num_topics, num_words=num_words, formatted=False))\n",
    "                    for token, weight in tokens if weight > 0.0 ],\n",
    "            columns=['topic_id', 'token', 'weight']\n",
    "        )\n",
    "\n",
    "        df = pd.merge(\n",
    "            df_topic_weights.set_index('token'),\n",
    "            dictionary.reset_index().set_index('token'),\n",
    "            how='inner',\n",
    "            left_index=True,\n",
    "            right_index=True\n",
    "        )\n",
    "        return df.reset_index()[['topic_id', 'token_id', 'token', 'weight']]\n",
    "\n",
    "    @staticmethod\n",
    "    def compile_topic_token_overview(topic_token_weights, alpha=None, n_words=200):\n",
    "        \"\"\"\n",
    "        Group by topic_id and concatenate n_words words within group sorted by weight descending.\n",
    "        There must be a better way of doing this...\n",
    "        \"\"\"\n",
    "        logger.info('Compiling topic-tokens overview...')\n",
    "\n",
    "        df = topic_token_weights.groupby('topic_id')\\\n",
    "            .apply(lambda x: sorted(list(zip(x[\"token\"], x[\"weight\"])), key=lambda z: z[1], reverse=True))\\\n",
    "            .apply(lambda x: ' '.join([z[0] for z in x][:n_words])).reset_index()\n",
    "        df['alpha'] = df.topic_id.apply(lambda topic_id: alpha[topic_id]) if alpha is not None else 0.0\n",
    "        df.columns = ['topic_id', 'tokens', 'alpha']\n",
    "\n",
    "        return df.set_index('topic_id')\n",
    "\n",
    "    @staticmethod\n",
    "    def compile_document_topics(model, corpus, documents, minimum_probability=0.001):\n",
    "\n",
    "        def document_topics_iter(model, corpus, minimum_probability):\n",
    "\n",
    "            if isinstance(model, models.LsiModel):\n",
    "                data_iter = model[corpus]\n",
    "            else:\n",
    "                data_iter = model.get_document_topics(corpus, minimum_probability=minimum_probability)\\\n",
    "                    if hasattr(model, 'get_document_topics')\\\n",
    "                    else model.load_document_topics()\n",
    "\n",
    "            for document_id, topic_weights in enumerate(data_iter):\n",
    "                for (topic_id, weight) in ((topic_id, weight) for (topic_id, weight) in topic_weights if weight >= minimum_probability):\n",
    "                    yield (document_id, topic_id, weight)\n",
    "        '''\n",
    "        Get document topic weights for all documents in corpus\n",
    "        Note!  minimum_probability=None filters less probable topics, set to 0 to retrieve all topcs\n",
    "\n",
    "        If gensim model then use 'get_document_topics', else 'load_document_topics' for mallet model\n",
    "        '''\n",
    "        logger.info('Compiling document topics...')\n",
    "        logger.info('  Creating data iterator...')\n",
    "        data = document_topics_iter(model, corpus, minimum_probability)\n",
    "        logger.info('  Creating frame from iterator...')\n",
    "        df_doc_topics = pd.DataFrame(data, columns=[ 'document_id', 'topic_id', 'weight' ]).set_index('document_id')\n",
    "        logger.info('  Merging data...')\n",
    "        df = pd.merge(documents, df_doc_topics, how='inner', left_index=True, right_index=True)\n",
    "        logger.info('  DONE!')\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_compiled_data(model, corpus, id2term, documents):\n",
    "\n",
    "        dictionary = LdaDataCompiler.compile_dictionary(model)\n",
    "        topic_token_weights = LdaDataCompiler.compile_topic_token_weights(model, dictionary, num_words=200)\n",
    "        alpha = model.alpha if 'alpha' in model.__dict__ else None\n",
    "        topic_token_overview = LdaDataCompiler.compile_topic_token_overview(topic_token_weights, alpha)\n",
    "        document_topic_weights = LdaDataCompiler.compile_document_topics(model, corpus, documents, minimum_probability=0.001)\n",
    "\n",
    "        return types.SimpleNamespace(\n",
    "            dictionary=dictionary,\n",
    "            documents=documents,\n",
    "            topic_token_weights=topic_token_weights,\n",
    "            topic_token_overview=topic_token_overview,\n",
    "            document_topic_weights=document_topic_weights\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_topic_titles(topic_token_weights, topic_id=None, n_words=100):\n",
    "        df_temp = topic_token_weights if topic_id is None else topic_token_weights[(topic_token_weights.topic_id==topic_id)]\n",
    "        df = df_temp\\\n",
    "                .sort_values('weight', ascending=False)\\\n",
    "                .groupby('topic_id')\\\n",
    "                .apply(lambda x: ' '.join(x.token[:n_words].str.title()))\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def get_topic_title(topic_token_weights, topic_id, n_words=100):\n",
    "        return LdaDataCompiler.get_topic_titles(topic_token_weights, topic_id, n_words=n_words).iloc[0]\n",
    "\n",
    "    #get_topics_tokens_as_text = get_topic_titles\n",
    "    #get_topic_tokens_as_text = get_topic_title\n",
    "\n",
    "    @staticmethod\n",
    "    def get_topic_tokens(topic_token_weights, topic_id=None, n_words=100):\n",
    "        df_temp = topic_token_weights if topic_id is None else topic_token_weights[(topic_token_weights.topic_id == topic_id)]\n",
    "        df = df_temp.sort_values('weight', ascending=False)[:n_words]\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_lda_topics(model, n_tokens=20):\n",
    "        return pd.DataFrame({\n",
    "            'Topic#{:02d}'.format(topic_id+1) : [ word[0] for word in model.show_topic(topic_id, topn=n_tokens) ]\n",
    "                for topic_id in range(model.num_topics)\n",
    "        })\n",
    "\n",
    "# OBS OBS! https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html\n",
    "DEFAULT_VECTORIZE_PARAMS = dict(tf_type='linear', apply_idf=False, idf_type='smooth', norm='l2', min_df=1, max_df=0.95)\n",
    "\n",
    "def compute_topic_model(corpus, tick=utility.noop, method='sklearn_lda', vec_args=None, term_args=None, tm_args=None, **args):\n",
    "    \n",
    "    tick()\n",
    "    vec_args = utility.extend({}, DEFAULT_VECTORIZE_PARAMS, vec_args)\n",
    "    \n",
    "    terms_iter = lambda: (filter_terms(doc, term_args) for doc in corpus)\n",
    "    tick()\n",
    "    \n",
    "    vectorizer = textacy.Vectorizer(**vec_args)\n",
    "    doc_term_matrix = vectorizer.fit_transform(terms_iter())\n",
    "\n",
    "    if method.startswith('sklearn'):\n",
    "        \n",
    "        tm_model = textacy.TopicModel(method.split('_')[1], **tm_args)\n",
    "        tm_model.fit(doc_term_matrix)\n",
    "        tick()\n",
    "        doc_topic_matrix = tm_model.transform(doc_term_matrix)\n",
    "        tick()\n",
    "        tm_id2word = vectorizer.id_to_term\n",
    "        tm_corpus = matutils.Sparse2Corpus(doc_term_matrix, documents_columns=False)\n",
    "        compiled_data = None # FIXME\n",
    "        \n",
    "    elif method.startswith('gensim_'):\n",
    "        \n",
    "        algorithm = method.split('_')[1].upper()\n",
    "        doc_topic_matrix = None # ?\n",
    "        tm_id2word = corpora.Dictionary(terms_iter())\n",
    "        tm_corpus = [ tm_id2word.doc2bow(text) for text in terms_iter() ]\n",
    "        #tm_id2word = vectorizer.id_to_term\n",
    "        #tm_corpus = matutils.Sparse2Corpus(doc_term_matrix, documents_columns=False)\n",
    "        \n",
    "        algorithms = {\n",
    "            'LSI': {\n",
    "                'engine': models.LsiModel,\n",
    "                'options': {\n",
    "                    'corpus': tm_corpus, \n",
    "                    'num_topics':  tm_args.get('n_topics', 0),\n",
    "                    'id2word':  tm_id2word,\n",
    "                    'power_iters': 2,\n",
    "                    'onepass': True\n",
    "                }\n",
    "            },\n",
    "            'LDA': {\n",
    "                'engine': models.LdaModel,\n",
    "                'options': {\n",
    "                    'corpus': tm_corpus, \n",
    "                    'num_topics':  tm_args.get('n_topics', 0),\n",
    "                    'id2word':  tm_id2word,\n",
    "                    'iterations': tm_args.get('max_iter', 0),\n",
    "                    'passes': 20,\n",
    "                    'alpha': 'asymmetric'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        tm_model = algorithms[algorithm]['engine'](**algorithms[algorithm]['options'])\n",
    "        documents = get_corpus_documents(corpus)\n",
    "        compiled_data = LdaDataCompiler.compute_compiled_data(tm_model, tm_corpus, tm_id2word, documents)\n",
    "    \n",
    "    tm_data = types.SimpleNamespace(\n",
    "        tm_model=tm_model,\n",
    "        tm_id2term=tm_id2word,\n",
    "        tm_corpus=tm_corpus,\n",
    "        doc_term_matrix=doc_term_matrix,\n",
    "        doc_topic_matrix=doc_topic_matrix,\n",
    "        vectorizer=vectorizer,\n",
    "        compiled_data=compiled_data\n",
    "    )\n",
    "    \n",
    "    tick(0)\n",
    "    \n",
    "    return tm_data\n",
    "\n",
    "def get_doc_topic_weights(doc_topic_matrix, threshold=0.05):\n",
    "    topic_ids = range(0,doc_topic_matrix.shape[1])\n",
    "    for document_id in range(0,doc_topic_matrix.shape[1]):\n",
    "        topic_weights = doc_topic_matrix[document_id, :]\n",
    "        for topic_id in topic_ids:\n",
    "            if topic_weights[topic_id] >= threshold:\n",
    "                yield (document_id, topic_id, topic_weights[topic_id])\n",
    "\n",
    "def get_df_doc_topic_weights(doc_topic_matrix, threshold=0.05):\n",
    "    it = get_doc_topic_weights(doc_topic_matrix, threshold)\n",
    "    df = pd.DataFrame(list(it), columns=['document_id', 'topic_id', 'weight']).set_index('document_id')\n",
    "    return df\n",
    "\n",
    "def display_topic_model_gui(corpus, compute_callback):\n",
    "    \n",
    "    pos_options = [ x for x in DF_TAGSET.POS.unique() if x not in ['PUNCT', '', 'DET', 'X', 'SPACE', 'PART', 'CONJ', 'SYM', 'INTJ', 'PRON']]\n",
    "    # groupby(['POS'])['DESCRIPTION'].apply(list).apply(lambda x: ', '.join(x)).to_dict()\n",
    "    engine_options = { 'gensim LDA': 'gensim_lda', 'gensim LSI': 'gensim_lsi' } #, 'sklearn_lda': 'sklearn_lda'}\n",
    "    normalize_options = { 'None': False, 'Use lemma': 'lemma', 'Lowercase': 'lower'}\n",
    "    ngrams_options = { '1': [1], '1, 2': [1, 2], '1,2,3': [1, 2, 3] }\n",
    "    gui = types.SimpleNamespace(\n",
    "        progress=widgets.IntProgress(value=0, min=0, max=5, step=1, description='', layout=widgets.Layout(width='90%')),\n",
    "        n_topics=widgets.IntSlider(description='#topics', min=5, max=50, value=20, step=1),\n",
    "        min_freq=widgets.IntSlider(description='Min word freq', min=0, max=10, value=2, step=1),\n",
    "        max_iter=widgets.IntSlider(description='Max iterations', min=100, max=1000, value=20, step=10),\n",
    "        ngrams=widgets.Dropdown(description='n-grams', options=ngrams_options, value=[1], layout=widgets.Layout(width='200px')),\n",
    "        normalize=widgets.Dropdown(description='Normalize', options=normalize_options, value='lemma', layout=widgets.Layout(width='200px')),\n",
    "        filter_stops=widgets.ToggleButton(value=True, description='Remove stopword',  tooltip='Filter out stopwords', icon='check'),\n",
    "        filter_nums=widgets.ToggleButton(value=True, description='Remove nums',  tooltip='Filter out stopwords', icon='check'),\n",
    "        named_entities=widgets.ToggleButton(value=False, description='Merge entities',  tooltip='Merge entities', icon='check'),\n",
    "        drop_determiners=widgets.ToggleButton(value=True, description='Drop determiners',  tooltip='Drop determiners', icon='check'),\n",
    "        apply_idf=widgets.ToggleButton(value=False, description='Apply IDF',  tooltip='Apply TF-IDF', icon='check'),\n",
    "        include_pos=widgets.SelectMultiple(description='POS', options=pos_options, value=['NOUN', 'PROPN'], rows=7, layout=widgets.Layout(width='200px')),\n",
    "        method=widgets.Dropdown(description='Engine', options=engine_options, value='gensim_lda', layout=widgets.Layout(width='200px')),\n",
    "        compute=widgets.Button(description='Compute'),\n",
    "        boxes=None,\n",
    "        output = widgets.Output(), # layout={'height': '500px'}),\n",
    "        model=None\n",
    "    )\n",
    "    gui.boxes = widgets.VBox([\n",
    "        gui.progress,\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([\n",
    "                gui.n_topics,\n",
    "                gui.min_freq,\n",
    "                gui.max_iter\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                gui.filter_stops,\n",
    "                gui.filter_nums,\n",
    "                gui.named_entities,\n",
    "                gui.drop_determiners,\n",
    "                gui.apply_idf\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                gui.normalize,\n",
    "                gui.ngrams,\n",
    "                gui.method\n",
    "            ]),\n",
    "            gui.include_pos,\n",
    "            widgets.VBox([\n",
    "                gui.compute\n",
    "            ])\n",
    "        ]),\n",
    "        widgets.VBox([gui.output]), # ,layout=widgets.Layout(top='20px', height='500px',width='100%'))\n",
    "    ])\n",
    "    fx = lambda *args: compute_callback(corpus, gui, *args)\n",
    "    gui.compute.on_click(fx)\n",
    "    return gui\n",
    "    \n",
    "\n",
    "def compute_callback(corpus, gui, *args):\n",
    "\n",
    "    def tick(x=None):\n",
    "        gui.progress.value = gui.progress.value + 1 if x is None else x\n",
    "    \n",
    "    tick(1)\n",
    "    gui.output.clear_output()\n",
    "\n",
    "    with gui.output:\n",
    "        vec_args = dict(apply_idf=gui.apply_idf.value)\n",
    "        term_args = dict(\n",
    "            args=dict(\n",
    "                ngrams=gui.ngrams.value,\n",
    "                named_entities=gui.named_entities.value,\n",
    "                normalize=gui.normalize.value,\n",
    "                as_strings=True\n",
    "            ),\n",
    "            kwargs=dict(\n",
    "                filter_nums=gui.filter_nums.value,\n",
    "                drop_determiners=gui.drop_determiners.value,\n",
    "                min_freq=gui.min_freq.value,\n",
    "                include_pos=gui.include_pos.value,\n",
    "                filter_stops=gui.filter_stops.value,\n",
    "                filter_punct=True\n",
    "            )\n",
    "        )\n",
    "        tm_args = dict(\n",
    "            n_topics=gui.n_topics.value,\n",
    "            max_iter=gui.max_iter.value,\n",
    "            learning_method='online', \n",
    "            n_jobs=1\n",
    "        )\n",
    "        method = gui.method.value\n",
    "        gui.model = compute_topic_model(\n",
    "            corpus=corpus,\n",
    "            tick=tick,\n",
    "            method=method,\n",
    "            vec_args=vec_args,\n",
    "            term_args=term_args,\n",
    "            tm_args=tm_args\n",
    "        )\n",
    "    \n",
    "    gui.output.clear_output()\n",
    "    with gui.output:\n",
    "        display(LdaDataCompiler.get_lda_topics(gui.model.tm_model, n_tokens=20))\n",
    "        \n",
    "TM_GUI_MODEL = display_topic_model_gui(CORPUS, compute_callback)\n",
    "display(TM_GUI_MODEL.boxes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>MODEL</span> Display Named Entities<span style='color: green; float: right'>SKIP</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce89cd72797e46d4be818d087f7136e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Paper', index=322, layout=Layout(width='80%'), options={'107458': 151, '1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Named Entities\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "def display_document_entities_gui(corpus):\n",
    "    \n",
    "    def display_document_entities(document_id, corpus):\n",
    "        displacy.render(corpus[document_id].spacy_doc, style='ent', jupyter=True)\n",
    "    \n",
    "    df_documents = get_corpus_documents(corpus)\n",
    "\n",
    "    document_widget = widgets.Dropdown(description='Paper', options={v: k for k, v in df_documents['title'].to_dict().items()}, value=0, layout=widgets.Layout(width='80%'))\n",
    "\n",
    "    itw = widgets.interactive(display_document_entities,document_id=document_widget, corpus=widgets.fixed(corpus))\n",
    "\n",
    "    display(widgets.VBox([document_widget, widgets.VBox([itw.children[-1]],layout=widgets.Layout(margin_top='20px', height='500px',width='100%'))]))\n",
    "\n",
    "    itw.update()\n",
    "    \n",
    "try:\n",
    "    display_document_entities_gui(CORPUS)\n",
    "except Except as ex:\n",
    "    logger.error(ec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic's Word Distribution as a Wordcloud<span style='color: red; float: right'>TRY IT</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749bc07290644f42b54d9a43f6f02aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='tx02'></span>\", placeholder=''), HBox(children=(Button(description='<<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display LDA topic's token wordcloud\n",
    "opts = { 'max_font_size': 100, 'background_color': 'white', 'width': 900, 'height': 600 }\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "import common.widgets_utility as widgets_utility\n",
    "\n",
    "def display_wordcloud_gui(callback, tm_data, text_id, output_options=None, word_count=(1, 100, 50)):\n",
    "    model = tm_data.tm_model\n",
    "    output_options = output_options or []\n",
    "    wf = widgets_utility.wf\n",
    "    wc = widgets_utility.WidgetUtility(\n",
    "        n_topics=model.num_topics,\n",
    "        text_id=text_id,\n",
    "        text=wf.create_text_widget(text_id),\n",
    "        topic_id=widgets.IntSlider(\n",
    "            description='Topic ID', min=0, max=model.num_topics - 1, step=1, value=0, continuous_update=False),\n",
    "        word_count=widgets.IntSlider(\n",
    "            description='#Words', min=word_count[0], max=word_count[1], step=1, value=word_count[2], continuous_update=False),\n",
    "        output_format=wf.create_select_widget('Format', output_options, default=output_options[0], layout=widgets.Layout(width=\"200px\")),\n",
    "        progress = widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\"))\n",
    "    )\n",
    "\n",
    "    wc.prev_topic_id = wc.create_prev_id_button('topic_id', model.num_topics)\n",
    "    wc.next_topic_id = wc.create_next_id_button('topic_id', model.num_topics)\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        callback,\n",
    "        tm_data=widgets.fixed(tm_data),\n",
    "        topic_id=wc.topic_id,\n",
    "        n_words=wc.word_count,\n",
    "        output_format=wc.output_format,\n",
    "        widget_container=widgets.fixed(wc)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        wc.text,\n",
    "        widgets.HBox([wc.prev_topic_id, wc.next_topic_id, wc.topic_id, wc.word_count, wc.output_format]),\n",
    "        wc.progress,\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "\n",
    "def plot_wordcloud(df_data, token='token', weight='weight', figsize=(14, 14/1.618), **args):\n",
    "    token_weights = dict({ tuple(x) for x in df_data[[token, weight]].values })\n",
    "    image = wordcloud.WordCloud(**args,)\n",
    "    image.fit_words(token_weights)\n",
    "    plt.figure(figsize=figsize) #, dpi=100)\n",
    "    plt.imshow(image, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def display_wordcloud(\n",
    "    tm_data,\n",
    "    topic_id=0,\n",
    "    n_words=100,\n",
    "    output_format='Wordcloud',\n",
    "    widget_container=None\n",
    "):\n",
    "    container = tm_data.compiled_data\n",
    "    widget_container.progress.value = 1\n",
    "    df_temp = container.topic_token_weights.loc[(container.topic_token_weights.topic_id == topic_id)]\n",
    "    tokens = LdaDataCompiler.get_topic_title(container.topic_token_weights, topic_id, n_words=n_words)\n",
    "    widget_container.value = 2\n",
    "    widget_container.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "    if output_format == 'Wordcloud':\n",
    "        plot_wordcloud(df_temp, 'token', 'weight', max_words=n_words, **opts)\n",
    "    elif output_format == 'Table':\n",
    "        widget_container.progress.value = 3\n",
    "        df_temp = LdaDataCompiler.get_topic_tokens(container.topic_token_weights, topic_id=topic_id, n_words=n_words)\n",
    "        widget_container.progress.value = 4\n",
    "        display(HTML(df_temp.to_html()))\n",
    "    else:\n",
    "        display(pivot_ui(LdaDataCompiler.get_topic_tokens(topic_id, n_words)))\n",
    "    widget_container.progress.value = 0\n",
    "\n",
    "try:\n",
    "    tm_data = get_current_model()\n",
    "    display_wordcloud_gui(display_wordcloud, tm_data, 'tx02', ['Wordcloud', 'Table', 'Pivot'])\n",
    "except TopicModelNotComputed as ex:\n",
    "    logger.info(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic's Word Distribution as a Chart<span style='color: red; float: right'>TRY IT</span>\n",
    "The following chart shows the word distribution for each selected topic. You can zoom in on the left chart. The distribution seems to follow [Zipf's law](https://en.wikipedia.org/wiki/Zipf%27s_law) as (perhaps) expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27a7562f3134994bb1a458c574f2777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='wc01'></span>\", placeholder=''), HBox(children=(Button(description='<<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display topic's word distribution\n",
    "import numpy as np\n",
    "\n",
    "def plot_topic_word_distribution(tokens, **args):\n",
    "\n",
    "    source = bokeh.models.ColumnDataSource(tokens)\n",
    "\n",
    "    p = bokeh.plotting.figure(toolbar_location=\"right\", **args)\n",
    "\n",
    "    cr = p.circle(x='xs', y='ys', source=source)\n",
    "\n",
    "    label_style = dict(level='overlay', text_font_size='8pt', angle=np.pi/6.0)\n",
    "\n",
    "    text_aligns = ['left', 'right']\n",
    "    for i in [0, 1]:\n",
    "        label_source = bokeh.models.ColumnDataSource(tokens.iloc[i::2])\n",
    "        labels = bokeh.models.LabelSet(x='xs', y='ys', text_align=text_aligns[i], text='token', text_baseline='middle',\n",
    "                          y_offset=5*(1 if i == 0 else -1),\n",
    "                          x_offset=5*(1 if i == 0 else -1),\n",
    "                          source=label_source, **label_style)\n",
    "        p.add_layout(labels)\n",
    "\n",
    "    p.xaxis[0].axis_label = 'Token #'\n",
    "    p.yaxis[0].axis_label = 'Probability%'\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"6pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    return p\n",
    "\n",
    "def display_topic_tokens(tm_data, topic_id=0, n_words=100, output_format='Chart', widget_container=None):\n",
    "    widget_container.forward()\n",
    "    container = tm_data.compiled_data\n",
    "    tokens = LdaDataCompiler.get_topic_tokens(container.topic_token_weights, topic_id=topic_id).\\\n",
    "        copy()\\\n",
    "        .drop('topic_id', axis=1)\\\n",
    "        .assign(weight=lambda x: 100.0 * x.weight)\\\n",
    "        .sort_values('weight', axis=0, ascending=False)\\\n",
    "        .reset_index()\\\n",
    "        .head(n_words)\n",
    "    if output_format == 'Chart':\n",
    "        widget_container.forward()\n",
    "        tokens = tokens.assign(xs=tokens.index, ys=tokens.weight)\n",
    "        p = plot_topic_word_distribution(tokens, plot_width=1000, plot_height=500, title='', tools='box_zoom,wheel_zoom,pan,reset')\n",
    "        bokeh.plotting.show(p)\n",
    "        widget_container.forward()\n",
    "    elif output_format == 'Table':\n",
    "        #display(tokens)\n",
    "        display(HTML(tokens.to_html()))\n",
    "    else:\n",
    "        display(pivot_ui(tokens))\n",
    "        \n",
    "    # Added code for missing method: widget_container.reset()\n",
    "    if 'progress' in widget_container.__dict__.keys():\n",
    "        widget_container.progress.value = 0\n",
    "    \n",
    "    \n",
    "def display_topic_distribution_widgets(callback, tm_data, text_id, output_options=None, word_count=(1, 100, 50)):\n",
    "    \n",
    "    output_options = output_options or []\n",
    "    model = tm_data.tm_model\n",
    "    wf = widgets_utility.wf\n",
    "    wc = widgets_utility.WidgetUtility(\n",
    "        n_topics=model.num_topics,\n",
    "        text_id=text_id,\n",
    "        text=wf.create_text_widget(text_id),\n",
    "        topic_id=widgets.IntSlider(\n",
    "            description='Topic ID', min=0, max=model.num_topics - 1, step=1, value=0, continuous_update=False),\n",
    "        word_count=widgets.IntSlider(\n",
    "            description='#Words', min=word_count[0], max=word_count[1], step=1, value=word_count[2], continuous_update=False),\n",
    "        output_format=wf.create_select_widget('Format', output_options, default=output_options[0], layout=widgets.Layout(width=\"200px\")),\n",
    "        progress = widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\"))\n",
    "    )\n",
    "\n",
    "    wc.prev_topic_id = wc.create_prev_id_button('topic_id', model.num_topics)\n",
    "    wc.next_topic_id = wc.create_next_id_button('topic_id', model.num_topics)\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        callback,\n",
    "        tm_data=widgets.fixed(tm_data),\n",
    "        topic_id=wc.topic_id,\n",
    "        n_words=wc.word_count,\n",
    "        output_format=wc.output_format,\n",
    "        widget_container=widgets.fixed(wc)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        wc.text,\n",
    "        widgets.HBox([wc.prev_topic_id, wc.next_topic_id, wc.topic_id, wc.word_count, wc.output_format]),\n",
    "        wc.progress,\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "TM_DATA = TM_GUI_MODEL.model\n",
    "\n",
    "display_topic_distribution_widgets(display_topic_tokens, TM_DATA, 'wc01', ['Chart', 'Table'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic's Trend Over Time or Documents<span style='color: red; float: right'>RUN</span>\n",
    "- Displays topic's share over documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cabdf647c2e46b393964842f7b9a3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='topic_share_plot'></span>\", placeholder=''), HBox(children=(Button(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a topic's yearly weight over time in selected LDA topic model\n",
    "#import numpy as np\n",
    "#import math\n",
    "#import bokeh.plotting\n",
    "#from bokeh.models import ColumnDataSource, DataRange1d, Plot, LinearAxis, Grid\n",
    "#from bokeh.models.glyphs import VBar\n",
    "#from bokeh.io import curdoc, show\n",
    "\n",
    "def slim_title(x):\n",
    "    try:\n",
    "        m = re.match('.*\\((.*)\\)$', x).groups()\n",
    "        if m is not None and len(m) > 0:\n",
    "            return m[0]\n",
    "        return ' '.join(x.split(' ')[:3]) + '...'\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "import math\n",
    "\n",
    "def plot_topic_trend(df, pivot_column, value_column, x_label=None, y_label=None):\n",
    "    tools = \"pan,wheel_zoom,box_zoom,reset,previewsave\"\n",
    "\n",
    "    xs = df[pivot_column].astype(np.str)\n",
    "    p = bokeh.plotting.figure(x_range=xs, plot_width=1000, plot_height=700, title='', tools=tools, toolbar_location=\"right\")\n",
    "\n",
    "    glyph = p.vbar(x=xs, top=df[value_column], width=0.5, fill_color=\"#b3de69\")\n",
    "    p.xaxis.major_label_orientation = math.pi/4\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.xaxis[0].axis_label = (x_label or '').title()\n",
    "    p.yaxis[0].axis_label = (y_label or '').title()\n",
    "    p.y_range.start = 0.0\n",
    "    #p.y_range.end = 1.0\n",
    "    p.x_range.range_padding = 0.01\n",
    "    return p\n",
    "\n",
    "def display_topic_trend(topic_id, widgets_container, output_format='Chart', tm_data=None, threshold=0.01):\n",
    "    container = tm_data.compiled_data\n",
    "    tokens = LdaDataCompiler.get_topic_title(container.topic_token_weights, topic_id, n_words=200)\n",
    "    widgets_container.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "    value_column = 'weight'\n",
    "    category_column = 'author'\n",
    "    df = container.document_topic_weights[(container.document_topic_weights.topic_id==topic_id)]\n",
    "    df = df[(df.weight > threshold)].reset_index()\n",
    "    df[category_column] = df.title.apply(slim_title)\n",
    "\n",
    "    if output_format == 'Table':\n",
    "        display(df)\n",
    "    else:\n",
    "        x_label = category_column.title()\n",
    "        y_label = value_column.title()\n",
    "        p = plot_topic_trend(df, category_column, value_column, x_label=x_label, y_label=y_label)\n",
    "        bokeh.plotting.show(p)\n",
    "\n",
    "def create_topic_trend_widgets(tm_data):\n",
    "    \n",
    "    model = tm_data.tm_model\n",
    "    wf = widgets_utility.wf\n",
    "    wc = widgets_utility.WidgetUtility(\n",
    "        n_topics=model.num_topics,\n",
    "        text_id='topic_share_plot',\n",
    "        text=wf.create_text_widget('topic_share_plot'),\n",
    "        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=0.25, step=0.01, value=0.10, continuous_update=False),\n",
    "        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=model.num_topics - 1, step=1, value=0, continuous_update=False),\n",
    "        output_format=wf.create_select_widget('Format', ['Chart', 'Table'], default='Chart'),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"50%\")),\n",
    "    )\n",
    "\n",
    "    wc.prev_topic_id = wc.create_prev_id_button('topic_id', model.num_topics)\n",
    "    wc.next_topic_id = wc.create_next_id_button('topic_id', model.num_topics)\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        display_topic_trend,\n",
    "        topic_id=wc.topic_id,\n",
    "        widgets_container=widgets.fixed(wc),\n",
    "        output_format=wc.output_format,\n",
    "        tm_data=widgets.fixed(tm_data),\n",
    "        threshold=wc.threshold\n",
    "    )\n",
    "    display(widgets.VBox([\n",
    "        wc.text,\n",
    "        widgets.HBox([wc.prev_topic_id, wc.next_topic_id, wc.output_format]),\n",
    "        widgets.HBox([wc.topic_id, wc.threshold, wc.progress]),\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "    \n",
    "    iw.update()\n",
    "\n",
    "tm_data = get_current_model()\n",
    "create_topic_trend_widgets(tm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic to Document Network<span style='color: red; float: right'>TRY IT</span>\n",
    "The green nodes are documents, and blue nodes are topics. The edges (lines) indicates the strength of a topic in the connected document. The width of the edge is proportinal to the strength of the connection. Note that only edges with a strength above the certain threshold are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2613df7b9b4b71a5b38413df4e43c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='nx_id1'></span>\", placeholder=''), HBox(children=(Dropdown(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize year-to-topic network by means of topic-document-weights\n",
    "from common.plot_utility import layout_algorithms, PlotNetworkUtility\n",
    "from common.network_utility import NetworkUtility, DISTANCE_METRICS, NetworkMetricHelper\n",
    "\n",
    "\n",
    "\n",
    "def plot_document_topic_network(network, layout, scale=1.0, titles=None):\n",
    "    tools = \"pan,wheel_zoom,box_zoom,reset,hover,previewsave\"\n",
    "    year_nodes, topic_nodes = NetworkUtility.get_bipartite_node_set(network, bipartite=0)  \n",
    "    \n",
    "    year_source = NetworkUtility.get_node_subset_source(network, layout, year_nodes)\n",
    "    topic_source = NetworkUtility.get_node_subset_source(network, layout, topic_nodes)\n",
    "    lines_source = NetworkUtility.get_edges_source(network, layout, scale=6.0, normalize=False)\n",
    "    \n",
    "    edges_alphas = NetworkMetricHelper.compute_alpha_vector(lines_source.data['weights'])\n",
    "    \n",
    "    lines_source.add(edges_alphas, 'alphas')\n",
    "    \n",
    "    p = bokeh.plotting.figure(plot_width=1000, plot_height=600, x_axis_type=None, y_axis_type=None, tools=tools)\n",
    "    \n",
    "    r_lines = p.multi_line(\n",
    "        'xs', 'ys', line_width='weights', alpha='alphas', color='black', source=lines_source\n",
    "    )\n",
    "    r_years = p.circle(\n",
    "        'x','y', size=40, source=year_source, color='lightgreen', level='overlay', line_width=1,alpha=1.0\n",
    "    )\n",
    "    \n",
    "    r_topics = p.circle('x','y', size=25, source=topic_source, color='skyblue', level='overlay', alpha=1.00)\n",
    "    \n",
    "    p.add_tools(bokeh.models.HoverTool(renderers=[r_topics], tooltips=None, callback=widgets_utility.wf.\\\n",
    "        glyph_hover_callback(topic_source, 'node_id', text_ids=titles.index, text=titles, element_id='nx_id1'))\n",
    "    )\n",
    "\n",
    "    text_opts = dict(x='x', y='y', text='name', level='overlay', x_offset=0, y_offset=0, text_font_size='8pt')\n",
    "    \n",
    "    p.add_layout(\n",
    "        bokeh.models.LabelSet(\n",
    "            source=year_source, text_color='black', text_align='center', text_baseline='middle', **text_opts\n",
    "        )\n",
    "    )\n",
    "    p.add_layout(\n",
    "        bokeh.models.LabelSet(\n",
    "            source=topic_source, text_color='black', text_align='center', text_baseline='middle', **text_opts\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return p\n",
    "\n",
    "def main_topic_network(tm_data):\n",
    "    \n",
    "    model = tm_data.tm_model\n",
    "    text_id = 'nx_id1'\n",
    "    layout_options = [ 'Circular', 'Kamada-Kawai', 'Fruchterman-Reingold']\n",
    "    text_widget = widgets_utility.wf.create_text_widget(text_id)  # style=\"display: inline; height='400px'\"),\n",
    "    scale_widget = widgets.FloatSlider(description='Scale', min=0.0, max=1.0, step=0.01, value=0.1, continues_update=False)\n",
    "    threshold_widget = widgets.FloatSlider(description='Threshold', min=0.0, max=1.0, step=0.01, value=0.50, continues_update=False)\n",
    "    output_format_widget = widgets_utility.dropdown('Output', { 'Network': 'network', 'Table': 'table' }, 'network')\n",
    "    layout_widget = widgets_utility.dropdown('Layout', layout_options, 'Fruchterman-Reingold')\n",
    "    progress_widget = widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"40%\"))\n",
    "    \n",
    "    def tick(x=None):\n",
    "        progress_widget.value = progress_widget.value + 1 if x is None else x\n",
    "        \n",
    "    def display_topic_network(layout_algorithm, tm_data, threshold=0.10, scale=1.0, output_format='network'):\n",
    "            \n",
    "        tick(1)\n",
    "        container = tm_data.compiled_data\n",
    "        titles = LdaDataCompiler.get_topic_titles(container.topic_token_weights)\n",
    "\n",
    "        df = container.document_topic_weights[container.document_topic_weights.weight > threshold].reset_index()\n",
    "        \n",
    "        df['slim_title'] = df.title.apply(slim_title)\n",
    "        network = NetworkUtility.create_bipartite_network(df, 'slim_title', 'topic_id')\n",
    "        \n",
    "        tick()\n",
    "\n",
    "        if output_format == 'network':\n",
    "            \n",
    "            args = PlotNetworkUtility.layout_args(layout_algorithm, network, scale)\n",
    "            layout = (layout_algorithms[layout_algorithm])(network, **args)\n",
    "            \n",
    "            tick()\n",
    "            \n",
    "            p = plot_document_topic_network(network, layout, scale=scale, titles=titles)\n",
    "            bokeh.plotting.show(p)\n",
    "\n",
    "        elif output_format == 'table':\n",
    "            display(df)\n",
    "        else:\n",
    "            display(pivot_ui(df))\n",
    "\n",
    "        tick(0)\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        display_topic_network,\n",
    "        layout_algorithm=layout_widget,\n",
    "        tm_data=widgets.fixed(tm_data),\n",
    "        threshold=threshold_widget,\n",
    "        scale=scale_widget,\n",
    "        output_format=output_format_widget\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        text_widget,\n",
    "        widgets.HBox([layout_widget, threshold_widget]), \n",
    "        widgets.HBox([output_format_widget, scale_widget, progress_widget]),\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "    iw.update()\n",
    "\n",
    "tm_data = get_current_model()\n",
    "main_topic_network(tm_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Trends - Heatmap\n",
    "- The topic shares  displayed as a scattered heatmap plot using gradient color based on topic's weight in document.\n",
    "- [Stanford’s Termite software](http://vis.stanford.edu/papers/termite) uses a similar visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9241d5c3e58b47fea13cd72936f40c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(ToggleButton(value=True, description='Flip XY', layout=Layout(width='80px'), too…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_topic_relevance_by_year\n",
    "import bokeh.transform\n",
    "\n",
    "def setup_glyph_coloring(df):\n",
    "    max_weight = df.weight.max()\n",
    "    #colors = list(reversed(bokeh.palettes.Greens[9]))\n",
    "    colors = ['#ffffff', '#f7fcf5', '#e5f5e0', '#c7e9c0', '#a1d99b', '#74c476', '#41ab5d', '#238b45', '#006d2c', '#00441b']\n",
    "    mapper = bokeh.models.LinearColorMapper(palette=colors, low=0.0, high=1.0) # low=df.weight.min(), high=max_weight)\n",
    "    color_transform = bokeh.transform.transform('weight', mapper)\n",
    "    color_bar = bokeh.models.ColorBar(color_mapper=mapper, location=(0, 0),\n",
    "                         ticker=bokeh.models.BasicTicker(desired_num_ticks=len(colors)),\n",
    "                         formatter=bokeh.models.PrintfTickFormatter(format=\" %5.2f\"))\n",
    "    return color_transform, color_bar\n",
    "\n",
    "def plot_topic_relevance_by_year(df, xs, ys, flip_axis, glyph, titles, text_id):\n",
    "\n",
    "    line_height = 7\n",
    "    if flip_axis is True:\n",
    "        xs, ys = ys, xs\n",
    "        line_height = 10\n",
    "    \n",
    "    ''' Setup axis categories '''\n",
    "    x_range = list(map(str, df[xs].unique()))\n",
    "    y_range = list(map(str, df[ys].unique()))\n",
    "    \n",
    "    ''' Setup coloring and color bar '''\n",
    "    color_transform, color_bar = setup_glyph_coloring(df)\n",
    "    \n",
    "    source = bokeh.models.ColumnDataSource(df)\n",
    "\n",
    "    plot_height = max(len(y_range) * line_height, 500)\n",
    "    \n",
    "    p = bokeh.plotting.figure(title=\"Topic heatmap\", toolbar_location=\"right\", x_range=x_range,\n",
    "           y_range=y_range, x_axis_location=\"above\", plot_width=1000, plot_height=plot_height)\n",
    "\n",
    "    args = dict(x=xs, y=ys, source=source, alpha=1.0, hover_color='red')\n",
    "    \n",
    "    if glyph == 'Circle':\n",
    "        cr = p.circle(color=color_transform, **args)\n",
    "    else:\n",
    "        cr = p.rect(width=1, height=1, line_color=None, fill_color=color_transform, **args)\n",
    "\n",
    "    p.x_range.range_padding = 0\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"8pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    p.xaxis.major_label_orientation = 1.0\n",
    "    p.add_layout(color_bar, 'right')\n",
    "    \n",
    "    p.add_tools(bokeh.models.HoverTool(tooltips=None, callback=widgets_utility.WidgetUtility.glyph_hover_callback(\n",
    "        source, 'topic_id', titles.index, titles, text_id), renderers=[cr]))\n",
    "    \n",
    "    return p\n",
    "    \n",
    "def display_doc_topic_heatmap(tm_data, key='max', flip_axis=False, glyph='Circle'):\n",
    "    try:\n",
    "        container = tm_data.compiled_data\n",
    "        titles = LdaDataCompiler.get_topic_titles(container.topic_token_weights, n_words=100)\n",
    "        df = container.document_topic_weights.copy().reset_index()\n",
    "        df['document_id'] = df.index.astype(str)\n",
    "        df['topic_id'] = df.topic_id.astype(str)\n",
    "        df['author'] = df.title.apply(slim_title)\n",
    "        p = plot_topic_relevance_by_year(df, xs='author', ys='topic_id', flip_axis=flip_axis, glyph=glyph, titles=titles, text_id='topic_relevance')\n",
    "        bokeh.plotting.show(p)\n",
    "    except Exception as ex:\n",
    "        raise\n",
    "        logger.error(ex)\n",
    "            \n",
    "def doc_topic_heatmap_gui(tm_data):\n",
    "    \n",
    "    def text_widget(element_id=None, default_value='', style='', line_height='20px'):\n",
    "        value = \"<span class='{}' style='line-height: {};{}'>{}</span>\".format(element_id, line_height, style, default_value) if element_id is not None else ''\n",
    "        return widgets.HTML(value=value, placeholder='', description='', layout=widgets.Layout(height='150px'))\n",
    "\n",
    "    text_id = 'topic_relevance'\n",
    "    #text_widget = widgets_utility.wf.create_text_widget(text_id)\n",
    "    text_widget = text_widget(text_id)\n",
    "    glyph = widgets.Dropdown(options=['Circle', 'Square'], value='Square', description='Glyph', layout=widgets.Layout(width=\"180px\"))\n",
    "    flip_axis = widgets.ToggleButton(value=True, description='Flip XY', tooltip='Flip X and Y axis', icon='', layout=widgets.Layout(width=\"80px\"))\n",
    "\n",
    "    iw = widgets.interactive(display_doc_topic_heatmap, tm_data=widgets.fixed(tm_data), glyph=glyph, flip_axis=flip_axis)\n",
    "\n",
    "    display(widgets.VBox([widgets.HBox([flip_axis, glyph ]), text_widget, iw.children[-1]]))\n",
    "\n",
    "    iw.update()\n",
    "\n",
    "doc_topic_heatmap_gui(get_current_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD STUFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame Corpus from spaCy Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203df9b55a12495db952a70fea0e878e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, layout=Layout(width='95%'), max=483)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def document_statistics(spacy_doc):\n",
    "    \n",
    "    spacy_sentences = list(spacy_doc.sents)\n",
    "    token_length_histogram = collections.Counter((len(x) for x in spacy_doc))\n",
    "    \n",
    "    return {\n",
    "        'word_count': len(spacy_doc),\n",
    "        'sentence_count': len(spacy_sentences),\n",
    "        'avg_words_per_sentence': len(spacy_doc) / len(spacy_sentences),\n",
    "        'token_lengths': dict(token_length_histogram)\n",
    "    }\n",
    "\n",
    "def doc_to_dataframe(treaty_id, spacy_doc, include_pos=None, ignore_pos=None):\n",
    "    include_pos = include_pos or []\n",
    "    ignore_pos = ignore_pos or []\n",
    "    df_source = ({\n",
    "        \"treaty_id\": treaty_id,\n",
    "        \"text\": w.text.lower(),\n",
    "        \"lemma\": w.lemma_.lower(),\n",
    "        \"pos\": w.pos_,\n",
    "        # \"tag\": w.tag_,\n",
    "        # \"dep\": w.dep_,\n",
    "        \"is_alpha\": w.is_alpha,\n",
    "        \"is_stop\": w.is_stop\n",
    "    } for w in spacy_doc\n",
    "        if w.pos_ in include_pos\n",
    "        and w.pos_ not in ignore_pos)\n",
    "    return pd.DataFrame(df_source)\n",
    "\n",
    "def create_dataframe_corpus(corpus, include_pos=None, ignore_pos=None, ticker=utility.noop):\n",
    "    \n",
    "    df_corpus = None\n",
    "    try:\n",
    "        for doc in corpus:\n",
    "            df = doc_to_dataframe(doc.metadata['treaty_id'], doc.spacy_doc, include_pos=include_pos, ignore_pos=ignore_pos)\n",
    "            if df_corpus is None:\n",
    "                df_corpus = df\n",
    "            else:\n",
    "                df_corpus = df_corpus.append(df, ignore_index=True)\n",
    "            tick()\n",
    "    finally:\n",
    "        tick(0)\n",
    "    return df_corpus\n",
    "\n",
    "progress_widget = widgets.IntProgress(min=0,max=len(CORPUS),step=1, layout=widgets.Layout(width='95%'))\n",
    "display(progress_widget)\n",
    "\n",
    "def ticker(w):\n",
    "    def tick(x=None):\n",
    "        w.value = w.value + 1 if x is None else x\n",
    "    return tick\n",
    "\n",
    "tick = ticker(progress_widget)\n",
    "df_corpus = create_dataframe_corpus(CORPUS, include_pos=('NOUN', 'PROPN', 'VERB'), ticker=tick)\n",
    "df_corpus.to_csv('spaCy_PoS_corpus.csv', sep='\\t', encoding='utf-8') # , compression='zip')\n",
    "df_documents = pd.DataFrame([ x.metadata for x in CORPUS]).set_index('treaty_id')\n",
    "# df_corpus2 = pd.read_csv('spaCy_PoS_corpus.csv', index_col=0, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_corpus.merge(df_documents, left_on='treaty_id', right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fade22d2e10>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"281.74625pt\" version=\"1.1\" viewBox=\"0 0 378.7875 281.74625\" width=\"378.7875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 281.74625 \n",
       "L 378.7875 281.74625 \n",
       "L 378.7875 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 33.2875 228.14 \n",
       "L 368.0875 228.14 \n",
       "L 368.0875 10.7 \n",
       "L 33.2875 10.7 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 36.276786 228.14 \n",
       "L 42.255357 228.14 \n",
       "L 42.255357 226.547033 \n",
       "L 36.276786 226.547033 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 48.233929 228.14 \n",
       "L 54.2125 228.14 \n",
       "L 54.2125 205.838462 \n",
       "L 48.233929 205.838462 \n",
       "z\n",
       "\" style=\"fill:#ff7f0e;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 60.191071 228.14 \n",
       "L 66.169643 228.14 \n",
       "L 66.169643 129.376044 \n",
       "L 60.191071 129.376044 \n",
       "z\n",
       "\" style=\"fill:#2ca02c;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 72.148214 228.14 \n",
       "L 78.126786 228.14 \n",
       "L 78.126786 199.466593 \n",
       "L 72.148214 199.466593 \n",
       "z\n",
       "\" style=\"fill:#d62728;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_7\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 84.105357 228.14 \n",
       "L 90.083929 228.14 \n",
       "L 90.083929 218.582198 \n",
       "L 84.105357 218.582198 \n",
       "z\n",
       "\" style=\"fill:#9467bd;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 96.0625 228.14 \n",
       "L 102.041071 228.14 \n",
       "L 102.041071 226.547033 \n",
       "L 96.0625 226.547033 \n",
       "z\n",
       "\" style=\"fill:#8c564b;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 108.019643 228.14 \n",
       "L 113.998214 228.14 \n",
       "L 113.998214 213.803297 \n",
       "L 108.019643 213.803297 \n",
       "z\n",
       "\" style=\"fill:#e377c2;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 119.976786 228.14 \n",
       "L 125.955357 228.14 \n",
       "L 125.955357 194.687692 \n",
       "L 119.976786 194.687692 \n",
       "z\n",
       "\" style=\"fill:#7f7f7f;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 131.933929 228.14 \n",
       "L 137.9125 228.14 \n",
       "L 137.9125 197.873626 \n",
       "L 131.933929 197.873626 \n",
       "z\n",
       "\" style=\"fill:#bcbd22;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 143.891071 228.14 \n",
       "L 149.869643 228.14 \n",
       "L 149.869643 191.501758 \n",
       "L 143.891071 191.501758 \n",
       "z\n",
       "\" style=\"fill:#17becf;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 155.848214 228.14 \n",
       "L 161.826786 228.14 \n",
       "L 161.826786 201.05956 \n",
       "L 155.848214 201.05956 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 167.805357 228.14 \n",
       "L 173.783929 228.14 \n",
       "L 173.783929 60.878462 \n",
       "L 167.805357 60.878462 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 179.7625 228.14 \n",
       "L 185.741071 228.14 \n",
       "L 185.741071 115.039341 \n",
       "L 179.7625 115.039341 \n",
       "z\n",
       "\" style=\"fill:#ff7f0e;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 191.719643 228.14 \n",
       "L 197.698214 228.14 \n",
       "L 197.698214 172.386154 \n",
       "L 191.719643 172.386154 \n",
       "z\n",
       "\" style=\"fill:#2ca02c;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_17\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 203.676786 228.14 \n",
       "L 209.655357 228.14 \n",
       "L 209.655357 140.526813 \n",
       "L 203.676786 140.526813 \n",
       "z\n",
       "\" style=\"fill:#d62728;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 215.633929 228.14 \n",
       "L 221.6125 228.14 \n",
       "L 221.6125 91.144835 \n",
       "L 215.633929 91.144835 \n",
       "z\n",
       "\" style=\"fill:#9467bd;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_19\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 227.591071 228.14 \n",
       "L 233.569643 228.14 \n",
       "L 233.569643 36.983956 \n",
       "L 227.591071 36.983956 \n",
       "z\n",
       "\" style=\"fill:#8c564b;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_20\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 239.548214 228.14 \n",
       "L 245.526786 228.14 \n",
       "L 245.526786 150.084615 \n",
       "L 239.548214 150.084615 \n",
       "z\n",
       "\" style=\"fill:#e377c2;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_21\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 251.505357 228.14 \n",
       "L 257.483929 228.14 \n",
       "L 257.483929 127.783077 \n",
       "L 251.505357 127.783077 \n",
       "z\n",
       "\" style=\"fill:#7f7f7f;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_22\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 263.4625 228.14 \n",
       "L 269.441071 228.14 \n",
       "L 269.441071 100.702637 \n",
       "L 263.4625 100.702637 \n",
       "z\n",
       "\" style=\"fill:#bcbd22;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_23\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 275.419643 228.14 \n",
       "L 281.398214 228.14 \n",
       "L 281.398214 115.039341 \n",
       "L 275.419643 115.039341 \n",
       "z\n",
       "\" style=\"fill:#17becf;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_24\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 287.376786 228.14 \n",
       "L 293.355357 228.14 \n",
       "L 293.355357 21.054286 \n",
       "L 287.376786 21.054286 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_25\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 299.333929 228.14 \n",
       "L 305.3125 228.14 \n",
       "L 305.3125 60.878462 \n",
       "L 299.333929 60.878462 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_26\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 311.291071 228.14 \n",
       "L 317.269643 228.14 \n",
       "L 317.269643 43.355824 \n",
       "L 311.291071 43.355824 \n",
       "z\n",
       "\" style=\"fill:#ff7f0e;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_27\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 323.248214 228.14 \n",
       "L 329.226786 228.14 \n",
       "L 329.226786 91.144835 \n",
       "L 323.248214 91.144835 \n",
       "z\n",
       "\" style=\"fill:#2ca02c;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_28\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 335.205357 228.14 \n",
       "L 341.183929 228.14 \n",
       "L 341.183929 124.597143 \n",
       "L 335.205357 124.597143 \n",
       "z\n",
       "\" style=\"fill:#d62728;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_29\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 347.1625 228.14 \n",
       "L 353.141071 228.14 \n",
       "L 353.141071 137.340879 \n",
       "L 347.1625 137.340879 \n",
       "z\n",
       "\" style=\"fill:#9467bd;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_30\">\n",
       "    <path clip-path=\"url(#p935e5c497c)\" d=\"M 359.119643 228.14 \n",
       "L 365.098214 228.14 \n",
       "L 365.098214 73.622198 \n",
       "L 359.119643 73.622198 \n",
       "z\n",
       "\" style=\"fill:#8c564b;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m11b205f492\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.266071\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 1945 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       <path d=\"M 10.984375 1.515625 \n",
       "L 10.984375 10.5 \n",
       "Q 14.703125 8.734375 18.5 7.8125 \n",
       "Q 22.3125 6.890625 25.984375 6.890625 \n",
       "Q 35.75 6.890625 40.890625 13.453125 \n",
       "Q 46.046875 20.015625 46.78125 33.40625 \n",
       "Q 43.953125 29.203125 39.59375 26.953125 \n",
       "Q 35.25 24.703125 29.984375 24.703125 \n",
       "Q 19.046875 24.703125 12.671875 31.3125 \n",
       "Q 6.296875 37.9375 6.296875 49.421875 \n",
       "Q 6.296875 60.640625 12.9375 67.421875 \n",
       "Q 19.578125 74.21875 30.609375 74.21875 \n",
       "Q 43.265625 74.21875 49.921875 64.515625 \n",
       "Q 56.59375 54.828125 56.59375 36.375 \n",
       "Q 56.59375 19.140625 48.40625 8.859375 \n",
       "Q 40.234375 -1.421875 26.421875 -1.421875 \n",
       "Q 22.703125 -1.421875 18.890625 -0.6875 \n",
       "Q 15.09375 0.046875 10.984375 1.515625 \n",
       "z\n",
       "M 30.609375 32.421875 \n",
       "Q 37.25 32.421875 41.125 36.953125 \n",
       "Q 45.015625 41.5 45.015625 49.421875 \n",
       "Q 45.015625 57.28125 41.125 61.84375 \n",
       "Q 37.25 66.40625 30.609375 66.40625 \n",
       "Q 23.96875 66.40625 20.09375 61.84375 \n",
       "Q 16.21875 57.28125 16.21875 49.421875 \n",
       "Q 16.21875 41.5 20.09375 36.953125 \n",
       "Q 23.96875 32.421875 30.609375 32.421875 \n",
       "z\n",
       "\" id=\"DejaVuSans-57\"/>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "       <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(42.025446 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.223214\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 1946 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(53.982589 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"63.180357\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 1947 -->\n",
       "      <defs>\n",
       "       <path d=\"M 8.203125 72.90625 \n",
       "L 55.078125 72.90625 \n",
       "L 55.078125 68.703125 \n",
       "L 28.609375 0 \n",
       "L 18.3125 0 \n",
       "L 43.21875 64.59375 \n",
       "L 8.203125 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-55\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(65.939732 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"75.1375\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 1948 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(77.896875 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"87.094643\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 1949 -->\n",
       "      <g transform=\"translate(89.854018 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"99.051786\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1950 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(101.811161 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"111.008929\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 1951 -->\n",
       "      <g transform=\"translate(113.768304 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"122.966071\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 1952 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(125.725446 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"134.923214\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 1953 -->\n",
       "      <defs>\n",
       "       <path d=\"M 40.578125 39.3125 \n",
       "Q 47.65625 37.796875 51.625 33 \n",
       "Q 55.609375 28.21875 55.609375 21.1875 \n",
       "Q 55.609375 10.40625 48.1875 4.484375 \n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \n",
       "Q 12.796875 0.390625 7.625 2.203125 \n",
       "L 7.625 11.71875 \n",
       "Q 11.71875 9.328125 16.59375 8.109375 \n",
       "Q 21.484375 6.890625 26.8125 6.890625 \n",
       "Q 36.078125 6.890625 40.9375 10.546875 \n",
       "Q 45.796875 14.203125 45.796875 21.1875 \n",
       "Q 45.796875 27.640625 41.28125 31.265625 \n",
       "Q 36.765625 34.90625 28.71875 34.90625 \n",
       "L 20.21875 34.90625 \n",
       "L 20.21875 43.015625 \n",
       "L 29.109375 43.015625 \n",
       "Q 36.375 43.015625 40.234375 45.921875 \n",
       "Q 44.09375 48.828125 44.09375 54.296875 \n",
       "Q 44.09375 59.90625 40.109375 62.90625 \n",
       "Q 36.140625 65.921875 28.71875 65.921875 \n",
       "Q 24.65625 65.921875 20.015625 65.03125 \n",
       "Q 15.375 64.15625 9.8125 62.3125 \n",
       "L 9.8125 71.09375 \n",
       "Q 15.4375 72.65625 20.34375 73.4375 \n",
       "Q 25.25 74.21875 29.59375 74.21875 \n",
       "Q 40.828125 74.21875 47.359375 69.109375 \n",
       "Q 53.90625 64.015625 53.90625 55.328125 \n",
       "Q 53.90625 49.265625 50.4375 45.09375 \n",
       "Q 46.96875 40.921875 40.578125 39.3125 \n",
       "z\n",
       "\" id=\"DejaVuSans-51\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(137.682589 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_10\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"146.880357\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 1954 -->\n",
       "      <g transform=\"translate(149.639732 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_11\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"158.8375\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1955 -->\n",
       "      <g transform=\"translate(161.596875 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_12\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"170.794643\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1956 -->\n",
       "      <g transform=\"translate(173.554018 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_13\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"182.751786\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 1957 -->\n",
       "      <g transform=\"translate(185.511161 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_14\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"194.708929\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 1958 -->\n",
       "      <g transform=\"translate(197.468304 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_15\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"206.666071\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 1959 -->\n",
       "      <g transform=\"translate(209.425446 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_16\">\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.623214\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 1960 -->\n",
       "      <g transform=\"translate(221.382589 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_17\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.580357\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_17\">\n",
       "      <!-- 1961 -->\n",
       "      <g transform=\"translate(233.339732 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_18\">\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"242.5375\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_18\">\n",
       "      <!-- 1962 -->\n",
       "      <g transform=\"translate(245.296875 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_19\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"254.494643\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- 1963 -->\n",
       "      <g transform=\"translate(257.254018 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_20\">\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"266.451786\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_20\">\n",
       "      <!-- 1964 -->\n",
       "      <g transform=\"translate(269.211161 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_21\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"278.408929\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_21\">\n",
       "      <!-- 1965 -->\n",
       "      <g transform=\"translate(281.168304 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_22\">\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"290.366071\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_22\">\n",
       "      <!-- 1966 -->\n",
       "      <g transform=\"translate(293.125446 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_23\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.323214\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_23\">\n",
       "      <!-- 1967 -->\n",
       "      <g transform=\"translate(305.082589 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_24\">\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"314.280357\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_24\">\n",
       "      <!-- 1968 -->\n",
       "      <g transform=\"translate(317.039732 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_25\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"326.2375\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_25\">\n",
       "      <!-- 1969 -->\n",
       "      <g transform=\"translate(328.996875 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_26\">\n",
       "     <g id=\"line2d_26\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"338.194643\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_26\">\n",
       "      <!-- 1970 -->\n",
       "      <g transform=\"translate(340.954018 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_27\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"350.151786\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_27\">\n",
       "      <!-- 1971 -->\n",
       "      <g transform=\"translate(352.911161 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_28\">\n",
       "     <g id=\"line2d_28\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"362.108929\" xlink:href=\"#m11b205f492\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_28\">\n",
       "      <!-- 1972 -->\n",
       "      <g transform=\"translate(364.868304 260.59)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_29\">\n",
       "     <!-- signed_year -->\n",
       "     <defs>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "      <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "      <path d=\"M 45.40625 27.984375 \n",
       "Q 45.40625 37.75 41.375 43.109375 \n",
       "Q 37.359375 48.484375 30.078125 48.484375 \n",
       "Q 22.859375 48.484375 18.828125 43.109375 \n",
       "Q 14.796875 37.75 14.796875 27.984375 \n",
       "Q 14.796875 18.265625 18.828125 12.890625 \n",
       "Q 22.859375 7.515625 30.078125 7.515625 \n",
       "Q 37.359375 7.515625 41.375 12.890625 \n",
       "Q 45.40625 18.265625 45.40625 27.984375 \n",
       "z\n",
       "M 54.390625 6.78125 \n",
       "Q 54.390625 -7.171875 48.1875 -13.984375 \n",
       "Q 42 -20.796875 29.203125 -20.796875 \n",
       "Q 24.46875 -20.796875 20.265625 -20.09375 \n",
       "Q 16.0625 -19.390625 12.109375 -17.921875 \n",
       "L 12.109375 -9.1875 \n",
       "Q 16.0625 -11.328125 19.921875 -12.34375 \n",
       "Q 23.78125 -13.375 27.78125 -13.375 \n",
       "Q 36.625 -13.375 41.015625 -8.765625 \n",
       "Q 45.40625 -4.15625 45.40625 5.171875 \n",
       "L 45.40625 9.625 \n",
       "Q 42.625 4.78125 38.28125 2.390625 \n",
       "Q 33.9375 0 27.875 0 \n",
       "Q 17.828125 0 11.671875 7.65625 \n",
       "Q 5.515625 15.328125 5.515625 27.984375 \n",
       "Q 5.515625 40.671875 11.671875 48.328125 \n",
       "Q 17.828125 56 27.875 56 \n",
       "Q 33.9375 56 38.28125 53.609375 \n",
       "Q 42.625 51.21875 45.40625 46.390625 \n",
       "L 45.40625 54.6875 \n",
       "L 54.390625 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-103\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "      <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "      <path d=\"M 45.40625 46.390625 \n",
       "L 45.40625 75.984375 \n",
       "L 54.390625 75.984375 \n",
       "L 54.390625 0 \n",
       "L 45.40625 0 \n",
       "L 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "z\n",
       "M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-100\"/>\n",
       "      <path d=\"M 50.984375 -16.609375 \n",
       "L 50.984375 -23.578125 \n",
       "L -0.984375 -23.578125 \n",
       "L -0.984375 -16.609375 \n",
       "z\n",
       "\" id=\"DejaVuSans-95\"/>\n",
       "      <path d=\"M 32.171875 -5.078125 \n",
       "Q 28.375 -14.84375 24.75 -17.8125 \n",
       "Q 21.140625 -20.796875 15.09375 -20.796875 \n",
       "L 7.90625 -20.796875 \n",
       "L 7.90625 -13.28125 \n",
       "L 13.1875 -13.28125 \n",
       "Q 16.890625 -13.28125 18.9375 -11.515625 \n",
       "Q 21 -9.765625 23.484375 -3.21875 \n",
       "L 25.09375 0.875 \n",
       "L 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 11.921875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-121\"/>\n",
       "      <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "      <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(170.444531 272.188437)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"52.099609\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"79.882812\" xlink:href=\"#DejaVuSans-103\"/>\n",
       "      <use x=\"143.359375\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"206.738281\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"268.261719\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"331.738281\" xlink:href=\"#DejaVuSans-95\"/>\n",
       "      <use x=\"381.738281\" xlink:href=\"#DejaVuSans-121\"/>\n",
       "      <use x=\"440.917969\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"502.441406\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"563.720703\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"mfedfe08684\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfedfe08684\" y=\"228.14\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_30\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(19.925 231.939219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_30\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfedfe08684\" y=\"196.280659\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_31\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(13.5625 200.079878)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_31\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfedfe08684\" y=\"164.421319\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_32\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(13.5625 168.220537)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_32\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfedfe08684\" y=\"132.561978\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_33\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(13.5625 136.361197)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_33\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfedfe08684\" y=\"100.702637\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_34\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(13.5625 104.501856)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_34\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfedfe08684\" y=\"68.843297\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_35\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(7.2 72.642515)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_35\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mfedfe08684\" y=\"36.983956\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_36\">\n",
       "      <!-- 120 -->\n",
       "      <g transform=\"translate(7.2 40.783175)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_31\">\n",
       "    <path d=\"M 33.2875 228.14 \n",
       "L 33.2875 10.7 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_32\">\n",
       "    <path d=\"M 368.0875 228.14 \n",
       "L 368.0875 10.7 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_33\">\n",
       "    <path d=\"M 33.2875 228.14 \n",
       "L 368.0875 228.14 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_34\">\n",
       "    <path d=\"M 33.2875 10.7 \n",
       "L 368.0875 10.7 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p935e5c497c\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"10.7\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.loc[df.lemma.isin(['culture', 'cultural'])].groupby(['signed_year']).size().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>text</th>\n",
       "      <th>treaty_id</th>\n",
       "      <th>english</th>\n",
       "      <th>filename</th>\n",
       "      <th>french</th>\n",
       "      <th>headnote</th>\n",
       "      <th>...</th>\n",
       "      <th>party2</th>\n",
       "      <th>signed</th>\n",
       "      <th>signed_period</th>\n",
       "      <th>signed_period_alt</th>\n",
       "      <th>signed_year</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>additional</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>additional</td>\n",
       "      <td>100701</td>\n",
       "      <td>en</td>\n",
       "      <td>100701_en_corr.txt</td>\n",
       "      <td>fr</td>\n",
       "      <td>SCIENTIFIC LITERARY AND EDUCATIONAL RELATIONS</td>\n",
       "      <td>...</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>1945-12-08</td>\n",
       "      <td>1945 to 1955</td>\n",
       "      <td>1945 to 1955</td>\n",
       "      <td>1945</td>\n",
       "      <td>UNTS</td>\n",
       "      <td>PROTOC</td>\n",
       "      <td>7CULT</td>\n",
       "      <td>7CULT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>protocol</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>protocol</td>\n",
       "      <td>100701</td>\n",
       "      <td>en</td>\n",
       "      <td>100701_en_corr.txt</td>\n",
       "      <td>fr</td>\n",
       "      <td>SCIENTIFIC LITERARY AND EDUCATIONAL RELATIONS</td>\n",
       "      <td>...</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>1945-12-08</td>\n",
       "      <td>1945 to 1955</td>\n",
       "      <td>1945 to 1955</td>\n",
       "      <td>1945</td>\n",
       "      <td>UNTS</td>\n",
       "      <td>PROTOC</td>\n",
       "      <td>7CULT</td>\n",
       "      <td>7CULT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>declaration</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>declaration concerning scientific</td>\n",
       "      <td>100701</td>\n",
       "      <td>en</td>\n",
       "      <td>100701_en_corr.txt</td>\n",
       "      <td>fr</td>\n",
       "      <td>SCIENTIFIC LITERARY AND EDUCATIONAL RELATIONS</td>\n",
       "      <td>...</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>1945-12-08</td>\n",
       "      <td>1945 to 1955</td>\n",
       "      <td>1945 to 1955</td>\n",
       "      <td>1945</td>\n",
       "      <td>UNTS</td>\n",
       "      <td>PROTOC</td>\n",
       "      <td>7CULT</td>\n",
       "      <td>7CULT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>literary</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>literary</td>\n",
       "      <td>100701</td>\n",
       "      <td>en</td>\n",
       "      <td>100701_en_corr.txt</td>\n",
       "      <td>fr</td>\n",
       "      <td>SCIENTIFIC LITERARY AND EDUCATIONAL RELATIONS</td>\n",
       "      <td>...</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>1945-12-08</td>\n",
       "      <td>1945 to 1955</td>\n",
       "      <td>1945 to 1955</td>\n",
       "      <td>1945</td>\n",
       "      <td>UNTS</td>\n",
       "      <td>PROTOC</td>\n",
       "      <td>7CULT</td>\n",
       "      <td>7CULT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>educational</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>educational</td>\n",
       "      <td>100701</td>\n",
       "      <td>en</td>\n",
       "      <td>100701_en_corr.txt</td>\n",
       "      <td>fr</td>\n",
       "      <td>SCIENTIFIC LITERARY AND EDUCATIONAL RELATIONS</td>\n",
       "      <td>...</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>1945-12-08</td>\n",
       "      <td>1945 to 1955</td>\n",
       "      <td>1945 to 1955</td>\n",
       "      <td>1945</td>\n",
       "      <td>UNTS</td>\n",
       "      <td>PROTOC</td>\n",
       "      <td>7CULT</td>\n",
       "      <td>7CULT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_alpha  is_stop        lemma    pos                               text  \\\n",
       "0      True    False   additional  PROPN                         additional   \n",
       "1      True    False     protocol  PROPN                           protocol   \n",
       "2     False    False  declaration   NOUN  declaration concerning scientific   \n",
       "3      True    False     literary  PROPN                           literary   \n",
       "4      True    False  educational  PROPN                        educational   \n",
       "\n",
       "  treaty_id english            filename french  \\\n",
       "0    100701      en  100701_en_corr.txt     fr   \n",
       "1    100701      en  100701_en_corr.txt     fr   \n",
       "2    100701      en  100701_en_corr.txt     fr   \n",
       "3    100701      en  100701_en_corr.txt     fr   \n",
       "4    100701      en  100701_en_corr.txt     fr   \n",
       "\n",
       "                                        headnote   ...    party2     signed  \\\n",
       "0  SCIENTIFIC LITERARY AND EDUCATIONAL RELATIONS   ...    FRANCE 1945-12-08   \n",
       "1  SCIENTIFIC LITERARY AND EDUCATIONAL RELATIONS   ...    FRANCE 1945-12-08   \n",
       "2  SCIENTIFIC LITERARY AND EDUCATIONAL RELATIONS   ...    FRANCE 1945-12-08   \n",
       "3  SCIENTIFIC LITERARY AND EDUCATIONAL RELATIONS   ...    FRANCE 1945-12-08   \n",
       "4  SCIENTIFIC LITERARY AND EDUCATIONAL RELATIONS   ...    FRANCE 1945-12-08   \n",
       "\n",
       "  signed_period signed_period_alt signed_year source   title  topic topic1  \\\n",
       "0  1945 to 1955      1945 to 1955        1945   UNTS  PROTOC  7CULT  7CULT   \n",
       "1  1945 to 1955      1945 to 1955        1945   UNTS  PROTOC  7CULT  7CULT   \n",
       "2  1945 to 1955      1945 to 1955        1945   UNTS  PROTOC  7CULT  7CULT   \n",
       "3  1945 to 1955      1945 to 1955        1945   UNTS  PROTOC  7CULT  7CULT   \n",
       "4  1945 to 1955      1945 to 1955        1945   UNTS  PROTOC  7CULT  7CULT   \n",
       "\n",
       "   topic2  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treaty_pos_tokens = df_corpus[~df_corpus.Stop&~df_corpus.POS.isin(['SPACE', 'PUNCT'])].groupby(['treaty_id', 'Lemma', 'POS']).size()\n",
    "df_treaty_pos_tokens = df_treaty_pos_tokens.reset_index().rename(columns={'Lemma': 'lemma', 'POS': 'pos', 0: 'count'})\n",
    "df_treaty_pos_tokens = df_treaty_pos_tokens.set_index(['treaty_id'])\n",
    "df_treaty_pos_tokens = df_treaty_pos_tokens.merge(pd.DataFrame(treaties['signed_year']), how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>country</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>article</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>3924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>exchange</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>3458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>operation</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>co</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>force</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>institution</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>territory</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5086</th>\n",
       "      <td>purpose</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>field</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>agreement</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>party</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>study</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>art</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>period</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5392</th>\n",
       "      <td>research</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>education</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>government</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>culture</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>language</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>accordance</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>film</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6856</th>\n",
       "      <td>work</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>contracting</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6093</th>\n",
       "      <td>student</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>date</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4052</th>\n",
       "      <td>member</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>relation</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6597</th>\n",
       "      <td>university</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>establishment</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>ratification</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>provision</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6312</th>\n",
       "      <td>text</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5634</th>\n",
       "      <td>science</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>instrument</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>teacher</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>activity</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>national</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>organisation</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535</th>\n",
       "      <td>organization</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811</th>\n",
       "      <td>who</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>publication</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4687</th>\n",
       "      <td>people</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>school</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>radio</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>course</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>basis</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>visit</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>personnel</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>convention</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lemma   pos  count\n",
       "1593        country  NOUN   4400\n",
       "518         article  NOUN   3924\n",
       "2331       exchange  NOUN   3458\n",
       "4502      operation  NOUN   1820\n",
       "1269             co  NOUN   1652\n",
       "2564          force  NOUN   1625\n",
       "3267    institution  NOUN   1601\n",
       "6306      territory  NOUN   1376\n",
       "5086        purpose  NOUN   1228\n",
       "2484          field  NOUN   1100\n",
       "238       agreement  NOUN   1083\n",
       "4637          party  NOUN   1038\n",
       "6098          study  NOUN   1018\n",
       "515             art  NOUN    975\n",
       "4704         period  NOUN    973\n",
       "5392       research  NOUN    963\n",
       "2094      education  NOUN    948\n",
       "2793     government  NOUN    946\n",
       "1639        culture  NOUN    934\n",
       "3648       language  NOUN    933\n",
       "113      accordance  NOUN    920\n",
       "2501           film  NOUN    883\n",
       "6856           work  NOUN    872\n",
       "1506    contracting  NOUN    867\n",
       "6093        student  NOUN    827\n",
       "1719           date  NOUN    824\n",
       "4052         member  NOUN    810\n",
       "5299       relation  NOUN    764\n",
       "6597     university  NOUN    763\n",
       "2283  establishment  NOUN    757\n",
       "5159   ratification  NOUN    719\n",
       "5045      provision  NOUN    690\n",
       "6312           text  NOUN    684\n",
       "5634        science  NOUN    681\n",
       "3276     instrument  NOUN    675\n",
       "6248        teacher  NOUN    672\n",
       "140        activity  NOUN    660\n",
       "4285       national  NOUN    653\n",
       "4530   organisation  NOUN    649\n",
       "4535   organization  NOUN    647\n",
       "6811            who  NOUN    640\n",
       "5057    publication  NOUN    613\n",
       "4687         people  NOUN    609\n",
       "5622         school  NOUN    581\n",
       "5130          radio  NOUN    575\n",
       "1597         course  NOUN    564\n",
       "722           basis  NOUN    563\n",
       "6738          visit  NOUN    563\n",
       "4716      personnel  NOUN    560\n",
       "1525     convention  NOUN    555"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#df_treaty_pos_tokens.head()\n",
    "\n",
    "df_year_pos_tokens = df.groupby(['lemma', 'pos']).size().reset_index().rename(columns={0:'count'})\n",
    "df_year_pos_tokens[df_year_pos_tokens.pos.isin(['NOUN'])].nlargest(50, 'count')\n",
    "#df_year_pos_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_token_pos = df_corpus[~df_corpus.POS.isin(['SPACE', 'PUNCT'])].groupby(['Lemma', 'POS']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Corpus vs WTI Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Corpus' object has no attribute 'documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-ec0b8ea74839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCORPUS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'treaty_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'language'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtreaty_text_languages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwti_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_treaty_text_languages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'treaty_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'language'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtreaties_in_corpus_not_in_wti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_documents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreaty_text_languages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtreaties_in_wti_not_in_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreaty_text_languages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_documents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Corpus' object has no attribute 'documents'"
     ]
    }
   ],
   "source": [
    "corpus_documents = corpus.documents.set_index(['treaty_id', 'language'])\n",
    "treaty_text_languages = wti_index.get_treaty_text_languages().set_index(['treaty_id', 'language'])\n",
    "\n",
    "treaties_in_corpus_not_in_wti = corpus_documents.index.difference(treaty_text_languages.index).get_values()\n",
    "treaties_in_wti_not_in_corpus = treaty_text_languages.index.difference(corpus_documents.index).get_values()\n",
    "\n",
    "print(  'Found in corpus, but not in WTI: ' +\n",
    "        ', '.join([ '{}/{}'.format(x,y) for x,y in treaties_in_corpus_not_in_wti ]))\n",
    "\n",
    "print(  'Found in WTI, but not in corpus: ' +\n",
    "        ', '.join([ '{}/{}'.format(x,y) for x,y in treaties_in_wti_not_in_corpus ]))\n",
    "\n",
    "#corpus_documents.loc[corpus_text_not_in_wti]\n",
    "#treaty_text_languages.loc[wti_not_in_corpus]\n",
    "\n",
    "#wti_not_in_corpus\n",
    "\n",
    "# Duplicates:\n",
    "#corpus_documents.index.get_duplicates()\n",
    "#treaty_text_languages.corpus_documents.index.get_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Basic Corpus Statistics\n",
    "See https://www.nltk.org/book/ch01.html\n",
    "\n",
    "* Size of treaties over time\n",
    "* Unique word, unique words per word class\n",
    "* Lexical diversity\n",
    "* Frequency distribution\n",
    "* Average word length, sentence length\n",
    "\n",
    "\n",
    "```python\n",
    " \t\n",
    ">>> len(texts) / count(docs)\n",
    "0.06230453042623537\n",
    ">>>\n",
    "\n",
    ">>> len(set(text3)) / len(text3)\n",
    "0.06230453042623537\n",
    ">>>\n",
    "\n",
    ">>> > def lexical_diversity(text): [1]\n",
    "...     return len(set(text)) / len(text) [2]\n",
    "...\n",
    ">>> def percentage(count, total): [3]\n",
    "...     return 100 * count / total\n",
    "\n",
    "# Most common words\n",
    "fdist1 = FreqDist(text1)\n",
    "fdist1.most_common(50)\n",
    "\n",
    "# Word length frequencies\n",
    ">>> fdist = FreqDist(len(w) for w in text1)  [2]\n",
    ">>> print(fdist)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code \n",
    "\n",
    "corpus = None\n",
    "def display_token_toplist_interact(source_folder):\n",
    "    global corpus\n",
    "    progress_widget = None\n",
    "    \n",
    "    def display_token_toplist(source_folder, language, statistics='', remove_stopwords=False):\n",
    "        global corpus\n",
    "\n",
    "        try:\n",
    "\n",
    "            progress_widget.value = 1\n",
    "\n",
    "            corpus = TreatyCorpusSaveLoad(source_folder=source_folder, lang=language[0]).load_mm_corpus()\n",
    "\n",
    "            progress_widget.value = 2\n",
    "            service = MmCorpusStatisticsService(corpus, dictionary=corpus.dictionary, language=language)\n",
    "\n",
    "            print(\"Corpus consists of {} documents, {} words in total and a vocabulary size of {} tokens.\"\\\n",
    "                      .format(len(corpus), corpus.dictionary.num_pos, len(corpus.dictionary)))\n",
    "\n",
    "            progress_widget.value = 3\n",
    "            if statistics == 'word_freqs':\n",
    "                display(service.compute_word_frequencies(remove_stopwords))\n",
    "            elif statistics == 'documents':\n",
    "                display(service.compute_document_stats())\n",
    "            elif statistics == 'word_count':\n",
    "                display(service.compute_word_stats())\n",
    "            else:\n",
    "                print('Unknown: ' + statistics)\n",
    "\n",
    "        except Exception as ex:\n",
    "            logger.error(ex)\n",
    "\n",
    "        progress_widget.value = 5\n",
    "        progress_widget.value = 0\n",
    "        return corpus\n",
    "    \n",
    "    language_widget=widgets.Dropdown(\n",
    "        options={\n",
    "            'English': ('en', 'english'),\n",
    "            'French': ('fr', 'french'),\n",
    "            'German': ('de', 'german'),\n",
    "            'Italian': ('it', 'italian')\n",
    "        },\n",
    "        value=('en', 'english'),\n",
    "        description='Language:', **dict(layout=widgets.Layout(width='260px'))\n",
    "    )\n",
    "    \n",
    "    statistics_widget=widgets.Dropdown(\n",
    "        options={\n",
    "            'Word freqs': 'word_freqs',\n",
    "            'Documents': 'documents',\n",
    "            'Word count': 'word_count'\n",
    "        },\n",
    "        value='word_count',\n",
    "        description='Statistics:', **dict(layout=widgets.Layout(width='260px'))\n",
    "    )\n",
    "    \n",
    "    remove_stopwords_widget=widgets.ToggleButton(\n",
    "        description='Remove stopwords', value=True,\n",
    "        tooltip='Do not include stopwords in token toplist'\n",
    "    )\n",
    "    \n",
    "    progress_widget=widgets.IntProgress(min=0, max=5, step=1, value=0) #, layout=widgets.Layout(width='100%')),\n",
    "\n",
    "    wi = widgets.interactive(\n",
    "        display_token_toplist,\n",
    "        source_folder=source_folder,\n",
    "        language=language_widget,\n",
    "        statistics=statistics_widget,\n",
    "        remove_stopwords=remove_stopwords_widget\n",
    "    )\n",
    "\n",
    "    boxes = widgets.HBox(\n",
    "        [\n",
    "            language_widget, statistics_widget, remove_stopwords_widget, progress_widget\n",
    "        ]\n",
    "    )\n",
    "    display(widgets.VBox([boxes, wi.children[-1]]))\n",
    "    wi.update()\n",
    "\n",
    "display_token_toplist_interact('../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: red'>WORK IN PROGRESS</span> Task: Treaty Keyword Extraction (using TF-IDF weighing)\n",
    "- [ML Wiki.org](http://mlwiki.org/index.php/TF-IDF)\n",
    "- [Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "- Spärck Jones, K. (1972). \"A Statistical Interpretation of Term Specificity and Its Application in Retrieval\".\n",
    "- Manning, C.D.; Raghavan, P.; Schutze, H. (2008). \"Scoring, term weighting, and the vector space model\". ([PDF](http://nlp.stanford.edu/IR-book/pdf/06vect.pdf))\n",
    "- https://markroxor.github.io/blog/tfidf-pivoted_norm/\n",
    "$\\frac{tf-idf}{\\sqrt(rowSums( tf-idf^2 ) )}$\n",
    "- https://nlp.stanford.edu/IR-book/html/htmledition/pivoted-normalized-document-length-1.html\n",
    "\n",
    "Neural Network Methods in Natural Language Processing, Yoav Goldberg:\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Code\n",
    "from scipy.sparse import csr_matrix\n",
    "%timeit\n",
    "\n",
    "    \n",
    "def get_top_tfidf_words(data, n_top=5):\n",
    "    top_list = data.groupby(['treaty_id'])\\\n",
    "        .apply(lambda x: x.nlargest(n_top, 'score'))\\\n",
    "        .reset_index(level=0, drop=True)\n",
    "    return top_list\n",
    "\n",
    "def compute_tfidf_scores(corpus, dictionary, smartirs='ntc'):\n",
    "    #model = gensim.models.logentropy_model.LogEntropyModel(corpus, normalize=True)\n",
    "    model = gensim.models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary, normalize=True) #, smartirs=smartirs)\n",
    "    rows, cols, scores = [], [], []\n",
    "    for r, document in enumerate(corpus): \n",
    "        vector = model[document]\n",
    "        c, v = zip(*vector)\n",
    "        rows += (len(c) * [ int(r) ])\n",
    "        cols += c\n",
    "        scores += v\n",
    "        \n",
    "    return csr_matrix((scores, (rows, cols)))\n",
    "    \n",
    "if True: #'tfidf_cache' not in globals():\n",
    "    tfidf_cache = {\n",
    "    }\n",
    "    \n",
    "def display_tfidf_scores(source_folder, language, period, n_top=5, threshold=0.001):\n",
    "    \n",
    "    global state, tfw, tfidf_cache\n",
    "    \n",
    "    try:\n",
    "        treaties = state.treaties\n",
    "\n",
    "        tfw.progress.value = 0\n",
    "        tfw.progress.value += 1\n",
    "        if language[0] not in tfidf_cache.keys():\n",
    "            corpus = TreatyCorpusSaveLoad(source_folder=source_folder, lang=language[0])\\\n",
    "                .load_mm_corpus(normalize_by_D=True)\n",
    "            document_names = corpus.document_names\n",
    "            dictionary = corpus.dictionary\n",
    "            _ = dictionary[0]\n",
    "\n",
    "            tfw.progress.value += 1\n",
    "            A = compute_tfidf_scores(corpus, dictionary)\n",
    "\n",
    "            tfw.progress.value += 1\n",
    "            scores = pd.DataFrame(\n",
    "                [ (i, j, dictionary.id2token[j], A[i, j]) for i, j in zip(*A.nonzero())],\n",
    "                columns=['document_id', 'token_id', 'token', 'score']\n",
    "            )\n",
    "            tfw.progress.value += 1\n",
    "            scores = scores.merge(document_names, how='inner', left_on='document_id', right_index=True)\\\n",
    "                .drop(['document_id', 'token_id', 'document_name'], axis=1)\n",
    "\n",
    "            scores = scores[['treaty_id', 'token', 'score']]\\\n",
    "                .sort_values(['treaty_id', 'score'], ascending=[True, False])\n",
    "\n",
    "            tfidf_cache[language[0]] = scores\n",
    "\n",
    "        scores = tfidf_cache[language[0]]\n",
    "        if threshold > 0:\n",
    "            scores = scores.loc[scores.score >= threshold]\n",
    "\n",
    "        tfw.progress.value += 1\n",
    "\n",
    "        #scores = get_top_tfidf_words(scores, n_top=5)\n",
    "        #scores = scores.groupby(['treaty_id']).sum() \n",
    "\n",
    "        scores = scores.groupby(['treaty_id'])\\\n",
    "            .apply(lambda x: x.nlargest(n_top, 'score'))\\\n",
    "            .reset_index(level=0, drop=True)\\\n",
    "            .set_index('treaty_id')\n",
    "\n",
    "        if period is not None:\n",
    "            periods = state.treaties[period]\n",
    "            scores = scores.merge(periods.to_frame(), left_index=True, right_index=True, how='inner')\\\n",
    "                .groupby([period, 'token']).score.agg([np.mean])\\\n",
    "                .reset_index().rename(columns={0:'score'}) #.sort_values('token')\n",
    "\n",
    "        #['token'].apply(' '.join)\n",
    "\n",
    "        display(scores)\n",
    "    except Exception as ex:\n",
    "        logger.error(ex)\n",
    "        \n",
    "    tfw.progress.value = 0\n",
    "\n",
    "#if 'tfidf_scores' not in globals():\n",
    "#    tfidf_scores = compute_document_tfidf(corpus, corpus.dictionary, state.treaties)\n",
    "#    tfidf_scores = tfidf_scores.sort_values(['treaty_id', 'score'], ascending=[True, False])\n",
    "\n",
    "tfw = BaseWidgetUtility(\n",
    "    language=widgets.Dropdown(\n",
    "        options={\n",
    "            'English': ('en', 'english'),\n",
    "            'French': ('fr', 'french'),\n",
    "            'German': ('de', 'german'),\n",
    "            'Italian': ('it', 'italian')\n",
    "        },\n",
    "        value=('en', 'english'),\n",
    "        description='Language:', **drop_style\n",
    "    ),\n",
    "    remove_stopwords=widgets.ToggleButton(\n",
    "        description='Remove stopwords', value=True,\n",
    "        tooltip='Do not include stopwords in token toplist', **toggle_style\n",
    "    ),    \n",
    "    n_top=widgets.IntSlider(\n",
    "        value=5, min=1, max=25, step=1,\n",
    "        description='Top #:',\n",
    "        continuous_update=False\n",
    "    ),\n",
    "    threshold=widgets.FloatSlider(\n",
    "        value=0.001, min=0.0, max=0.5, step=0.01,\n",
    "        description='Threshold:',\n",
    "        tooltip='Word having a TF-IDF score below this value is filtered out',\n",
    "        continuous_update=False,\n",
    "        readout_format='.3f',\n",
    "    ), \n",
    "    period=widgets.Dropdown(\n",
    "        options={\n",
    "            '': None,\n",
    "            'Year': 'signed_year',\n",
    "            'Default division': 'signed_period',\n",
    "            'Alt. division': 'signed_period_alt'\n",
    "        },\n",
    "        value='signed_period',\n",
    "        description='Period:', **drop_style\n",
    "    ),\n",
    "    output=widgets.Dropdown(\n",
    "        options={\n",
    "            '': None,\n",
    "            'Year': 'signed_year',\n",
    "            'Default division': 'signed_period',\n",
    "            'Alt. division': 'signed_period_alt'\n",
    "        },\n",
    "        value='signed_period',\n",
    "        description='Output:', **drop_style\n",
    "    ),\n",
    "    progress=widgets.IntProgress(min=0, max=5, step=1, value=0) #, layout=widgets.Layout(width='100%')),\n",
    ")\n",
    "\n",
    "itfw = widgets.interactive(\n",
    "    display_tfidf_scores,\n",
    "    source_folder='./data',\n",
    "    language=tfw.language,\n",
    "    n_top=tfw.n_top,\n",
    "    threshold=tfw.threshold,\n",
    "    period=tfw.period\n",
    ")\n",
    "\n",
    "boxes = widgets.HBox(\n",
    "    [\n",
    "        widgets.VBox([tfw.language, tfw.period]),\n",
    "        widgets.VBox([tfw.n_top, tfw.threshold]),\n",
    "        widgets.VBox([tfw.progress, tfw.output])\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(widgets.VBox([boxes, itfw.children[-1]]))\n",
    "itfw.update()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 655.4,
   "position": {
    "height": "886px",
    "left": "1049px",
    "right": "20px",
    "top": "110px",
    "width": "654px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
