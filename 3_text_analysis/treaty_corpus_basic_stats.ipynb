{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Culture of International Relations - Corpus statistics\n",
    "\n",
    "#### About this notebook\n",
    "tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".jupyter-widgets, .widget-dropdown > select, .widget-label, .widget-toggle-button > button {\n",
       "    font-size: 8pt;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".jupyter-widgets, .widget-dropdown > select, .widget-label, .widget-toggle-button > button {\n",
    "    font-size: 8pt;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:blue'>**Mandatory Prepare Step**</span>: Setup Notebook\n",
    "The following code cell must to be executed once for each user session. The step loads utility Python code stored in separate files, and imports dependencies to external libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-21 11:23:28,768 : INFO : Data loaded!\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if '..' not in sys.path: sys.path.insert(1, '..')\n",
    "\n",
    "from common.treaty_state import load_wti_index\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import common.widgets_config as widgets_config\n",
    "import common.config as config\n",
    "import common.utility as utility\n",
    "import common.treaty_utility as treaty_utility\n",
    "import treaty_corpus\n",
    "import nltk\n",
    "\n",
    "logger = utility.getLogger('corpus_text_analysis')\n",
    "\n",
    "wti_index = load_wti_index(data_folder='../data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_group = config.PERIOD_GROUPS_ID_MAP['years_1945-1972']\n",
    "\n",
    "treaties = wti_index.get_treaties_within_division(\n",
    "    period_group=period_group,\n",
    "    treaty_filter='is_cultural',\n",
    "    recode_is_cultural=False,\n",
    "    parties=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-19 15:28:57,085 : INFO : Initializing dictionary\n",
      "2018-10-19 15:28:57,103 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-10-19 15:29:04,148 : INFO : built Dictionary(20604 unique tokens: ['nucleus', 'sokpulsa', 'ltalo', 'intervenus', 'kattner']...) from 721 documents (total 934111 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "source_folder = '../data'\n",
    "source_path = os.path.join(source_folder, 'treaty_text_corpora_20181018.zip')\n",
    "\n",
    "treaties = wti_index\n",
    "corpus_stream = treaty_corpus.CompressedFileReader(source_path, pattern='*.txt')\n",
    "\n",
    "\n",
    "# corpus = treaty_corpus.TreatyCorpus(stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in corpus, but not in WTI: 304127/en, 400039/de, 415293/fr, XXX042/de, XXX046/de\n",
      "Found in WTI, but not in corpus: XXX010/de\n"
     ]
    }
   ],
   "source": [
    "corpus_documents = corpus.documents.set_index(['treaty_id', 'language'])\n",
    "treaty_text_languages = wti_index.get_treaty_text_languages().set_index(['treaty_id', 'language'])\n",
    "\n",
    "treaties_in_corpus_not_in_wti = corpus_documents.index.difference(treaty_text_languages.index).get_values()\n",
    "treaties_in_wti_not_in_corpus = treaty_text_languages.index.difference(corpus_documents.index).get_values()\n",
    "\n",
    "print(  'Found in corpus, but not in WTI: ' +\n",
    "        ', '.join([ '{}/{}'.format(x,y) for x,y in treaties_in_corpus_not_in_wti ]))\n",
    "\n",
    "print(  'Found in WTI, but not in corpus: ' +\n",
    "        ', '.join([ '{}/{}'.format(x,y) for x,y in treaties_in_wti_not_in_corpus ]))\n",
    "\n",
    "#corpus_documents.loc[corpus_text_not_in_wti]\n",
    "#treaty_text_languages.loc[wti_not_in_corpus]\n",
    "\n",
    "#wti_not_in_corpus\n",
    "\n",
    "# Duplicates:\n",
    "#corpus_documents.index.get_duplicates()\n",
    "#treaty_text_languages.corpus_documents.index.get_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style='color:blue'>**Mandatory Step**</span>: Convert Treaty Text Corpora to MM Format\n",
    "\n",
    "This code cell is a mandatory step for subsequent text corpus statistics. \n",
    "\n",
    "This step processes the treaty text for from given compressed archive (ZIP-file), each language , and stores in an efficient Market-Matrix (MM) corpus format. The corpora is only stored if it is not previously stored, or the \"Force Update\" is specified. Note that an update MUST be forced whenever the treaty archive is updated - otherwise the text in the new archive is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     119,
     200,
     219
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e034a82e5e11441fb4da89b4ab44f1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Corpus:', index=2, options=('../data/treaty_text_corpora_2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code\n",
    "def store_mm_corpora(source_path, force, languages):\n",
    "    try:\n",
    "        progress_widget.value = 1\n",
    "        tokenizer = nltk.tokenize.word_tokenize\n",
    "        source_folder = os.path.split(source_path)[0]\n",
    "        for language in languages.split(','):\n",
    "            progress_widget.value += 1\n",
    "            loader = treaty_corpus.TreatyCorpusSaveLoad(source_folder, language)\n",
    "            if not loader.exists() or force:\n",
    "                progress_widget.description = 'Processing: {}'.format(language)\n",
    "                stream = treaty_corpus.CompressedFileReader(source_path, pattern='*_{}*.txt'.format(language))\n",
    "                corpus = treaty_corpus.TreatyCorpus(stream, tokenizer=tokenizer)        \n",
    "                loader.store_as_mm_corpus(corpus)\n",
    "        progress_widget.description = ''\n",
    "        progress_widget.value = 0\n",
    "    except Exception as ex:\n",
    "        logger.error(ex)\n",
    "        raise\n",
    "        \n",
    "def prepare_treaty_text_corpora(source_pattern):\n",
    "    \n",
    "    current_archives = (utility.ls_sorted(source_pattern) or [])\n",
    "    default_archive = current_archives[-1] if len(current_archives) else None\n",
    "    \n",
    "    source_path_widget=widgets_config.dropdown('Corpus:', current_archives, default_archive)\n",
    "    force_corpus_update_widget=widgets_config.toggle('Force Update', False)\n",
    "    progress_widget = widgets_config.progress(min=0, max=5, step=1, value=0)\n",
    "        \n",
    "    wi = widgets.interactive(\n",
    "        store_mm_corpora,\n",
    "        source_path=source_path_widget,\n",
    "        force=force_corpus_update_widget,\n",
    "        languages='en,it,fr,de'\n",
    "    )\n",
    "\n",
    "    display(\n",
    "        widgets.VBox([widgets.HBox([source_path_widget, force_corpus_update_widget, progress_widget]), wi.children[-1]])\n",
    "    )\n",
    "\n",
    "    # wi.update()\n",
    "    \n",
    "prepare_treaty_text_corpora('../data/*.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d617233b1af64854911f1ed89677807f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Please specify corpus', description='caption'),)), HBox(children=(D…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from IPython.display import display, HTML\n",
    "os.sys.path = os.sys.path if '..' in os.sys.path else os.sys.path + ['..']\n",
    "\n",
    "from common.file_utility import FileUtility\n",
    "from common.widgets_utility import BaseWidgetUtility\n",
    "from common.utility import extend\n",
    "\n",
    "import configuration_elements as config\n",
    "\n",
    "state = load_treaty_state('../data')\n",
    "\n",
    "treaty_state = load_treaty_state(data_folder='../data')\n",
    "\n",
    "def specify_corpus_reader(archive_filename, corpus_option, language, caption, treaty_state=None):\n",
    "    \n",
    "    def get_document_names(archive_filename):\n",
    "        document_names = CompressedFileReader(zip_archive=archive_filename).archive_filenames\n",
    "        df = pd.DataFrame([[x] + re.split('_|\\.',x)[:2] for x in document_names],\n",
    "                          columns=['filename', 'treaty_id', 'language'])\n",
    "        df = df.set_index('treaty_id')\n",
    "        df['is_corr'] = df.filename.apply(lambda z: \"_corr\" in z)\n",
    "        return df\n",
    "    \n",
    "    if corpus_option is None:\n",
    "        caption.value = 'Please select corpus'\n",
    "        return\n",
    "\n",
    "    df_documents = get_document_names(archive_filename)\n",
    "    df_treaties = treaty_state.get_treaty_subset(corpus_option, language).join(df_documents)\n",
    "\n",
    "    display(HTML(df_treaties.head(5).to_html()))\n",
    "\n",
    "    return df_treaties\n",
    "    \n",
    "def specify_corpus_reader_interactor(source_pattern, treaty_state):\n",
    "    \n",
    "    current_archives = (ls_sorted(source_pattern) or [])\n",
    "    \n",
    "    progress_widget=widgets.IntProgress(min=0, max=5, step=1, value=0, layout=widgets.Layout(width='99%'))\n",
    "\n",
    "    archive_filename_widget=widgets.Dropdown(\n",
    "        options=current_archives,\n",
    "        value=current_archives[-1] if len(current_archives) else None,\n",
    "        description='Text archive:' #, **drop_style\n",
    "    )\n",
    "      \n",
    "    corpus_options = {\n",
    "        'UNTS 1945-1972': dict(source=['UNTS', 'UNXX'], from_year=1945, to_year=1972,\n",
    "                               parties=None, lang=['en', 'fr']),\n",
    "        'Party of Five': dict(source=None, from_year=1915, to_year=1972,\n",
    "                              parties=config.parties_of_interest, lang=['en', 'fr', 'de', 'it'])\n",
    "    }\n",
    "    \n",
    "    corpus_widget=widgets.Dropdown(\n",
    "        options=corpus_options,\n",
    "        value=corpus_options[list(corpus_options.keys())[0]],\n",
    "        description='Corpus:'\n",
    "    )\n",
    "\n",
    "    language_widget=widgets.Dropdown(\n",
    "        options=['en', 'fr', 'it', 'de'],\n",
    "        value='en',\n",
    "        description='Language:'\n",
    "    )\n",
    "    \n",
    "    caption = widgets.Label(value='Please specify corpus')\n",
    "    \n",
    "    w = widgets.interactive(\n",
    "        specify_corpus_reader,\n",
    "        archive_filename=archive_filename_widget,\n",
    "        corpus_option=corpus_widget,\n",
    "        language=language_widget,\n",
    "        caption=caption,\n",
    "        treaty_state=widgets.fixed(treaty_state)\n",
    "    )\n",
    "\n",
    "    display(\n",
    "        widgets.VBox([\n",
    "            widgets.HBox([caption]),\n",
    "            widgets.HBox([archive_filename_widget, corpus_widget, language_widget]),\n",
    "            widgets.HBox([progress_widget]),\n",
    "            w.children[-1]])\n",
    "    )\n",
    "    \n",
    "    #def corpus_widget_change(change):\n",
    "    #    current_value = language_widget.value\n",
    "    #    languages = None if corpus_widget.value is None else corpus_widget.value['lang']\n",
    "    #    language_widget.options = languages or []\n",
    "    #    caption.value = str(lang)\n",
    "                 \n",
    "    #corpus_widget.observe(corpus_widget_change, names='value')\n",
    "\n",
    "    return w\n",
    "\n",
    "treaties_select_widget = specify_corpus_reader_interactor('../data/*.zip', treaty_state)\n",
    "treaties_select_widget.update()\n",
    "\n",
    "#print(treaties_select_widget)\n",
    "#def data_changed(change):\n",
    "#    raise Exception(\"HEJ\")\n",
    "#    \n",
    "#treaties_select_widget.observe(data_changed, names='value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Basic Corpus Statistics\n",
    "See https://www.nltk.org/book/ch01.html\n",
    "\n",
    "* Size of treaties over time\n",
    "* Unique word, unique words per word class\n",
    "* Lexical diversity\n",
    "* Frequency distribution\n",
    "* Average word length, sentence length\n",
    "\n",
    "\n",
    "```python\n",
    " \t\n",
    ">>> len(texts) / count(docs)\n",
    "0.06230453042623537\n",
    ">>>\n",
    "\n",
    ">>> len(set(text3)) / len(text3)\n",
    "0.06230453042623537\n",
    ">>>\n",
    "\n",
    ">>> > def lexical_diversity(text): [1]\n",
    "...     return len(set(text)) / len(text) [2]\n",
    "...\n",
    ">>> def percentage(count, total): [3]\n",
    "...     return 100 * count / total\n",
    "\n",
    "# Most common words\n",
    "fdist1 = FreqDist(text1)\n",
    "fdist1.most_common(50)\n",
    "\n",
    "# Word length frequencies\n",
    ">>> fdist = FreqDist(len(w) for w in text1)  [2]\n",
    ">>> print(fdist)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82760878b374cc78a2756f91b6343bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Language:', index=1, layout=Layout(width='260px'), options…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code \n",
    "\n",
    "corpus = None\n",
    "def display_token_toplist_interact(source_folder):\n",
    "    global corpus\n",
    "    progress_widget = None\n",
    "    \n",
    "    def display_token_toplist(source_folder, language, statistics='', remove_stopwords=False):\n",
    "        global corpus\n",
    "\n",
    "        try:\n",
    "\n",
    "            progress_widget.value = 1\n",
    "\n",
    "            corpus = TreatyCorpusSaveLoad(source_folder=source_folder, lang=language[0]).load_mm_corpus()\n",
    "\n",
    "            progress_widget.value = 2\n",
    "            service = MmCorpusStatisticsService(corpus, dictionary=corpus.dictionary, language=language)\n",
    "\n",
    "            print(\"Corpus consists of {} documents, {} words in total and a vocabulary size of {} tokens.\"\\\n",
    "                      .format(len(corpus), corpus.dictionary.num_pos, len(corpus.dictionary)))\n",
    "\n",
    "            progress_widget.value = 3\n",
    "            if statistics == 'word_freqs':\n",
    "                display(service.compute_word_frequencies(remove_stopwords))\n",
    "            elif statistics == 'documents':\n",
    "                display(service.compute_document_stats())\n",
    "            elif statistics == 'word_count':\n",
    "                display(service.compute_word_stats())\n",
    "            else:\n",
    "                print('Unknown: ' + statistics)\n",
    "\n",
    "        except Exception as ex:\n",
    "            logger.error(ex)\n",
    "\n",
    "        progress_widget.value = 5\n",
    "        progress_widget.value = 0\n",
    "        return corpus\n",
    "    \n",
    "    language_widget=widgets.Dropdown(\n",
    "        options={\n",
    "            'English': ('en', 'english'),\n",
    "            'French': ('fr', 'french'),\n",
    "            'German': ('de', 'german'),\n",
    "            'Italian': ('it', 'italian')\n",
    "        },\n",
    "        value=('en', 'english'),\n",
    "        description='Language:', **dict(layout=widgets.Layout(width='260px'))\n",
    "    )\n",
    "    \n",
    "    statistics_widget=widgets.Dropdown(\n",
    "        options={\n",
    "            'Word freqs': 'word_freqs',\n",
    "            'Documents': 'documents',\n",
    "            'Word count': 'word_count'\n",
    "        },\n",
    "        value='word_count',\n",
    "        description='Statistics:', **dict(layout=widgets.Layout(width='260px'))\n",
    "    )\n",
    "    \n",
    "    remove_stopwords_widget=widgets.ToggleButton(\n",
    "        description='Remove stopwords', value=True,\n",
    "        tooltip='Do not include stopwords in token toplist'\n",
    "    )\n",
    "    \n",
    "    progress_widget=widgets.IntProgress(min=0, max=5, step=1, value=0) #, layout=widgets.Layout(width='100%')),\n",
    "\n",
    "    wi = widgets.interactive(\n",
    "        display_token_toplist,\n",
    "        source_folder=source_folder,\n",
    "        language=language_widget,\n",
    "        statistics=statistics_widget,\n",
    "        remove_stopwords=remove_stopwords_widget\n",
    "    )\n",
    "\n",
    "    boxes = widgets.HBox(\n",
    "        [\n",
    "            language_widget, statistics_widget, remove_stopwords_widget, progress_widget\n",
    "        ]\n",
    "    )\n",
    "    display(widgets.VBox([boxes, wi.children[-1]]))\n",
    "    wi.update()\n",
    "\n",
    "display_token_toplist_interact('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_predicate = None\n",
    "filename_predicate = filename_predicate or (lambda x: True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: red'>WORK IN PROGRESS</span> Task: Treaty Keyword Extraction (using TF-IDF weighing)\n",
    "- [ML Wiki.org](http://mlwiki.org/index.php/TF-IDF)\n",
    "- [Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "- Spärck Jones, K. (1972). \"A Statistical Interpretation of Term Specificity and Its Application in Retrieval\".\n",
    "- Manning, C.D.; Raghavan, P.; Schutze, H. (2008). \"Scoring, term weighting, and the vector space model\". ([PDF](http://nlp.stanford.edu/IR-book/pdf/06vect.pdf))\n",
    "- https://markroxor.github.io/blog/tfidf-pivoted_norm/\n",
    "$\\frac{tf-idf}{\\sqrt(rowSums( tf-idf^2 ) )}$\n",
    "- https://nlp.stanford.edu/IR-book/html/htmledition/pivoted-normalized-document-length-1.html\n",
    "\n",
    "Neural Network Methods in Natural Language Processing, Yoav Goldberg:\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2bd4d39be54eb08a67fb69cc66730f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='Language:', index=3, layout=Layout(width='260px'), options={'German': ('de', 'german'), 'French': ('fr', 'french'), 'Italian': ('it', 'italian'), 'English': ('en', 'english')}, value=('en', 'english')), Dropdown(description='Period:', index=3, layout=Layout(width='260px'), options={'': None, 'Alt. division': 'signed_period_alt', 'Year': 'signed_year', 'Default division': 'signed_period'}, value='signed_period'))), VBox(children=(IntSlider(value=5, continuous_update=False, description='Top #:', max=25, min=1), FloatSlider(value=0.001, continuous_update=False, description='Threshold:', max=0.5, readout_format='.3f', step=0.01))), VBox(children=(IntProgress(value=0, max=5), Dropdown(description='Output:', index=3, layout=Layout(width='260px'), options={'': None, 'Alt. division': 'signed_period_alt', 'Year': 'signed_year', 'Default division': 'signed_period'}, value='signed_period'))))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code\n",
    "from scipy.sparse import csr_matrix\n",
    "%timeit\n",
    "\n",
    "    \n",
    "def get_top_tfidf_words(data, n_top=5):\n",
    "    top_list = data.groupby(['treaty_id'])\\\n",
    "        .apply(lambda x: x.nlargest(n_top, 'score'))\\\n",
    "        .reset_index(level=0, drop=True)\n",
    "    return top_list\n",
    "\n",
    "def compute_tfidf_scores(corpus, dictionary, smartirs='ntc'):\n",
    "    #model = gensim.models.logentropy_model.LogEntropyModel(corpus, normalize=True)\n",
    "    model = gensim.models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary, normalize=True) #, smartirs=smartirs)\n",
    "    rows, cols, scores = [], [], []\n",
    "    for r, document in enumerate(corpus): \n",
    "        vector = model[document]\n",
    "        c, v = zip(*vector)\n",
    "        rows += (len(c) * [ int(r) ])\n",
    "        cols += c\n",
    "        scores += v\n",
    "        \n",
    "    return csr_matrix((scores, (rows, cols)))\n",
    "    \n",
    "if True: #'tfidf_cache' not in globals():\n",
    "    tfidf_cache = {\n",
    "    }\n",
    "    \n",
    "def display_tfidf_scores(source_folder, language, period, n_top=5, threshold=0.001):\n",
    "    \n",
    "    global state, tfw, tfidf_cache\n",
    "    \n",
    "    try:\n",
    "        treaties = state.treaties\n",
    "\n",
    "        tfw.progress.value = 0\n",
    "        tfw.progress.value += 1\n",
    "        if language[0] not in tfidf_cache.keys():\n",
    "            corpus = TreatyCorpusSaveLoad(source_folder=source_folder, lang=language[0])\\\n",
    "                .load_mm_corpus(normalize_by_D=True)\n",
    "            document_names = corpus.document_names\n",
    "            dictionary = corpus.dictionary\n",
    "            _ = dictionary[0]\n",
    "\n",
    "            tfw.progress.value += 1\n",
    "            A = compute_tfidf_scores(corpus, dictionary)\n",
    "\n",
    "            tfw.progress.value += 1\n",
    "            scores = pd.DataFrame(\n",
    "                [ (i, j, dictionary.id2token[j], A[i, j]) for i, j in zip(*A.nonzero())],\n",
    "                columns=['document_id', 'token_id', 'token', 'score']\n",
    "            )\n",
    "            tfw.progress.value += 1\n",
    "            scores = scores.merge(document_names, how='inner', left_on='document_id', right_index=True)\\\n",
    "                .drop(['document_id', 'token_id', 'document_name'], axis=1)\n",
    "\n",
    "            scores = scores[['treaty_id', 'token', 'score']]\\\n",
    "                .sort_values(['treaty_id', 'score'], ascending=[True, False])\n",
    "\n",
    "            tfidf_cache[language[0]] = scores\n",
    "\n",
    "        scores = tfidf_cache[language[0]]\n",
    "        if threshold > 0:\n",
    "            scores = scores.loc[scores.score >= threshold]\n",
    "\n",
    "        tfw.progress.value += 1\n",
    "\n",
    "        #scores = get_top_tfidf_words(scores, n_top=5)\n",
    "        #scores = scores.groupby(['treaty_id']).sum() \n",
    "\n",
    "        scores = scores.groupby(['treaty_id'])\\\n",
    "            .apply(lambda x: x.nlargest(n_top, 'score'))\\\n",
    "            .reset_index(level=0, drop=True)\\\n",
    "            .set_index('treaty_id')\n",
    "\n",
    "        if period is not None:\n",
    "            periods = state.treaties[period]\n",
    "            scores = scores.merge(periods.to_frame(), left_index=True, right_index=True, how='inner')\\\n",
    "                .groupby([period, 'token']).score.agg([np.mean])\\\n",
    "                .reset_index().rename(columns={0:'score'}) #.sort_values('token')\n",
    "\n",
    "        #['token'].apply(' '.join)\n",
    "\n",
    "        display(scores)\n",
    "    except Exception as ex:\n",
    "        logger.error(ex)\n",
    "        \n",
    "    tfw.progress.value = 0\n",
    "\n",
    "#if 'tfidf_scores' not in globals():\n",
    "#    tfidf_scores = compute_document_tfidf(corpus, corpus.dictionary, state.treaties)\n",
    "#    tfidf_scores = tfidf_scores.sort_values(['treaty_id', 'score'], ascending=[True, False])\n",
    "\n",
    "tfw = BaseWidgetUtility(\n",
    "    language=widgets.Dropdown(\n",
    "        options={\n",
    "            'English': ('en', 'english'),\n",
    "            'French': ('fr', 'french'),\n",
    "            'German': ('de', 'german'),\n",
    "            'Italian': ('it', 'italian')\n",
    "        },\n",
    "        value=('en', 'english'),\n",
    "        description='Language:', **drop_style\n",
    "    ),\n",
    "    remove_stopwords=widgets.ToggleButton(\n",
    "        description='Remove stopwords', value=True,\n",
    "        tooltip='Do not include stopwords in token toplist', **toggle_style\n",
    "    ),    \n",
    "    n_top=widgets.IntSlider(\n",
    "        value=5, min=1, max=25, step=1,\n",
    "        description='Top #:',\n",
    "        continuous_update=False\n",
    "    ),\n",
    "    threshold=widgets.FloatSlider(\n",
    "        value=0.001, min=0.0, max=0.5, step=0.01,\n",
    "        description='Threshold:',\n",
    "        tooltip='Word having a TF-IDF score below this value is filtered out',\n",
    "        continuous_update=False,\n",
    "        readout_format='.3f',\n",
    "    ), \n",
    "    period=widgets.Dropdown(\n",
    "        options={\n",
    "            '': None,\n",
    "            'Year': 'signed_year',\n",
    "            'Default division': 'signed_period',\n",
    "            'Alt. division': 'signed_period_alt'\n",
    "        },\n",
    "        value='signed_period',\n",
    "        description='Period:', **drop_style\n",
    "    ),\n",
    "    output=widgets.Dropdown(\n",
    "        options={\n",
    "            '': None,\n",
    "            'Year': 'signed_year',\n",
    "            'Default division': 'signed_period',\n",
    "            'Alt. division': 'signed_period_alt'\n",
    "        },\n",
    "        value='signed_period',\n",
    "        description='Output:', **drop_style\n",
    "    ),\n",
    "    progress=widgets.IntProgress(min=0, max=5, step=1, value=0) #, layout=widgets.Layout(width='100%')),\n",
    ")\n",
    "\n",
    "itfw = widgets.interactive(\n",
    "    display_tfidf_scores,\n",
    "    source_folder='./data',\n",
    "    language=tfw.language,\n",
    "    n_top=tfw.n_top,\n",
    "    threshold=tfw.threshold,\n",
    "    period=tfw.period\n",
    ")\n",
    "\n",
    "boxes = widgets.HBox(\n",
    "    [\n",
    "        widgets.VBox([tfw.language, tfw.period]),\n",
    "        widgets.VBox([tfw.n_top, tfw.threshold]),\n",
    "        widgets.VBox([tfw.progress, tfw.output])\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(widgets.VBox([boxes, itfw.children[-1]]))\n",
    "itfw.update()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 655.4,
   "position": {
    "height": "886px",
    "left": "1049px",
    "right": "20px",
    "top": "110px",
    "width": "654px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
