{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:blue'>**Mandatory Prepare Step**</span>: Setup Notebook\n",
    "The following code cell must to be executed once for each user session. The step loads utility Python code stored in separate files, and imports dependencies to external libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-21 11:23:28,768 : INFO : Data loaded!\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if '..' not in sys.path: sys.path.insert(1, '..')\n",
    "\n",
    "from common.treaty_state import load_wti_index\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import common.widgets_config as widgets_config\n",
    "import common.config as config\n",
    "import common.utility as utility\n",
    "import common.treaty_utility as treaty_utility\n",
    "import treaty_corpus\n",
    "import nltk\n",
    "\n",
    "logger = utility.getLogger('corpus_text_analysis')\n",
    "\n",
    "wti_index = load_wti_index(data_folder='../data')\n",
    "\n",
    "source_folder = '../data'\n",
    "source_path = os.path.join(source_folder, 'treaty_text_corpora_20181018.zip')\n",
    "\n",
    "treaties = wti_index\n",
    "corpus_stream = treaty_corpus.CompressedFileReader(source_path, pattern='*.txt')\n",
    "\n",
    "corpus = treaty_corpus.TreatyCorpus(corpus_stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_group = config.PERIOD_GROUPS_ID_MAP['years_1945-1972']\n",
    "\n",
    "treaties = wti_index.get_treaties_within_division(\n",
    "    period_group=period_group,\n",
    "    treaty_filter='is_cultural',\n",
    "    recode_is_cultural=False,\n",
    "    parties=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-19 15:28:57,085 : INFO : Initializing dictionary\n",
      "2018-10-19 15:28:57,103 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-10-19 15:29:04,148 : INFO : built Dictionary(20604 unique tokens: ['nucleus', 'sokpulsa', 'ltalo', 'intervenus', 'kattner']...) from 721 documents (total 934111 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "source_folder = '../data'\n",
    "source_path = os.path.join(source_folder, 'treaty_text_corpora_20181018.zip')\n",
    "\n",
    "treaties = wti_index\n",
    "corpus_stream = treaty_corpus.CompressedFileReader(source_path, pattern='*.txt')\n",
    "\n",
    "\n",
    "# corpus = treaty_corpus.TreatyCorpus(stream)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Basic Corpus Statistics\n",
    "See https://www.nltk.org/book/ch01.html\n",
    "\n",
    "* Size of treaties over time\n",
    "* Unique word, unique words per word class\n",
    "* Lexical diversity\n",
    "* Frequency distribution\n",
    "* Average word length, sentence length\n",
    "\n",
    "\n",
    "```python\n",
    " \t\n",
    ">>> len(texts) / count(docs)\n",
    "0.06230453042623537\n",
    ">>>\n",
    "\n",
    ">>> len(set(text3)) / len(text3)\n",
    "0.06230453042623537\n",
    ">>>\n",
    "\n",
    ">>> > def lexical_diversity(text): [1]\n",
    "...     return len(set(text)) / len(text) [2]\n",
    "...\n",
    ">>> def percentage(count, total): [3]\n",
    "...     return 100 * count / total\n",
    "\n",
    "# Most common words\n",
    "fdist1 = FreqDist(text1)\n",
    "fdist1.most_common(50)\n",
    "\n",
    "# Word length frequencies\n",
    ">>> fdist = FreqDist(len(w) for w in text1)  [2]\n",
    ">>> print(fdist)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/mdda/deep-learning-workshop/blob/master/notebooks/5-RNN/3-Text-Corpus-and-Embeddings.ipynb#scrollTo=jKrHrM7yKGwB\n",
    "\n",
    "## GloVe Word Embeddings\n",
    "Using the python package :  https://github.com/maciejkula/glove-python , and code samples from : http://developers.lyst.com/2014/11/11/word-embeddings-for-fashion/\n",
    "\n",
    "### Create the Co-occurrence Matrix\n",
    "For speed, this looks at the first 100,000 tokens in the corpus - and should create the co-occurences in 30 seconds or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: red'>WORK IN PROGRESS</span> Task: Treaty Keyword Extraction (using TF-IDF weighing)\n",
    "- [ML Wiki.org](http://mlwiki.org/index.php/TF-IDF)\n",
    "- [Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "- Sp√§rck Jones, K. (1972). \"A Statistical Interpretation of Term Specificity and Its Application in Retrieval\".\n",
    "- Manning, C.D.; Raghavan, P.; Schutze, H. (2008). \"Scoring, term weighting, and the vector space model\". ([PDF](http://nlp.stanford.edu/IR-book/pdf/06vect.pdf))\n",
    "- https://markroxor.github.io/blog/tfidf-pivoted_norm/\n",
    "$\\frac{tf-idf}{\\sqrt(rowSums( tf-idf^2 ) )}$\n",
    "- https://nlp.stanford.edu/IR-book/html/htmledition/pivoted-normalized-document-length-1.html\n",
    "\n",
    "Neural Network Methods in Natural Language Processing, Yoav Goldberg:\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2bd4d39be54eb08a67fb69cc66730f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='Language:', index=3, layout=Layout(width='260px'), options={'German': ('de', 'german'), 'French': ('fr', 'french'), 'Italian': ('it', 'italian'), 'English': ('en', 'english')}, value=('en', 'english')), Dropdown(description='Period:', index=3, layout=Layout(width='260px'), options={'': None, 'Alt. division': 'signed_period_alt', 'Year': 'signed_year', 'Default division': 'signed_period'}, value='signed_period'))), VBox(children=(IntSlider(value=5, continuous_update=False, description='Top #:', max=25, min=1), FloatSlider(value=0.001, continuous_update=False, description='Threshold:', max=0.5, readout_format='.3f', step=0.01))), VBox(children=(IntProgress(value=0, max=5), Dropdown(description='Output:', index=3, layout=Layout(width='260px'), options={'': None, 'Alt. division': 'signed_period_alt', 'Year': 'signed_year', 'Default division': 'signed_period'}, value='signed_period'))))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code\n",
    "from scipy.sparse import csr_matrix\n",
    "%timeit\n",
    "\n",
    "    \n",
    "def get_top_tfidf_words(data, n_top=5):\n",
    "    top_list = data.groupby(['treaty_id'])\\\n",
    "        .apply(lambda x: x.nlargest(n_top, 'score'))\\\n",
    "        .reset_index(level=0, drop=True)\n",
    "    return top_list\n",
    "\n",
    "def compute_tfidf_scores(corpus, dictionary, smartirs='ntc'):\n",
    "    #model = gensim.models.logentropy_model.LogEntropyModel(corpus, normalize=True)\n",
    "    model = gensim.models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary, normalize=True) #, smartirs=smartirs)\n",
    "    rows, cols, scores = [], [], []\n",
    "    for r, document in enumerate(corpus): \n",
    "        vector = model[document]\n",
    "        c, v = zip(*vector)\n",
    "        rows += (len(c) * [ int(r) ])\n",
    "        cols += c\n",
    "        scores += v\n",
    "        \n",
    "    return csr_matrix((scores, (rows, cols)))\n",
    "    \n",
    "if True: #'tfidf_cache' not in globals():\n",
    "    tfidf_cache = {\n",
    "    }\n",
    "    \n",
    "def display_tfidf_scores(source_folder, language, period, n_top=5, threshold=0.001):\n",
    "    \n",
    "    global state, tfw, tfidf_cache\n",
    "    \n",
    "    try:\n",
    "        treaties = state.treaties\n",
    "\n",
    "        tfw.progress.value = 0\n",
    "        tfw.progress.value += 1\n",
    "        if language[0] not in tfidf_cache.keys():\n",
    "            corpus = TreatyCorpusSaveLoad(source_folder=source_folder, lang=language[0])\\\n",
    "                .load_mm_corpus(normalize_by_D=True)\n",
    "            document_names = corpus.document_names\n",
    "            dictionary = corpus.dictionary\n",
    "            _ = dictionary[0]\n",
    "\n",
    "            tfw.progress.value += 1\n",
    "            A = compute_tfidf_scores(corpus, dictionary)\n",
    "\n",
    "            tfw.progress.value += 1\n",
    "            scores = pd.DataFrame(\n",
    "                [ (i, j, dictionary.id2token[j], A[i, j]) for i, j in zip(*A.nonzero())],\n",
    "                columns=['document_id', 'token_id', 'token', 'score']\n",
    "            )\n",
    "            tfw.progress.value += 1\n",
    "            scores = scores.merge(document_names, how='inner', left_on='document_id', right_index=True)\\\n",
    "                .drop(['document_id', 'token_id', 'document_name'], axis=1)\n",
    "\n",
    "            scores = scores[['treaty_id', 'token', 'score']]\\\n",
    "                .sort_values(['treaty_id', 'score'], ascending=[True, False])\n",
    "\n",
    "            tfidf_cache[language[0]] = scores\n",
    "\n",
    "        scores = tfidf_cache[language[0]]\n",
    "        if threshold > 0:\n",
    "            scores = scores.loc[scores.score >= threshold]\n",
    "\n",
    "        tfw.progress.value += 1\n",
    "\n",
    "        #scores = get_top_tfidf_words(scores, n_top=5)\n",
    "        #scores = scores.groupby(['treaty_id']).sum() \n",
    "\n",
    "        scores = scores.groupby(['treaty_id'])\\\n",
    "            .apply(lambda x: x.nlargest(n_top, 'score'))\\\n",
    "            .reset_index(level=0, drop=True)\\\n",
    "            .set_index('treaty_id')\n",
    "\n",
    "        if period is not None:\n",
    "            periods = state.treaties[period]\n",
    "            scores = scores.merge(periods.to_frame(), left_index=True, right_index=True, how='inner')\\\n",
    "                .groupby([period, 'token']).score.agg([np.mean])\\\n",
    "                .reset_index().rename(columns={0:'score'}) #.sort_values('token')\n",
    "\n",
    "        #['token'].apply(' '.join)\n",
    "\n",
    "        display(scores)\n",
    "    except Exception as ex:\n",
    "        logger.error(ex)\n",
    "        \n",
    "    tfw.progress.value = 0\n",
    "\n",
    "#if 'tfidf_scores' not in globals():\n",
    "#    tfidf_scores = compute_document_tfidf(corpus, corpus.dictionary, state.treaties)\n",
    "#    tfidf_scores = tfidf_scores.sort_values(['treaty_id', 'score'], ascending=[True, False])\n",
    "\n",
    "tfw = BaseWidgetUtility(\n",
    "    language=widgets.Dropdown(\n",
    "        options={\n",
    "            'English': ('en', 'english'),\n",
    "            'French': ('fr', 'french'),\n",
    "            'German': ('de', 'german'),\n",
    "            'Italian': ('it', 'italian')\n",
    "        },\n",
    "        value=('en', 'english'),\n",
    "        description='Language:', **drop_style\n",
    "    ),\n",
    "    remove_stopwords=widgets.ToggleButton(\n",
    "        description='Remove stopwords', value=True,\n",
    "        tooltip='Do not include stopwords in token toplist', **toggle_style\n",
    "    ),    \n",
    "    n_top=widgets.IntSlider(\n",
    "        value=5, min=1, max=25, step=1,\n",
    "        description='Top #:',\n",
    "        continuous_update=False\n",
    "    ),\n",
    "    threshold=widgets.FloatSlider(\n",
    "        value=0.001, min=0.0, max=0.5, step=0.01,\n",
    "        description='Threshold:',\n",
    "        tooltip='Word having a TF-IDF score below this value is filtered out',\n",
    "        continuous_update=False,\n",
    "        readout_format='.3f',\n",
    "    ), \n",
    "    period=widgets.Dropdown(\n",
    "        options={\n",
    "            '': None,\n",
    "            'Year': 'signed_year',\n",
    "            'Default division': 'signed_period',\n",
    "            'Alt. division': 'signed_period_alt'\n",
    "        },\n",
    "        value='signed_period',\n",
    "        description='Period:', **drop_style\n",
    "    ),\n",
    "    output=widgets.Dropdown(\n",
    "        options={\n",
    "            '': None,\n",
    "            'Year': 'signed_year',\n",
    "            'Default division': 'signed_period',\n",
    "            'Alt. division': 'signed_period_alt'\n",
    "        },\n",
    "        value='signed_period',\n",
    "        description='Output:', **drop_style\n",
    "    ),\n",
    "    progress=widgets.IntProgress(min=0, max=5, step=1, value=0) #, layout=widgets.Layout(width='100%')),\n",
    ")\n",
    "\n",
    "itfw = widgets.interactive(\n",
    "    display_tfidf_scores,\n",
    "    source_folder='./data',\n",
    "    language=tfw.language,\n",
    "    n_top=tfw.n_top,\n",
    "    threshold=tfw.threshold,\n",
    "    period=tfw.period\n",
    ")\n",
    "\n",
    "boxes = widgets.HBox(\n",
    "    [\n",
    "        widgets.VBox([tfw.language, tfw.period]),\n",
    "        widgets.VBox([tfw.n_top, tfw.threshold]),\n",
    "        widgets.VBox([tfw.progress, tfw.output])\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(widgets.VBox([boxes, itfw.children[-1]]))\n",
    "itfw.update()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 655.4,
   "position": {
    "height": "886px",
    "left": "1049px",
    "right": "20px",
    "top": "110px",
    "width": "654px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
