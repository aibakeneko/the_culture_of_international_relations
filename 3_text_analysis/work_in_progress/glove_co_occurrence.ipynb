{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barn</th>\n",
       "      <th>Fell</th>\n",
       "      <th>Horse</th>\n",
       "      <th>Past</th>\n",
       "      <th>Raced</th>\n",
       "      <th>The</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barn</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fell</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horse</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Past</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raced</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Barn      Fell     Horse      Past  Raced  The\n",
       "word                                                     \n",
       "Barn   0.000000  0.000000  0.000000  0.000000    0.0  0.0\n",
       "Fell   1.000000  0.000000  0.000000  0.000000    0.0  0.0\n",
       "Horse  0.250000  0.200000  0.000000  0.000000    0.0  0.0\n",
       "Past   0.500000  0.333333  0.500000  0.000000    0.0  0.0\n",
       "Raced  0.333333  0.250000  1.000000  1.000000    0.0  0.0\n",
       "The    1.200000  0.500000  1.333333  1.333333    1.0  0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "from glove import Corpus\n",
    "import pandas as pd\n",
    "    \n",
    "# See http://www.foldl.me/2014/glove-python/\n",
    "def compute_GloVe_df(sentences, window=2, dictionary=None):\n",
    "    \n",
    "    corpus = Corpus( dictionary=dictionary)\n",
    "    corpus.fit(sentences, window=window)\n",
    "\n",
    "    dm = corpus.matrix.todense()\n",
    "    inverse_dictionary = { i: w for w, i in corpus.dictionary.items() }\n",
    "    id2token = [ inverse_dictionary[i] for i in range(0,max(inverse_dictionary.keys())+1)]\n",
    "\n",
    "    df = pd.DataFrame(dm.T, columns=id2token).assign(word=id2token).set_index('word')\n",
    "    return df\n",
    "\n",
    "# Create sorted dictionary to make HAL comparision easier\n",
    "def create_sorted_dictionary(sentences):\n",
    "    tokens = set()\n",
    "    for sentence in sentences:\n",
    "        tokens = tokens | set(sentence)\n",
    "    tokens = list(tokens)\n",
    "    tokens.sort()\n",
    "    dictionary = { w: i for i, w in enumerate(tokens)}    \n",
    "    return dictionary\n",
    "sentences = [ \"The Horse Raced Past The Barn Fell\".title().split() ]\n",
    "\n",
    "dictionary = create_sorted_dictionary(sentences)\n",
    "\n",
    "df = compute_GloVe_df(sentences, window=5, dictionary=dictionary)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 17), (1, 1), (2, 1), (3, 10), (4, 2), (5, 1), (6, 3), (7, 1), (8, 2), (9, 2), (10, 1), (11, 3), (12, 1), (13, 4), (14, 2), (15, 1), (16, 6), (17, 90), (18, 2), (19, 2), (20, 2), (21, 2), (22, 1), (23, 2), (24, 1), (25, 2), (26, 1), (27, 28), (28, 1), (29, 1), (30, 15), (31, 3), (32, 21), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 23), (41, 4), (42, 1), (43, 1), (44, 18), (45, 1), (46, 1), (47, 1), (48, 5), (49, 2), (50, 2), (51, 2), (52, 3), (53, 21), (54, 1), (55, 1), (56, 3), (57, 1), (58, 2), (59, 1), (60, 3), (61, 1), (62, 1), (63, 2), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 3), (70, 2), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 16), (78, 1), (79, 1), (80, 1), (81, 11), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 7), (88, 7), (89, 1), (90, 2), (91, 1), (92, 1), (93, 2), (94, 1), (95, 27), (96, 14), (97, 1), (98, 1), (99, 1), (100, 1), (101, 3), (102, 2), (103, 15), (104, 1), (105, 1), (106, 1), (107, 1), (108, 2), (109, 2), (110, 4), (111, 1), (112, 3), (113, 3), (114, 1), (115, 1), (116, 1), (117, 1), (118, 3), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 2), (126, 1), (127, 6), (128, 15), (129, 15), (130, 1), (131, 1), (132, 1), (133, 1), (134, 2), (135, 1), (136, 1), (137, 1), (138, 1), (139, 3), (140, 1), (141, 4), (142, 1), (143, 2), (144, 2), (145, 6), (146, 1), (147, 5), (148, 1), (149, 1), (150, 4), (151, 1), (152, 2), (153, 1), (154, 2), (155, 1), (156, 3), (157, 1), (158, 3), (159, 1), (160, 2), (161, 16), (162, 2), (163, 1), (164, 1), (165, 1), (166, 13), (167, 1), (168, 30), (169, 5), (170, 1), (171, 1), (172, 1), (173, 1), (174, 2), (175, 1), (176, 2), (177, 1), (178, 25), (179, 5), (180, 1), (181, 2), (182, 3), (183, 2), (184, 1), (185, 7), (186, 1), (187, 3), (188, 2), (189, 1), (190, 3), (191, 3), (192, 2), (193, 1), (194, 1), (195, 1), (196, 50), (197, 1), (198, 2), (199, 1), (200, 6), (201, 1), (202, 2), (203, 2), (204, 3), (205, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 2), (211, 3), (212, 2), (213, 5), (214, 7), (215, 1), (216, 3), (217, 1), (218, 3), (219, 2), (220, 4), (221, 1), (222, 2), (223, 3), (224, 1), (225, 1), (226, 4), (227, 4), (228, 1), (229, 1), (230, 11), (231, 4), (232, 1), (233, 1), (234, 1), (235, 1), (236, 1), (237, 1), (238, 1), (239, 8), (240, 3), (241, 3), (242, 1), (243, 1), (244, 2), (245, 2), (246, 1), (247, 1), (248, 1), (249, 3), (250, 1), (251, 2), (252, 1), (253, 1), (254, 2), (255, 6), (256, 1), (257, 1), (258, 6), (259, 1), (260, 2), (261, 1), (262, 1), (263, 1), (264, 8), (265, 102), (266, 1), (267, 6), (268, 1), (269, 3), (270, 2), (271, 2), (272, 1), (273, 1), (274, 1), (275, 2), (276, 4), (277, 2), (278, 2), (279, 1), (280, 1), (281, 10), (282, 2), (283, 1), (284, 1), (285, 4), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 2), (296, 1), (297, 3), (298, 1), (299, 2), (300, 1), (301, 1), (302, 1), (303, 6), (304, 1), (305, 1), (306, 6), (307, 1), (308, 1), (309, 2), (310, 1), (311, 1), (312, 1), (313, 1), (314, 4), (315, 1), (316, 1), (317, 1), (318, 1), (319, 3), (320, 11), (321, 2), (322, 5), (323, 1), (324, 3), (325, 7), (326, 2), (327, 1), (328, 1), (329, 1), (330, 1), (331, 2), (332, 5), (333, 1), (334, 3), (335, 3), (336, 2), (337, 1), (338, 1), (339, 1), (340, 2), (341, 1), (342, 3), (343, 12), (344, 1), (345, 1), (346, 1), (347, 1), (348, 1), (349, 1), (350, 1), (351, 1), (352, 1), (353, 2), (354, 1), (355, 3), (356, 1), (357, 1), (358, 1), (359, 2), (360, 2), (361, 8), (362, 3), (363, 1), (364, 16), (365, 1), (366, 7), (367, 2), (368, 1), (369, 1), (370, 24), (371, 4), (372, 1), (373, 1), (374, 1), (375, 2), (376, 1), (377, 1), (378, 1), (379, 1), (380, 2), (381, 1), (382, 5), (383, 1), (384, 6), (385, 1), (386, 1), (387, 1), (388, 1), (389, 1), (390, 2), (391, 1), (392, 10), (393, 1), (394, 3), (395, 1), (396, 1), (397, 5), (398, 1), (399, 3), (400, 1), (401, 13), (402, 181), (403, 1), (404, 5), (405, 2), (406, 1), (407, 6), (408, 3), (409, 11), (410, 1), (411, 1), (412, 51), (413, 1), (414, 1), (415, 1), (416, 1), (417, 12), (418, 2), (419, 4), (420, 3), (421, 1), (422, 6), (423, 2), (424, 1), (425, 1), (426, 1), (427, 4), (428, 1), (429, 1), (430, 1), (431, 6), (432, 2), (433, 22), (434, 1), (435, 1), (436, 13), (437, 3), (438, 6), (439, 1), (440, 2), (441, 3)]\n"
     ]
    }
   ],
   "source": [
    "# Glove CO-OCCURRENCE (as implemented in python-glove):\n",
    "#  The counts are ALWAYS FORWARD i.e the window is added tvalues are ABSOLUTE c\n",
    "#  Added increment for each pair = 1 / distance-between-other-word\n",
    "#  NO normalization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glove\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "pd.options.display.precision = 2\n",
    "window = 4\n",
    "docs = [\n",
    "    'one two two one two two one two two one two two',\n",
    "    'one two two one two two one two two one two two',\n",
    "    #'This is the first document.',\n",
    "    #'This document is the second document.',\n",
    "    #'And this is the third one.',\n",
    "    #'Is this the first document?',\n",
    "]\n",
    "\n",
    "docs = [\n",
    "    [ w.lower() for w in word_tokenize(doc) if len(w) > 1 ] for doc in docs\n",
    "]\n",
    "\n",
    "model = glove.Corpus()\n",
    "model.fit(docs, window=window)\n",
    "\n",
    "X = model.matrix + model.matrix.T\n",
    "T = len(model.dictionary)\n",
    "id2token = { i: w for w, i in model.dictionary.items()  }\n",
    "\n",
    "df = pd.DataFrame(data=X.todense(), index=np.array(range(1, T+1)), columns=np.array(range(1, T+1)))\n",
    "df.columns = list(id2token.values())\n",
    "df['word'] = list(id2token.values())\n",
    "df = df.set_index('word')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
